# å¼€å‘è€…æŒ‡å—

**æœ¬æŒ‡å—é¢å‘å¼€å‘è€…**ï¼Œä»‹ç»å¦‚ä½•è¿›è¡ŒäºŒæ¬¡å¼€å‘å’Œæ‰©å±•ã€‚

> ğŸ’¡ **è®¾è®¡åŸåˆ™**ï¼šæ¨¡å—åŒ–æ¶æ„ã€ç±»å‹å®‰å…¨ã€æ˜“äºæ‰©å±•

---

## ğŸ“‹ ç›®å½•

- [é¡¹ç›®æ¶æ„](#é¡¹ç›®æ¶æ„)
- [æ ¸å¿ƒæ¨¡å—](#æ ¸å¿ƒæ¨¡å—)
- [UI å¼€å‘](#ui-å¼€å‘)
- [æ‰©å±•å¼€å‘](#æ‰©å±•å¼€å‘)
- [æœ€ä½³å®è·µ](#æœ€ä½³å®è·µ)

---

## é¡¹ç›®æ¶æ„

### ç›®å½•ç»“æ„

```
ai-data-analyst-system/
â”œâ”€â”€ config/                    # é…ç½®æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ settings.py           # ç³»ç»Ÿé…ç½®ï¼ˆPydantic Settingsï¼‰
â”‚   â”œâ”€â”€ llm_config.py         # LLM å’Œ Embedding é…ç½®
â”‚   â””â”€â”€ prompts.py            # Prompt æ¨¡æ¿ç®¡ç†
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/               # Pydantic æ•°æ®æ¨¡å‹ï¼ˆç±»å‹å®‰å…¨ï¼‰
â”‚   â”‚   â”œâ”€â”€ config.py         # é…ç½®æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ datasource.py     # æ•°æ®æºæ¨¡å‹
â”‚   â”‚   â””â”€â”€ analysis.py       # åˆ†æç»“æœæ¨¡å‹
â”‚   â”‚
â”‚   â”œâ”€â”€ datasources/          # æ•°æ®æºé€‚é…å™¨ï¼ˆç­–ç•¥æ¨¡å¼ï¼‰
â”‚   â”‚   â”œâ”€â”€ base.py           # æŠ½è±¡åŸºç±»
â”‚   â”‚   â”œâ”€â”€ sqlite_source.py  # SQLite é€‚é…å™¨
â”‚   â”‚   â”œâ”€â”€ file_source.py    # æ–‡ä»¶é€‚é…å™¨
â”‚   â”‚   â”œâ”€â”€ knowledge_base.py # çŸ¥è¯†åº“é€‚é…å™¨
â”‚   â”‚   â””â”€â”€ web_source.py     # Web æœç´¢é€‚é…å™¨
â”‚   â”‚
â”‚   â”œâ”€â”€ analyzers/            # æ•°æ®åˆ†æå™¨
â”‚   â”‚   â””â”€â”€ data_analyzer.py  # æ ¸å¿ƒåˆ†æé€»è¾‘
â”‚   â”‚
â”‚   â”œâ”€â”€ tools/                # å·¥å…·æ¨¡å—
â”‚   â”‚   â””â”€â”€ nl2sql.py         # NL2SQL è½¬æ¢å·¥å…·
â”‚   â”‚
â”‚   â”œâ”€â”€ ui/                   # UI ç»„ä»¶ï¼ˆGradioï¼‰
â”‚   â”‚   â”œâ”€â”€ constants.py      # UI å¸¸é‡
â”‚   â”‚   â”œâ”€â”€ helpers.py        # UI è¾…åŠ©å‡½æ•°
â”‚   â”‚   â””â”€â”€ datasource_manager.py  # æ•°æ®æºç®¡ç†ç»„ä»¶
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/                # å·¥å…·å‡½æ•°
â”‚   â”‚   â”œâ”€â”€ logger.py         # æ—¥å¿—é…ç½®
â”‚   â”‚   â””â”€â”€ helpers.py        # é€šç”¨è¾…åŠ©å‡½æ•°
â”‚   â”‚
â”‚   â””â”€â”€ agent.py              # æ ¸å¿ƒ Agent ç±»
â”‚
â”œâ”€â”€ data/                     # æ•°æ®ç›®å½•
â”‚   â”œâ”€â”€ databases/            # SQLite æ•°æ®åº“
â”‚   â”œâ”€â”€ files/                # CSV/Excel/JSON æ–‡ä»¶
â”‚   â”œâ”€â”€ knowledge_base/       # çŸ¥è¯†åº“æ–‡æ¡£
â”‚   â””â”€â”€ cache/                # Embedding ç¼“å­˜
â”‚
â”œâ”€â”€ docs/                     # é¡¹ç›®æ–‡æ¡£
â”œâ”€â”€ logs/                     # è¿è¡Œæ—¥å¿—
â”œâ”€â”€ output/                   # è¾“å‡ºæ–‡ä»¶
â”‚
â”œâ”€â”€ init_system.py            # ç³»ç»Ÿåˆå§‹åŒ–è„šæœ¬
â”œâ”€â”€ web_ui.py                 # Web UI å…¥å£ï¼ˆGradioï¼‰
â”œâ”€â”€ requirements.txt          # é¡¹ç›®ä¾èµ–
â””â”€â”€ .env                      # ç¯å¢ƒé…ç½®
```

### æ ¸å¿ƒæ¶æ„è®¾è®¡

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Web UI (Gradio)                â”‚
â”‚  - å•å±è®¾è®¡ï¼Œè‡ªåŠ¨åˆå§‹åŒ–                   â”‚
â”‚  - å®æ—¶å¯è§†åŒ–æ›´æ–°                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        DataAnalystAgent                  â”‚
â”‚  - å¯¹è¯ç®¡ç†ï¼ˆä¸Šä¸‹æ–‡ä¿æŒï¼‰                 â”‚
â”‚  - æ•°æ®æºæ³¨å†Œä¸ç®¡ç†                       â”‚
â”‚  - æŸ¥è¯¢è°ƒåº¦ä¸ç»“æœå¤„ç†                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚        â”‚        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â” â”Œâ”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Analyzer  â”‚ â”‚LLM API â”‚ â”‚Embedding â”‚
â”‚ åˆ†æå™¨    â”‚ â”‚é…ç½®å±‚  â”‚ â”‚æ¨¡å‹      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
  â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚            â”‚          â”‚        â”‚
â”Œâ”€â–¼â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â–¼â”€â”€â”€â”  â”Œâ”€â”€â–¼â”€â”€â”  â”Œâ”€â”€â–¼â”€â”€â”€â”
â”‚SQLiteâ”‚  â”‚ File  â”‚  â”‚ KB  â”‚  â”‚ Web  â”‚
â”‚Sourceâ”‚  â”‚Source â”‚  â”‚     â”‚  â”‚Searchâ”‚
â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜
         æ•°æ®æºé€‚é…å±‚ï¼ˆæ’ä»¶åŒ–ï¼‰
```

### å…³é”®è®¾è®¡æ¨¡å¼

1. **ç­–ç•¥æ¨¡å¼** - æ•°æ®æºé€‚é…å™¨ï¼Œç»Ÿä¸€æ¥å£ä¸åŒå®ç°
2. **å•ä¾‹æ¨¡å¼** - Agent å®ä¾‹ç®¡ç†
3. **å·¥å‚æ¨¡å¼** - LLM å’Œ Embedding æ¨¡å‹åˆ›å»º
4. **è§‚å¯Ÿè€…æ¨¡å¼** - UI ç»„ä»¶çŠ¶æ€æ›´æ–°

---

## æ ¸å¿ƒæ¨¡å—

### 1. æ•°æ®æ¨¡å‹ (src/models/)

ä½¿ç”¨ **Pydantic v2** è¿›è¡Œæ•°æ®éªŒè¯å’Œåºåˆ—åŒ–ã€‚

#### é…ç½®æ¨¡å‹ (models/config.py)

```python
from pydantic import BaseModel, Field
from typing import Optional

class LLMConfig(BaseModel):
    """LLM é…ç½®æ¨¡å‹"""
    api_key: str = Field(..., description="APIå¯†é’¥")
    api_base: str = Field(default="https://api.openai.com/v1")
    model: str = Field(default="gpt-3.5-turbo")
    temperature: float = Field(default=0.1, ge=0.0, le=2.0)
    
    class Config:
        str_strip_whitespace = True  # è‡ªåŠ¨å»é™¤ç©ºç™½

class EmbeddingConfig(BaseModel):
    """Embedding é…ç½®æ¨¡å‹"""
    provider: str = Field(default="huggingface")
    model_name: str
    api_key: Optional[str] = None
```

#### æ•°æ®æºæ¨¡å‹ (models/datasource.py)

```python
from pydantic import BaseModel
from typing import List, Dict, Any, Optional
from datetime import datetime

class QueryRequest(BaseModel):
    """æŸ¥è¯¢è¯·æ±‚æ¨¡å‹"""
    query: str = Field(..., description="æŸ¥è¯¢é—®é¢˜")
    data_source: str = Field(..., description="æ•°æ®æºåç§°")
    limit: Optional[int] = Field(default=100, ge=1, le=10000)

class QueryMetadata(BaseModel):
    """æŸ¥è¯¢å…ƒæ•°æ®"""
    rows_returned: int
    execution_time: float
    sql_query: Optional[str] = None
    timestamp: datetime = Field(default_factory=datetime.now)

class QueryResponse(BaseModel):
    """æŸ¥è¯¢å“åº”æ¨¡å‹"""
    success: bool
    data: List[Dict[str, Any]] = []
    metadata: QueryMetadata
    error: Optional[str] = None
    
    class Config:
        json_encoders = {
            datetime: lambda v: v.isoformat()
        }
```

### 2. æ•°æ®æºé€‚é…å™¨ (src/datasources/)

#### åŸºç±»è®¾è®¡ (datasources/base.py)

```python
from abc import ABC, abstractmethod
from typing import Dict, Any, List
from llama_index.core import VectorStoreIndex

class BaseDataSource(ABC):
    """æ•°æ®æºæŠ½è±¡åŸºç±»"""
    
    def __init__(self, name: str, **kwargs):
        self.name = name
        self.config = kwargs
    
    @abstractmethod
    def get_index(self) -> VectorStoreIndex:
        """è·å– LlamaIndex ç´¢å¼•"""
        pass
    
    @abstractmethod
    def get_schema(self) -> str:
        """è·å–æ•°æ®æºç»“æ„ä¿¡æ¯"""
        pass
    
    @abstractmethod
    def query(self, query_str: str) -> Dict[str, Any]:
        """æ‰§è¡ŒæŸ¥è¯¢"""
        pass
    
    def validate_config(self) -> bool:
        """éªŒè¯é…ç½®"""
        return True
```

#### SQLite é€‚é…å™¨ (datasources/sqlite_source.py)

```python
from llama_index.core import SQLDatabase, VectorStoreIndex
from sqlalchemy import create_engine, text
import pandas as pd

class SQLiteDataSource(BaseDataSource):
    """SQLite æ•°æ®æºé€‚é…å™¨"""
    
    def __init__(self, name: str, db_path: str):
        super().__init__(name, db_path=db_path)
        self.engine = create_engine(f"sqlite:///{db_path}")
        self.sql_database = SQLDatabase(self.engine)
    
    def get_index(self) -> VectorStoreIndex:
        """è·å–ç´¢å¼•"""
        from llama_index.core import VectorStoreIndex
        return VectorStoreIndex.from_documents([])
    
    def get_schema(self) -> str:
        """è·å–è¡¨ç»“æ„"""
        return self.sql_database.get_table_info()
    
    def query(self, query_str: str) -> Dict[str, Any]:
        """æ‰§è¡Œ SQL æŸ¥è¯¢"""
        try:
            with self.engine.connect() as conn:
                result = conn.execute(text(query_str))
                rows = result.fetchall()
                columns = result.keys()
                
                data = [dict(zip(columns, row)) for row in rows]
                
                return {
                    "success": True,
                    "data": data,
                    "rows": len(data)
                }
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "data": []
            }
```

### 3. æ ¸å¿ƒ Agent (src/agent.py)

```python
from typing import Dict, List, Optional
from src.datasources.base import BaseDataSource
from src.analyzers.data_analyzer import DataAnalyzer
from config.llm_config import get_llm, get_embedding_model

class DataAnalystAgent:
    """æ•°æ®åˆ†æ Agent æ ¸å¿ƒç±»"""
    
    def __init__(self, max_history_turns: int = 10):
        self.data_sources: Dict[str, BaseDataSource] = {}
        self.llm = get_llm()
        self.embedding = get_embedding_model()
        self.analyzer = DataAnalyzer(self)
        self.chat_history: List[Dict] = []
        self.max_history_turns = max_history_turns
    
    def register_data_source(self, source: BaseDataSource):
        """æ³¨å†Œæ•°æ®æº"""
        self.data_sources[source.name] = source
        logger.info(f"æ³¨å†Œæ•°æ®æº: {source.name}")
    
    def register_sqlite_database(self, name: str, db_path: str) -> bool:
        """æ³¨å†Œ SQLite æ•°æ®åº“"""
        from src.datasources.sqlite_source import SQLiteDataSource
        try:
            source = SQLiteDataSource(name, db_path)
            self.register_data_source(source)
            return True
        except Exception as e:
            logger.error(f"æ³¨å†Œå¤±è´¥: {e}")
            return False
    
    def list_data_sources(self) -> Dict[str, str]:
        """åˆ—å‡ºæ‰€æœ‰æ•°æ®æº"""
        return {
            name: type(source).__name__ 
            for name, source in self.data_sources.items()
        }
    
    def _add_to_history(self, role: str, content: str):
        """æ·»åŠ å¯¹è¯å†å²"""
        self.chat_history.append({"role": role, "content": content})
        
        # ä¿æŒå†å²è½®æ•°é™åˆ¶
        if len(self.chat_history) > self.max_history_turns * 2:
            self.chat_history = self.chat_history[-self.max_history_turns * 2:]
    
    def clear_history(self):
        """æ¸…ç©ºå¯¹è¯å†å²"""
        self.chat_history = []
```

### 4. æ•°æ®åˆ†æå™¨ (src/analyzers/data_analyzer.py)

```python
class DataAnalyzer:
    """æ•°æ®åˆ†æå™¨ - è´Ÿè´£æŸ¥è¯¢åˆ†æå’Œæ‰§è¡Œ"""
    
    def __init__(self, agent: 'DataAnalystAgent'):
        self.agent = agent
    
    def analyze_single_source(
        self, 
        question: str, 
        source_name: str,
        chat_history: str = ""
    ) -> Dict[str, Any]:
        """åˆ†æå•ä¸ªæ•°æ®æº"""
        
        # 1. è·å–æ•°æ®æº
        source = self.agent.data_sources.get(source_name)
        if not source:
            return {"success": False, "error": "æ•°æ®æºä¸å­˜åœ¨"}
        
        # 2. ç”Ÿæˆ SQLï¼ˆå¦‚æœæ˜¯æ•°æ®åº“ï¼‰
        if isinstance(source, SQLiteDataSource):
            sql = self._generate_sql(question, source)
            result = source.query(sql)
            result["sql"] = sql
        else:
            # 3. å…¶ä»–æ•°æ®æºä½¿ç”¨å‘é‡æ£€ç´¢
            result = self._query_index(question, source)
        
        # 4. ç”Ÿæˆè‡ªç„¶è¯­è¨€å›ç­”
        if result["success"]:
            answer = self._generate_answer(question, result["data"])
            result["answer"] = answer
        
        return result
    
    def _generate_sql(self, question: str, source) -> str:
        """ä½¿ç”¨ LLM ç”Ÿæˆ SQL"""
        from config.prompts import SQL_GENERATION_PROMPT
        
        schema = source.get_schema()
        prompt = SQL_GENERATION_PROMPT.format(
            schema=schema,
            question=question
        )
        
        response = self.agent.llm.complete(prompt)
        sql = self._extract_sql(response.text)
        return sql
```

---

## UI å¼€å‘

### Gradio ç•Œé¢è®¾è®¡

#### æ ¸å¿ƒç‰¹æ€§

1. **è‡ªåŠ¨åˆå§‹åŒ–** - ä½¿ç”¨ `demo.load()` äº‹ä»¶
2. **å•å±å¸ƒå±€** - é¿å…æ ‡ç­¾é¡µåˆ‡æ¢
3. **å®æ—¶æ›´æ–°** - ä½¿ç”¨ `.change()` äº‹ä»¶ç›‘å¬
4. **çŠ¶æ€ç®¡ç†** - AppState ç±»ç»Ÿä¸€ç®¡ç†

#### å…³é”®ä»£ç  (web_ui.py)

```python
class AppState:
    """å…¨å±€çŠ¶æ€ç®¡ç†"""
    def __init__(self):
        self.agent: Optional[DataAnalystAgent] = None
        self.last_query_result: Optional[pd.DataFrame] = None
        self.query_history: List[dict] = []
        self.auto_visualize: bool = True

# è‡ªåŠ¨åˆå§‹åŒ–
demo.load(
    fn=lambda: (initialize_agent()[1], update_source_list()),
    outputs=[system_status, source_dropdown]
)

# å®æ—¶å›¾è¡¨æ›´æ–°
for component in [chart_type, x_column, y_column, color_column]:
    component.change(
        fn=update_chart,
        inputs=[chart_type, x_column, y_column, color_column],
        outputs=viz_chart
    )
```

#### è‡ªåŠ¨å¯è§†åŒ–å®ç°

```python
def chat_response(message: str, history: List, source: str):
    """å¯¹è¯å“åº” + è‡ªåŠ¨å¯è§†åŒ–"""
    
    # 1. æ‰§è¡ŒæŸ¥è¯¢
    result = agent.analyzer.analyze_single_source(...)
    
    # 2. è‡ªåŠ¨ç”Ÿæˆå›¾è¡¨
    if result.get("data"):
        df = pd.DataFrame(result["data"])
        
        # æ™ºèƒ½é€‰æ‹©å›¾è¡¨ç±»å‹
        chart_type = "bar"
        if df[y_col].dtype in ['float64', 'int64'] and len(df) > 10:
            chart_type = "line"
        
        # ç”Ÿæˆå›¾è¡¨
        viz_chart = create_chart_from_dataframe(
            df=df,
            chart_type=chart_type,
            x_col=cols[0],
            y_col=cols[1]
        )
    
    return history, viz_chart, df, ...
```

### UI ç»„ä»¶å°è£… (src/ui/)

```python
# ui/helpers.py
def create_chart_from_dataframe(
    df: pd.DataFrame,
    chart_type: str,
    x_col: str,
    y_col: str,
    color_col: Optional[str] = None,
    title: Optional[str] = None
) -> go.Figure:
    """åˆ›å»º Plotly å›¾è¡¨"""
    
    if chart_type == "bar":
        fig = px.bar(df, x=x_col, y=y_col, color=color_col, title=title)
    elif chart_type == "line":
        fig = px.line(df, x=x_col, y=y_col, color=color_col, title=title)
    # ...
    
    return fig
```

---

## æ‰©å±•å¼€å‘

### æ·»åŠ æ–°æ•°æ®æº

#### 1. åˆ›å»ºé€‚é…å™¨ç±»

```python
# src/datasources/my_source.py
from src.datasources.base import BaseDataSource

class MyDataSource(BaseDataSource):
    """è‡ªå®šä¹‰æ•°æ®æº"""
    
    def __init__(self, name: str, **config):
        super().__init__(name, **config)
        # åˆå§‹åŒ–è¿æ¥
        self.client = MyClient(**config)
    
    def get_index(self) -> VectorStoreIndex:
        """å®ç°ç´¢å¼•è·å–"""
        documents = self._load_documents()
        return VectorStoreIndex.from_documents(documents)
    
    def get_schema(self) -> str:
        """è¿”å›æ•°æ®ç»“æ„æè¿°"""
        return "æ•°æ®æºç»“æ„ä¿¡æ¯..."
    
    def query(self, query_str: str) -> Dict[str, Any]:
        """æ‰§è¡ŒæŸ¥è¯¢"""
        try:
            result = self.client.query(query_str)
            return {
                "success": True,
                "data": result
            }
        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }
```

#### 2. åœ¨ Agent ä¸­æ³¨å†Œ

```python
# src/agent.py
def register_my_datasource(self, name: str, **config) -> bool:
    """æ³¨å†Œè‡ªå®šä¹‰æ•°æ®æº"""
    from src.datasources.my_source import MyDataSource
    try:
        source = MyDataSource(name, **config)
        self.register_data_source(source)
        return True
    except Exception as e:
        logger.error(f"æ³¨å†Œå¤±è´¥: {e}")
        return False
```

#### 3. æ·»åŠ  UI å…¥å£

```python
# web_ui.py - åœ¨æ•°æ®æºç®¡ç†é¢æ¿æ·»åŠ é€‰é¡¹
ds_type = gr.Radio(
    choices=["SQLiteæ•°æ®åº“", "æ–‡ä»¶(CSV/Excel)", "çŸ¥è¯†åº“", "æˆ‘çš„æ•°æ®æº"],
    value="SQLiteæ•°æ®åº“",
    label="ç±»å‹"
)

# æ·»åŠ å¤„ç†é€»è¾‘
def quick_register_datasource(ds_type: str, name: str, path: str):
    if ds_type == "æˆ‘çš„æ•°æ®æº":
        result = app_state.agent.register_my_datasource(name, path=path)
    # ...
```

### è‡ªå®šä¹‰ Prompt

```python
# config/prompts.py
SQL_GENERATION_PROMPT = """
ä½ æ˜¯ä¸€ä¸ª SQL ä¸“å®¶ã€‚æ ¹æ®ä»¥ä¸‹æ•°æ®åº“ç»“æ„å’Œç”¨æˆ·é—®é¢˜ç”Ÿæˆ SQL æŸ¥è¯¢ã€‚

æ•°æ®åº“ç»“æ„ï¼š
{schema}

ç”¨æˆ·é—®é¢˜ï¼š
{question}

è¦æ±‚ï¼š
1. åªè¿”å› SQL è¯­å¥ï¼Œä¸è¦å…¶ä»–å†…å®¹
2. ä½¿ç”¨ SELECT è¯­å¥
3. é™åˆ¶è¿”å› 100 æ¡è®°å½•

SQL:
"""

# ä½¿ç”¨
from config.prompts import SQL_GENERATION_PROMPT
prompt = SQL_GENERATION_PROMPT.format(schema=schema, question=question)
response = llm.complete(prompt)
```

### æ·»åŠ æ–°å›¾è¡¨ç±»å‹

```python
# src/ui/helpers.py
def create_chart_from_dataframe(...):
    """æ‰©å±•å›¾è¡¨ç±»å‹"""
    
    if chart_type == "heatmap":
        # çƒ­åŠ›å›¾
        fig = px.density_heatmap(df, x=x_col, y=y_col, title=title)
    
    elif chart_type == "treemap":
        # æ ‘çŠ¶å›¾
        fig = px.treemap(df, path=[x_col], values=y_col, title=title)
    
    elif chart_type == "sunburst":
        # æ—­æ—¥å›¾
        fig = px.sunburst(df, path=[x_col], values=y_col, title=title)
    
    return fig
```

---

## æœ€ä½³å®è·µ

### 1. ä»£ç è§„èŒƒ

```python
# âœ… å¥½çš„å®è·µ
from typing import Optional, List, Dict, Any
from pydantic import BaseModel, Field

class MyModel(BaseModel):
    """æ¸…æ™°çš„æ–‡æ¡£å­—ç¬¦ä¸²"""
    name: str = Field(..., description="åç§°")
    value: Optional[int] = Field(default=None, ge=0)
    
    def process(self) -> Dict[str, Any]:
        """æ–¹æ³•ä¹Ÿè¦æœ‰æ–‡æ¡£å­—ç¬¦ä¸²"""
        return {"name": self.name, "value": self.value}

# âŒ é¿å…
def process(data):  # ç¼ºå°‘ç±»å‹æ³¨è§£
    return data  # ç¼ºå°‘æ–‡æ¡£å­—ç¬¦ä¸²
```

### 2. é”™è¯¯å¤„ç†

```python
# âœ… å®Œå–„çš„é”™è¯¯å¤„ç†
def query_database(sql: str) -> Dict[str, Any]:
    try:
        result = execute_sql(sql)
        return {"success": True, "data": result}
    except SQLError as e:
        logger.error(f"SQL é”™è¯¯: {e}")
        return {"success": False, "error": f"SQL é”™è¯¯: {str(e)}"}
    except Exception as e:
        logger.error(f"æœªçŸ¥é”™è¯¯: {e}", exc_info=True)
        return {"success": False, "error": "ç³»ç»Ÿé”™è¯¯"}

# âŒ é¿å…è£¸éœ²çš„å¼‚å¸¸
def query_database(sql):
    result = execute_sql(sql)  # å¯èƒ½æŠ›å‡ºå¼‚å¸¸
    return result
```

### 3. æ—¥å¿—è®°å½•

```python
from src.utils.logger import logger

# âœ… é€‚å½“çš„æ—¥å¿—çº§åˆ«
logger.debug("è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯")
logger.info("é‡è¦æ“ä½œ: æ³¨å†Œæ•°æ®æº {name}")
logger.warning("è­¦å‘Š: æ•°æ®å¯èƒ½ä¸å®Œæ•´")
logger.error("é”™è¯¯: æŸ¥è¯¢å¤±è´¥", exc_info=True)  # åŒ…å«å †æ ˆ

# âŒ é¿å…
print("è°ƒè¯•ä¿¡æ¯")  # ä¸ä½¿ç”¨ print
logger.info("...")  # æ‰€æœ‰æ—¥å¿—éƒ½ç”¨ info
```

### 4. é…ç½®ç®¡ç†

```python
# âœ… ä½¿ç”¨ç¯å¢ƒå˜é‡
from config.settings import settings

api_key = settings.llm_api_key
model = settings.llm_model

# âŒ é¿å…ç¡¬ç¼–ç 
api_key = "sk-xxxxx"  # ä¸è¦ç¡¬ç¼–ç å¯†é’¥
```

### 5. æµ‹è¯•

```python
# tests/test_datasource.py
import pytest
from src.datasources.sqlite_source import SQLiteDataSource

def test_sqlite_query():
    """æµ‹è¯• SQLite æŸ¥è¯¢"""
    source = SQLiteDataSource("test", "test.db")
    result = source.query("SELECT * FROM users LIMIT 10")
    
    assert result["success"] is True
    assert len(result["data"]) <= 10
    assert "id" in result["data"][0]

def test_invalid_sql():
    """æµ‹è¯•æ— æ•ˆ SQL"""
    source = SQLiteDataSource("test", "test.db")
    result = source.query("INVALID SQL")
    
    assert result["success"] is False
    assert "error" in result
```

---

## æ€§èƒ½ä¼˜åŒ–

### 1. Embedding ç¼“å­˜

```python
# å¯ç”¨æŒä¹…åŒ–ç¼“å­˜
from llama_index.core import StorageContext, load_index_from_storage

# é¦–æ¬¡åˆ›å»º
index = VectorStoreIndex.from_documents(documents)
index.storage_context.persist(persist_dir="./data/cache")

# åç»­åŠ è½½
storage_context = StorageContext.from_defaults(persist_dir="./data/cache")
index = load_index_from_storage(storage_context)
```

### 2. æŸ¥è¯¢é™åˆ¶

```python
# é™åˆ¶è¿”å›è¡Œæ•°
def query(self, sql: str, limit: int = 100) -> Dict:
    """æ·»åŠ  LIMIT å­å¥"""
    if "LIMIT" not in sql.upper():
        sql = f"{sql} LIMIT {limit}"
    
    return self.execute(sql)
```

### 3. å¼‚æ­¥å¤„ç†

```python
import asyncio
from typing import List

async def batch_query(queries: List[str]) -> List[Dict]:
    """æ‰¹é‡å¼‚æ­¥æŸ¥è¯¢"""
    tasks = [query_async(q) for q in queries]
    results = await asyncio.gather(*tasks)
    return results
```

---

## è°ƒè¯•æŠ€å·§

### 1. å¯ç”¨è¯¦ç»†æ—¥å¿—

```bash
# .env
LOG_LEVEL=DEBUG
```

### 2. ä½¿ç”¨ IPython è°ƒè¯•

```python
# åœ¨ä»£ç ä¸­æ’å…¥æ–­ç‚¹
from IPython import embed
embed()  # è¿›å…¥äº¤äº’å¼è°ƒè¯•
```

### 3. æŸ¥çœ‹ LLM è¯·æ±‚

```python
# å¯ç”¨ LlamaIndex è°ƒè¯•
import logging
logging.basicConfig(level=logging.DEBUG)
logging.getLogger("llama_index").setLevel(logging.DEBUG)
```

---

## éƒ¨ç½²

### æœ¬åœ°éƒ¨ç½²

```bash
python web_ui.py
```

### Docker éƒ¨ç½²

```dockerfile
FROM python:3.10-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .

CMD ["python", "web_ui.py"]
```

```bash
docker build -t ai-data-analyst .
docker run -p 7860:7860 -v $(pwd)/data:/app/data ai-data-analyst
```

---

## è´¡çŒ®æŒ‡å—

1. Fork é¡¹ç›®
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. å¼€å¯ Pull Request

---

**æ›´æ–°æ—¥æœŸ**: 2025-12-31  
**ç‰ˆæœ¬**: v2.0 - ä¼˜åŒ–æ¶æ„

è¯¦è§ [Pydantic æ•°æ®éªŒè¯æŒ‡å—](PYDANTIC_GUIDE.md)

### 2. æ•°æ®æºé€‚é…å™¨ (src/datasources/)

æ‰€æœ‰æ•°æ®æºç»§æ‰¿ `DataSource` åŸºç±»ï¼š

```python
from src.datasources.base import DataSource
from src.models.datasource import QueryResponse

class CustomDataSource(DataSource):
    def __init__(self, name: str):
        super().__init__(name, "custom")
    
    def connect(self) -> bool:
        # å®ç°è¿æ¥é€»è¾‘
        return True
    
    def query(self, query: str, **kwargs) -> QueryResponse:
        # å®ç°æŸ¥è¯¢é€»è¾‘
        return QueryResponse(
            success=True,
            data=[...],
            metadata=QueryMetadata(...)
        )
    
    def get_schema(self) -> str:
        # è¿”å› schema æè¿°
        return "..."
    
    def close(self):
        # æ¸…ç†èµ„æº
        pass
```

### 3. Agent (src/agent.py)

æ ¸å¿ƒå¯¹è¯ä»£ç†ï¼š

```python
from src.agent import DataAnalystAgent

# åˆ›å»º Agent
agent = DataAnalystAgent(max_history_turns=10)

# æ³¨å†Œæ•°æ®æº
agent.register_sqlite_database("my_db", "path/to/db.sqlite")

# å¯¹è¯æŸ¥è¯¢
response = agent.chat("æŸ¥è¯¢é”€å”®æ•°æ®", data_sources=["my_db"])
```

## æ‰©å±•å¼€å‘

### æ·»åŠ æ–°æ•°æ®æº

1. **åˆ›å»ºæ•°æ®æºç±»**

```python
# src/datasources/mysql_source.py
from .base import DataSource
from src.models.datasource import QueryResponse, QueryMetadata
import time

class MySQLDataSource(DataSource):
    def __init__(self, name: str, host: str, database: str):
        super().__init__(name, "mysql")
        self.host = host
        self.database = database
        self.connection = None
    
    def connect(self) -> bool:
        try:
            import pymysql
            self.connection = pymysql.connect(
                host=self.host,
                database=self.database,
                # ...
            )
            return True
        except Exception as e:
            logger.error(f"è¿æ¥å¤±è´¥: {e}")
            return False
    
    def query(self, query: str, **kwargs) -> QueryResponse:
        start_time = time.time()
        try:
            cursor = self.connection.cursor()
            cursor.execute(query)
            data = cursor.fetchall()
            
            return QueryResponse(
                success=True,
                data=data,
                metadata=QueryMetadata(
                    row_count=len(data),
                    execution_time=time.time() - start_time,
                    data_source_type="mysql",
                ),
            )
        except Exception as e:
            return QueryResponse(
                success=False,
                error=str(e),
                metadata=QueryMetadata(
                    row_count=0,
                    execution_time=time.time() - start_time,
                    data_source_type="mysql",
                ),
            )
```

2. **æ³¨å†Œåˆ° Agent**

```python
# src/agent.py
def register_mysql_database(self, name: str, host: str, database: str):
    from .datasources.mysql_source import MySQLDataSource
    source = MySQLDataSource(name, host, database)
    if source.connect():
        self.analyzer.register_data_source(name, source)
        return True
    return False
```

### è‡ªå®šä¹‰åˆ†æå™¨

```python
# src/analyzers/custom_analyzer.py
class CustomAnalyzer:
    def analyze(self, data, question: str):
        # è‡ªå®šä¹‰åˆ†æé€»è¾‘
        insights = []
        # ... åˆ†æä»£ç 
        return {
            "summary": "...",
            "insights": insights,
        }
```

### æ‰©å±• Prompt æ¨¡æ¿

```python
# config/prompts.py
class CustomPromptTemplates:
    CUSTOM_ANALYSIS = """
    ä½ æ˜¯æ•°æ®åˆ†æä¸“å®¶ï¼Œè¯·åˆ†æä»¥ä¸‹æ•°æ®ï¼š
    
    æ•°æ®: {data}
    é—®é¢˜: {question}
    
    è¯·ç»™å‡ºè¯¦ç»†åˆ†æã€‚
    """
```

### æ·»åŠ æ–°çš„å›¾è¡¨ç±»å‹

1. **æ‰©å±•æšä¸¾**

```python
# src/models/analysis.py
class VisualizationType(str, Enum):
    # ... ç°æœ‰ç±»å‹
    CUSTOM = "custom"  # æ–°å¢ç±»å‹
```

2. **å®ç°æ¸²æŸ“é€»è¾‘**

```python
# src/analyzers/data_analyzer.py
def create_custom_chart(self, data, config):
    import plotly.graph_objects as go
    
    fig = go.Figure()
    # ... è‡ªå®šä¹‰å›¾è¡¨é€»è¾‘
    
    return fig
```

## æ•°æ®æ¨¡å‹

### é…ç½®æ¨¡å‹

```python
from src.models.config import (
    SystemSettings,    # ç³»ç»Ÿé…ç½®
    LLMConfig,        # LLM é…ç½®
    EmbeddingConfig,  # Embedding é…ç½®
)

# è‡ªåŠ¨éªŒè¯å’Œç±»å‹è½¬æ¢
settings = SystemSettings()
llm_config = settings.get_llm_config()
```

### æ•°æ®æºæ¨¡å‹

```python
from src.models.datasource import (
    DataSourceConfig,   # åŸºç¡€é…ç½®
    SQLiteConfig,       # SQLite é…ç½®
    FileConfig,         # æ–‡ä»¶é…ç½®
    QueryRequest,       # æŸ¥è¯¢è¯·æ±‚
    QueryResponse,      # æŸ¥è¯¢å“åº”
    QueryMetadata,      # å…ƒæ•°æ®
)
```

### åˆ†ææ¨¡å‹

```python
from src.models.analysis import (
    AnalysisRequest,    # åˆ†æè¯·æ±‚
    AnalysisResponse,   # åˆ†æå“åº”
    ChartConfig,        # å›¾è¡¨é…ç½®
    VisualizationType,  # å›¾è¡¨ç±»å‹
    ChatSession,        # ä¼šè¯ç®¡ç†
)
```

è¯¦ç»†è¯´æ˜è§ [Pydantic æ•°æ®éªŒè¯æŒ‡å—](PYDANTIC_GUIDE.md)

## æœ€ä½³å®è·µ

### 1. ä½¿ç”¨ Pydantic æ¨¡å‹

âœ… **æ¨è**
```python
from src.models.datasource import QueryResponse

def query_data(sql: str) -> QueryResponse:
    # è¿”å›éªŒè¯è¿‡çš„æ¨¡å‹
    return QueryResponse(
        success=True,
        data=[...],
        metadata=QueryMetadata(...)
    )
```

âŒ **ä¸æ¨è**
```python
def query_data(sql: str) -> dict:
    # è¿”å›åŸå§‹å­—å…¸ï¼Œæ— éªŒè¯
    return {"success": True, "data": [...]}
```

### 2. é”™è¯¯å¤„ç†

```python
from pydantic import ValidationError

try:
    config = LLMConfig(
        api_key="key",
        temperature=3.0,  # è¶…å‡ºèŒƒå›´
    )
except ValidationError as e:
    logger.error(f"é…ç½®éªŒè¯å¤±è´¥: {e}")
    for error in e.errors():
        print(f"å­—æ®µ: {error['loc']}, é”™è¯¯: {error['msg']}")
```

### 3. æ—¥å¿—è®°å½•

```python
from loguru import logger

logger.info("å¼€å§‹æŸ¥è¯¢")
logger.debug(f"SQL: {sql}")
logger.error(f"æŸ¥è¯¢å¤±è´¥: {e}")
logger.warning("æ•°æ®ä¸ºç©º")
```

### 4. èµ„æºç®¡ç†

```python
# ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨
with datasource:
    result = datasource.query("SELECT * FROM users")
```

### 5. é…ç½®ç®¡ç†

```python
# ç»Ÿä¸€ä½¿ç”¨ settings å®ä¾‹
from config.settings import settings

# è®¿é—®é…ç½®
api_key = settings.llm_api_key
temperature = settings.temperature

# ç¡®ä¿ç›®å½•å­˜åœ¨
settings.ensure_directories()
```

## å¼€å‘å·¥å…·

### è¿è¡Œæµ‹è¯•

```bash
# å•å…ƒæµ‹è¯•ï¼ˆå¾…æ·»åŠ ï¼‰
pytest tests/

# è¿è¡Œç¤ºä¾‹
python examples/pydantic_usage.py
```

### ä»£ç æ£€æŸ¥

```bash
# ç±»å‹æ£€æŸ¥
mypy src/

# ä»£ç æ ¼å¼åŒ–
black src/
```

### è°ƒè¯•

```python
# åœ¨ä»£ç ä¸­æ·»åŠ æ–­ç‚¹
import pdb; pdb.set_trace()

# æˆ–ä½¿ç”¨ IDE æ–­ç‚¹è°ƒè¯•
```

## API å‚è€ƒ

### Agent API

```python
agent = DataAnalystAgent(max_history_turns=10)

# æ³¨å†Œæ•°æ®æº
agent.register_sqlite_database(name, db_path)
agent.register_file_datasource(name, file_path)

# å¯¹è¯
response = agent.chat(question, data_sources)

# æ¸…ç©ºå†å²
agent.clear_history()
```

### DataSource API

```python
# è¿æ¥
datasource.connect()

# æŸ¥è¯¢
response: QueryResponse = datasource.query(query)

# è·å– Schema
schema: str = datasource.get_schema()

# å…³é—­
datasource.close()
```

## æ€§èƒ½ä¼˜åŒ–

1. **ç¼“å­˜æŸ¥è¯¢ç»“æœ** - é¿å…é‡å¤æŸ¥è¯¢
2. **é™åˆ¶è¿”å›æ•°æ®é‡** - ä½¿ç”¨ LIMIT å­å¥
3. **å¼‚æ­¥å¤„ç†** - å¯¹äºé•¿æ—¶é—´æŸ¥è¯¢ä½¿ç”¨å¼‚æ­¥
4. **æ‰¹é‡æ“ä½œ** - åˆå¹¶å¤šä¸ªå°æŸ¥è¯¢

## å¸¸è§é—®é¢˜

### Q: å¦‚ä½•æ·»åŠ è‡ªå®šä¹‰éªŒè¯ï¼Ÿ

ä½¿ç”¨ Pydantic çš„ `@field_validator`:

```python
from pydantic import BaseModel, field_validator

class CustomConfig(BaseModel):
    value: int
    
    @field_validator("value")
    @classmethod
    def validate_value(cls, v):
        if v < 0:
            raise ValueError("å€¼å¿…é¡»å¤§äº 0")
        return v
```

### Q: å¦‚ä½•æ”¯æŒæ–°çš„ LLM?

åªéœ€é…ç½®å…¼å®¹ OpenAI API çš„ endpointï¼š

```bash
LLM_API_BASE=https://your-llm-endpoint/v1
LLM_MODEL=your-model-name
```

### Q: å¦‚ä½•è°ƒè¯• SQL ç”Ÿæˆï¼Ÿ

æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶ `logs/` ä¸­çš„è¯¦ç»† SQL è¯­å¥ã€‚

## ğŸ“š å‚è€ƒèµ„æº

- [Pydantic æ–‡æ¡£](https://docs.pydantic.dev/)
- [LlamaIndex æ–‡æ¡£](https://docs.llamaindex.ai/)
- [Gradio æ–‡æ¡£](https://www.gradio.app/docs/)
- [Plotly æ–‡æ¡£](https://plotly.com/python/)

## ğŸ¤ è´¡çŒ®æŒ‡å—

1. Fork é¡¹ç›®
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some feature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. å¼€å¯ Pull Request
