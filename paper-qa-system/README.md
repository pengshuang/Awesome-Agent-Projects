# ğŸ“š Academic Paper Intelligent Q&A System

> Intelligent paper reading assistant based on RAG technology, supporting multi-turn conversations, Web UI, and web search to help you understand academic papers easily

[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![LlamaIndex](https://img.shields.io/badge/Powered%20by-LlamaIndex-orange)](https://www.llamaindex.ai/)
[![Pydantic](https://img.shields.io/badge/Config-Pydantic-blue)](https://docs.pydantic.dev/)

English | [ä¸­æ–‡](README_CN.md)


---

## ğŸ“– Documentation Navigation

| Document | Description |
|----------|-------------|
| [README.md](README.md) | **Project Overview & Quick Start** |
| [docs/USER_GUIDE_EN.md](docs/USER_GUIDE_EN.md) | **User Guide** (Configuration, UI usage, FAQ) |
| [docs/DEVELOPER_GUIDE_EN.md](docs/DEVELOPER_GUIDE_EN.md) | **Developer Guide** (Architecture, API, Pydantic config) |

---

## ğŸ–¼ï¸ Web UI

![ui-1](imgs/ui.png)

---

## ğŸŒŸ Core Features

- ğŸ’¬ **Multi-turn Dialogue** - Context memory, continuous questioning
- ğŸ§  **RAG Q&A** - Precise answers based on vector retrieval
- ğŸŒ **Web UI** - Beautiful and easy to use, supports Markdown rendering
- ğŸ“„ **Multi-format** - PDF, DOCX, Markdown, TXT
- ğŸ” **Semantic Retrieval** - Vector database, millisecond response
- ğŸ“Š **Source Tracing** - Answers annotated with original sources
- ğŸŒ **Web Search** - DuckDuckGo for latest information

---

## ğŸš€ Quick Start

```bash
# 1. Clone and enter directory
git clone https://github.com/pengshuang/Awesome-Agent-Projects.git
cd Awesome-Agent-Projects/academic-paper-qa

# 2. Install dependencies
pip install -r requirements.txt

# 3. Configure API Key
cp .env.example .env
# Edit .env and fill in your LLM API Key

# 4. Launch Web UI
./start_web_multi.sh
# or: python web_ui_multi_turn.py
# Visit http://127.0.0.1:7860
```

**First Use**: Place papers (PDF/DOCX/TXT) in `data/documents/` folder, then build index in the Web UI.

---

## ğŸ’¬ Multi-turn Dialogue vs Single-turn Q&A

### ğŸ¯ When to Use Multi-turn Dialogue?

**Suitable Scenarios:**
- ğŸ“– **In-depth Learning**: Gradually understand complex concepts, continuous questioning
- ğŸ” **Literature Review**: Compare multiple papers, associate contexts
- ğŸ’­ **Academic Discussion**: Brainstorming, in-depth analysis
- ğŸ“ **Paper Interpretation**: Complete understanding of paper structure and content

**Dialogue Example:**
```
ğŸ‘¤: What is Transformer?
ğŸ¤–: Transformer is a neural network architecture based on attention mechanism...

ğŸ‘¤: What are its applications?              # â† Automatically understands "its" refers to Transformer
ğŸ¤–: Transformer is mainly applied in NLP, CV and other fields...

ğŸ‘¤: Can you elaborate on NLP applications?  # â† Continue in-depth based on context
```

### âš¡ When to Use Single-turn Q&A?

**Suitable Scenarios:**
- ğŸ” **Quick Query**: Look up definitions, concepts, formulas
- ğŸ“ **Independent Questions**: Each question is independent without correlation
- ğŸ’¡ **Keyword Extraction**: Extract key information

**Q&A Example:**
```
Q: What is the full name of Transformer?
A: "Attention is All You Need"

Q: What is BERT?
A: BERT (Bidirectional Encoder Representations from Transformers)...
```

---

## ğŸ’¡ Usage Examples

### Add Documents and Ask Questions

```bash
# 1. Add paper
cp paper.pdf ./data/documents/

# 2. Start Web UI
./start_web_multi.sh

# 3. Build index â†’ Start asking
```

### Dialogue Example

```
ğŸ‘¤: What is the main contribution of this paper?
ğŸ¤–: The main contribution is proposing the Transformer architecture...

ğŸ‘¤: What problem does it solve?
ğŸ¤–: Transformer solves the sequential dependency problem of RNN...
```

Detailed instructions: [User Guide](docs/USER_GUIDE_EN.md)

---

## ğŸ› ï¸ Tech Stack

- **RAG Framework**: LlamaIndex
- **Vector Database**: Chroma
- **Embedding**: BAAI/bge-small-zh-v1.5
- **LLM**: OpenAI / DeepSeek / Moonshot
- **Web UI**: Gradio 4.0+

---

## â“ FAQ

**Q: What file formats are supported?**  
A: PDF, DOCX, Markdown, TXT

**Q: Is GPU required?**  
A: No, CPU is sufficient

**Q: Are local models supported?**  
A: Embedding supports local models, LLM requires API

**Q: How to adjust history turns?**  
A: See [User Guide - History Control](docs/USER_GUIDE_EN.md#history-control)

**Q: How many papers can be loaded at once?**  
A: Theoretically unlimited, practically limited by memory. Tested with 100+ papers with good performance.

More questions: [User Guide - Troubleshooting](docs/USER_GUIDE_EN.md#troubleshooting)

---

## ğŸ“„ License

MIT License
