# ============================================================================
# 学术论文智能问答系统 - 配置文件模板
# 复制此文件为 .env 并填入你的配置
# ============================================================================

# ============================================================================
# 🚀 快速开始 - 最小化配置（新手必填）
# ============================================================================

# LLM API Key（必填）
LLM_API_KEY=your_api_key_here

# LLM API Base URL（必填）
LLM_API_BASE=https://api.moonshot.cn/v1

# LLM 模型名称（必填）
LLM_MODEL=moonshot-v1-8k

# Embedding 提供商（huggingface/openai/qwen3）
EMBEDDING_PROVIDER=huggingface

# ============================================================================
# 📝 LLM 配置详解
# ============================================================================

# 温度参数 (0.0-2.0): 越低越确定，越高越随机
TEMPERATURE=0.1

# 最大输出 tokens（可选）
# MAX_TOKENS=2000

# API 请求超时（秒）
TIMEOUT=60

# ============================================================================
# 🌐 LLM 提供商配置示例
# ============================================================================

# 根据需要选择以下配置之一：

# Moonshot (Kimi) - 国内快速 | https://platform.moonshot.cn/
# LLM_API_KEY=your_moonshot_key
# LLM_API_BASE=https://api.moonshot.cn/v1
# LLM_MODEL=moonshot-v1-8k

# DeepSeek - 性价比高 | https://platform.deepseek.com/
# LLM_API_KEY=your_deepseek_key
# LLM_API_BASE=https://api.deepseek.com/v1
# LLM_MODEL=deepseek-chat

# OpenAI - 需国际网络 | https://platform.openai.com/
# LLM_API_KEY=sk-your_openai_key
# LLM_API_BASE=https://api.openai.com/v1
# LLM_MODEL=gpt-3.5-turbo

# 通义千问 (Qwen) | https://dashscope.aliyun.com/
# LLM_API_KEY=your_qwen_key
# LLM_API_BASE=https://dashscope.aliyuncs.com/compatible-mode/v1
# LLM_MODEL=qwen-turbo

# ============================================================================
# 🎯 Embedding 模型配置
# ============================================================================

# Embedding 模型名称（根据提供商选择对应模型）
EMBEDDING_MODEL_NAME=text-embedding-v3

# Embedding API Key（使用 openai/qwen3 时需要）
EMBEDDING_API_KEY=your_dashscope_key

# 批处理大小
EMBEDDING_BATCH_SIZE=10

# 提供商选项：
# huggingface: EMBEDDING_MODEL_NAME=BAAI/bge-small-zh-v1.5 (本地免费)
# openai: EMBEDDING_MODEL_NAME=text-embedding-3-small (云端付费)
# qwen3: EMBEDDING_MODEL_NAME=text-embedding-v3 (阿里云)

# ============================================================================
# ⚙️ RAG 核心参数
# ============================================================================

# 文本分块大小（字符数，推荐 512-1024）
CHUNK_SIZE=512

# 分块重叠大小
CHUNK_OVERLAP=50

# 检索文档数量（Top-K，推荐 5-10）
RETRIEVAL_TOP_K=5

# 相似度阈值（0.0-1.0，推荐 0.6-0.8）
RETRIEVAL_SIMILARITY_THRESHOLD=0.7

# ============================================================================
# 💬 多轮对话配置
# ============================================================================

# 最大历史轮数（0=单轮，5-10=推荐，15+=长对话）
MAX_HISTORY_TURNS=10

# ============================================================================
# 🌐 网络搜索配置
# ============================================================================

# 是否启用网络搜索
ENABLE_WEB_SEARCH=true

# 网络搜索结果数量
WEB_SEARCH_MAX_RESULTS=3

# ============================================================================
# 💾 数据目录配置
# ============================================================================

# 文档目录（存放 PDF/DOCX/TXT 文档）
DOCUMENTS_DIR=./data/documents

# 索引目录（向量存储）
INDEX_DIR=./data/vector_store

# 处理后的文档缓存
PROCESSED_DIR=./data/processed

# 日志目录
LOG_DIR=./logs

# ============================================================================
# 🔧 系统配置
# ============================================================================

# 日志级别: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO

# 是否启用缓存
ENABLE_CACHE=true

# 缓存目录
CACHE_DIR=./data/cache

# ============================================================================
# 🚀 Web UI 配置
# ============================================================================

# Gradio 服务端口
GRADIO_PORT=7860

# 是否公开分享（生成公开链接）
GRADIO_SHARE=false

# ============================================================================
# 📊 性能优化配置（高级）
# ============================================================================

# 向量检索批处理大小
# VECTOR_BATCH_SIZE=100

# 是否使用 GPU 加速（需要 CUDA）
# USE_GPU=false

# ============================================================================
# 💡 使用提示
# ============================================================================
# 1. 新手只需配置「快速开始」部分的 4 项即可运行
# 2. 首次使用本地 Embedding 会自动下载模型（约 1GB）
# 3. 详细配置说明见：docs/USER_GUIDE.md
# ============================================================================
