"""
çŸ¥è¯†åº“æ•°æ®æº
åŸºäºå‘é‡æ£€ç´¢çš„çŸ¥è¯†åº“
"""

from pathlib import Path
from typing import Any, Dict, Optional, List
from loguru import logger

from llama_index.core import (
    VectorStoreIndex,
    SimpleDirectoryReader,
    StorageContext,
    load_index_from_storage,
)

from .base import DataSource
from config.settings import SystemConfig


class KnowledgeBaseSource(DataSource):
    """çŸ¥è¯†åº“æ•°æ®æºï¼ˆåŸºäºå‘é‡æ£€ç´¢ï¼‰"""
    
    def __init__(self, name: str, kb_dir: Optional[str] = None):
        """
        åˆå§‹åŒ–çŸ¥è¯†åº“æ•°æ®æº
        
        Args:
            name: æ•°æ®æºåç§°
            kb_dir: çŸ¥è¯†åº“æ–‡æ¡£ç›®å½•ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®ä¸­çš„è·¯å¾„ï¼‰
        """
        super().__init__(name, "knowledge_base")
        self.kb_dir = Path(kb_dir) if kb_dir else SystemConfig.KNOWLEDGE_BASE_DIR
        self.index_dir = SystemConfig.CACHE_DIR / f"kb_index_{name}"
        self.index: Optional[VectorStoreIndex] = None
        self.documents: List = []
        
    def connect(self) -> bool:
        """åŠ è½½æˆ–æ„å»ºçŸ¥è¯†åº“ç´¢å¼•"""
        try:
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            self.kb_dir.mkdir(parents=True, exist_ok=True)
            self.index_dir.mkdir(parents=True, exist_ok=True)
            
            # å°è¯•ä»ç£ç›˜åŠ è½½ç´¢å¼•
            if self._index_exists():
                logger.info(f"ğŸ“š æ­£åœ¨ä»ç£ç›˜åŠ è½½çŸ¥è¯†åº“ç´¢å¼•: {self.index_dir}")
                storage_context = StorageContext.from_defaults(
                    persist_dir=str(self.index_dir)
                )
                self.index = load_index_from_storage(storage_context)
                logger.info(f"âœ… çŸ¥è¯†åº“ç´¢å¼•åŠ è½½æˆåŠŸ")
                return True
            else:
                # æ„å»ºæ–°ç´¢å¼•
                return self._build_index()
                
        except Exception as e:
            logger.error(f"âŒ çŸ¥è¯†åº“è¿æ¥å¤±è´¥: {e}")
            return False
    
    def _index_exists(self) -> bool:
        """æ£€æŸ¥ç´¢å¼•æ˜¯å¦å­˜åœ¨"""
        required_files = ['docstore.json', 'index_store.json']
        return all((self.index_dir / f).exists() for f in required_files)
    
    def _build_index(self) -> bool:
        """æ„å»ºçŸ¥è¯†åº“ç´¢å¼•"""
        try:
            logger.info(f"ğŸ“– æ­£åœ¨æ„å»ºçŸ¥è¯†åº“ç´¢å¼•...")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æ–‡æ¡£
            doc_files = list(self.kb_dir.glob('**/*'))
            doc_files = [f for f in doc_files if f.is_file() and not f.name.startswith('.')]
            
            if not doc_files:
                logger.warning(f"âš ï¸  çŸ¥è¯†åº“ç›®å½•ä¸ºç©º: {self.kb_dir}")
                logger.info(f"æç¤ºï¼šè¯·å°†æ–‡æ¡£æ”¾å…¥ {self.kb_dir} ç›®å½•")
                # åˆ›å»ºç©ºç´¢å¼•
                from llama_index.core.schema import Document
                self.documents = [Document(text="çŸ¥è¯†åº“ä¸ºç©ºï¼Œè¯·æ·»åŠ æ–‡æ¡£")]
                self.index = VectorStoreIndex.from_documents(self.documents)
                return True
            
            # åŠ è½½æ–‡æ¡£
            logger.info(f"ğŸ“„ æ­£åœ¨åŠ è½½ {len(doc_files)} ä¸ªæ–‡æ¡£...")
            reader = SimpleDirectoryReader(
                input_dir=str(self.kb_dir),
                recursive=True,
            )
            self.documents = reader.load_data()
            
            logger.info(f"âœ… å·²åŠ è½½ {len(self.documents)} ä¸ªæ–‡æ¡£å—")
            
            # æ„å»ºç´¢å¼•
            logger.info(f"ğŸ”¨ æ­£åœ¨æ„å»ºå‘é‡ç´¢å¼•...")
            self.index = VectorStoreIndex.from_documents(self.documents)
            
            # æŒä¹…åŒ–ç´¢å¼•
            logger.info(f"ğŸ’¾ æ­£åœ¨ä¿å­˜ç´¢å¼•åˆ°ç£ç›˜...")
            self.index.storage_context.persist(persist_dir=str(self.index_dir))
            
            logger.info(f"âœ… çŸ¥è¯†åº“ç´¢å¼•æ„å»ºæˆåŠŸ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ„å»ºçŸ¥è¯†åº“ç´¢å¼•å¤±è´¥: {e}")
            return False
    
    def query(self, query: str, **kwargs) -> Dict[str, Any]:
        """
        æŸ¥è¯¢çŸ¥è¯†åº“
        
        Args:
            query: æŸ¥è¯¢é—®é¢˜
            **kwargs: é¢å¤–å‚æ•°
                - top_k: è¿”å›top kä¸ªç»“æœï¼ˆé»˜è®¤5ï¼‰
                - similarity_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼
            
        Returns:
            æŸ¥è¯¢ç»“æœ
        """
        if self.index is None:
            return {
                "success": False,
                "data": None,
                "error": "çŸ¥è¯†åº“æœªåˆå§‹åŒ–",
                "metadata": {}
            }
        
        try:
            top_k = kwargs.get('top_k', 5)
            
            logger.info(f"ğŸ” æ­£åœ¨çŸ¥è¯†åº“ä¸­æ£€ç´¢: {query}")
            
            # åˆ›å»ºæŸ¥è¯¢å¼•æ“
            query_engine = self.index.as_query_engine(
                similarity_top_k=top_k,
            )
            
            # æ‰§è¡ŒæŸ¥è¯¢
            response = query_engine.query(query)
            
            # æå–æ£€ç´¢åˆ°çš„èŠ‚ç‚¹
            retrieved_nodes = []
            if hasattr(response, 'source_nodes'):
                for node in response.source_nodes:
                    retrieved_nodes.append({
                        'text': node.node.text,
                        'score': node.score,
                        'metadata': node.node.metadata,
                    })
            
            logger.info(f"âœ… æ£€ç´¢æˆåŠŸï¼Œæ‰¾åˆ° {len(retrieved_nodes)} ä¸ªç›¸å…³æ–‡æ¡£")
            
            return {
                "success": True,
                "data": {
                    "answer": str(response),
                    "retrieved_docs": retrieved_nodes,
                },
                "error": None,
                "metadata": {
                    "query": query,
                    "top_k": top_k,
                    "doc_count": len(retrieved_nodes),
                }
            }
            
        except Exception as e:
            error_msg = f"çŸ¥è¯†åº“æŸ¥è¯¢å¤±è´¥: {str(e)}"
            logger.error(f"âŒ {error_msg}")
            return {
                "success": False,
                "data": None,
                "error": error_msg,
                "metadata": {}
            }
    
    def get_schema(self) -> Optional[str]:
        """
        è·å–çŸ¥è¯†åº“ä¿¡æ¯
        
        Returns:
            çŸ¥è¯†åº“æè¿°å­—ç¬¦ä¸²
        """
        try:
            schema_parts = []
            
            schema_parts.append(f"çŸ¥è¯†åº“: {self.name}")
            schema_parts.append(f"æ–‡æ¡£ç›®å½•: {self.kb_dir}")
            schema_parts.append(f"ç´¢å¼•ç›®å½•: {self.index_dir}")
            
            # ç»Ÿè®¡æ–‡æ¡£æ•°é‡
            doc_files = list(self.kb_dir.glob('**/*'))
            doc_files = [f for f in doc_files if f.is_file() and not f.name.startswith('.')]
            
            schema_parts.append(f"æ–‡æ¡£æ•°é‡: {len(doc_files)}")
            schema_parts.append(f"æ–‡æ¡£å—æ•°é‡: {len(self.documents)}")
            
            if doc_files:
                schema_parts.append("\næ–‡æ¡£åˆ—è¡¨:")
                schema_parts.append("-" * 50)
                for doc_file in doc_files[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
                    relative_path = doc_file.relative_to(self.kb_dir)
                    schema_parts.append(f"  - {relative_path}")
                
                if len(doc_files) > 10:
                    schema_parts.append(f"  ... è¿˜æœ‰ {len(doc_files) - 10} ä¸ªæ–‡æ¡£")
            
            return "\n".join(schema_parts)
            
        except Exception as e:
            logger.error(f"âŒ è·å–çŸ¥è¯†åº“ä¿¡æ¯å¤±è´¥: {e}")
            return None
    
    def rebuild_index(self) -> bool:
        """é‡å»ºç´¢å¼•"""
        logger.info(f"ğŸ”„ æ­£åœ¨é‡å»ºçŸ¥è¯†åº“ç´¢å¼•...")
        return self._build_index()
    
    def close(self):
        """æ¸…ç†èµ„æº"""
        self.index = None
        self.documents = []
        logger.info(f"ğŸ”’ å·²é‡Šæ”¾çŸ¥è¯†åº“èµ„æº: {self.name}")
