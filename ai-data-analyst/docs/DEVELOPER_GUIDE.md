# å¼€å‘æŒ‡å—

> é¢å‘å¸Œæœ›è¿›è¡ŒäºŒæ¬¡å¼€å‘çš„å¼€å‘è€…

---

## ğŸ“ é¡¹ç›®ç»“æ„

```
ai-data-analyst/
â”œâ”€â”€ config/                  # é…ç½®æ¨¡å—
â”‚   â”œâ”€â”€ settings.py         # ç³»ç»Ÿé…ç½®
â”‚   â”œâ”€â”€ llm_config.py       # LLM é…ç½®
â”‚   â””â”€â”€ prompts.py          # Prompt æ¨¡æ¿ç®¡ç†
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agent.py            # æ ¸å¿ƒ Agent
â”‚   â”œâ”€â”€ datasources/        # æ•°æ®æºé€‚é…å™¨
â”‚   â”‚   â”œâ”€â”€ base.py        # æ•°æ®æºåŸºç±»
â”‚   â”‚   â”œâ”€â”€ sqlite_source.py
â”‚   â”‚   â”œâ”€â”€ file_source.py
â”‚   â”‚   â”œâ”€â”€ knowledge_base.py
â”‚   â”‚   â””â”€â”€ web_source.py
â”‚   â”œâ”€â”€ analyzers/          # åˆ†æå¼•æ“
â”‚   â”‚   â””â”€â”€ data_analyzer.py
â”‚   â”œâ”€â”€ tools/              # å·¥å…·æ¨¡å—
â”‚   â”‚   â””â”€â”€ nl2sql.py
â”‚   â””â”€â”€ utils/              # å·¥å…·å‡½æ•°
â”‚       â”œâ”€â”€ logger.py
â”‚       â””â”€â”€ helpers.py
â”œâ”€â”€ data/                    # æ•°æ®ç›®å½•
â”œâ”€â”€ logs/                    # æ—¥å¿—ç›®å½•
â”œâ”€â”€ web_ui.py               # Web ç•Œé¢
â””â”€â”€ init_system.py          # ç³»ç»Ÿåˆå§‹åŒ–
```

---

## ğŸ—ï¸ æ ¸å¿ƒæ¶æ„

### æ¨¡å—å…³ç³»

```
Web UI (Gradio)
    â†“
DataAnalystAgent (Agent)
    â†“
DataAnalyzer (åˆ†æå¼•æ“)
    â†“
DataSource (æ•°æ®æºæ¥å£)
    â”œâ”€â”€ SQLiteDataSource
    â”œâ”€â”€ FileDataSource
    â”œâ”€â”€ KnowledgeBaseSource
    â””â”€â”€ WebSearchSource
```

### æ ¸å¿ƒç±»è¯´æ˜

#### 1. DataAnalystAgent (`src/agent.py`)

**èŒè´£**: æ ¸å¿ƒå¯¹è¯ä»£ç†ï¼Œç®¡ç†å¤šè½®å¯¹è¯å’Œæ•°æ®æº

**å…³é”®æ–¹æ³•**:
```python
class DataAnalystAgent:
    def __init__(self, max_history_turns: int = 10)
    def register_sqlite_database(self, name: str, db_path: str) -> bool
    def register_file(self, name: str, file_path: str) -> bool
    def chat(self, message: str, source_name: Optional[str] = None) -> str
    def clear_history()
```

#### 2. DataSource (`src/datasources/base.py`)

**èŒè´£**: æ•°æ®æºåŸºç±»ï¼Œå®šä¹‰ç»Ÿä¸€æ¥å£

**æ¥å£å®šä¹‰**:
```python
class DataSource(ABC):
    @abstractmethod
    def connect(self) -> bool
    
    @abstractmethod
    def query(self, query: str, **kwargs) -> Dict[str, Any]
    
    @abstractmethod
    def get_schema(self) -> Optional[str]
    
    @abstractmethod
    def close()
```

#### 3. DataAnalyzer (`src/analyzers/data_analyzer.py`)

**èŒè´£**: æ•°æ®åˆ†æå¼•æ“

**å…³é”®æ–¹æ³•**:
```python
class DataAnalyzer:
    def analyze_single_source(self, question: str, source_name: str) -> Dict
    def analyze_multi_sources(self, question: str, source_names: List[str]) -> Dict
```

#### 4. PromptTemplates (`config/prompts.py`)

**èŒè´£**: ç»Ÿä¸€ç®¡ç†æ‰€æœ‰ LLM Prompt

**æ¨¡æ¿åˆ†ç±»**:
- `SYSTEM_DEFAULT` - ç³»ç»Ÿæç¤ºè¯
- `NL2SQL_TEMPLATE` - SQL ç”Ÿæˆ
- `DATA_ANALYSIS_TEMPLATE` - æ•°æ®åˆ†æ
- `MULTI_SOURCE_ANALYSIS` - å¤šæºåˆ†æ

---

## ğŸ”§ äºŒæ¬¡å¼€å‘

### æ·»åŠ æ–°æ•°æ®æº

#### æ­¥éª¤ 1: åˆ›å»ºæ•°æ®æºç±»

åœ¨ `src/datasources/` åˆ›å»ºæ–°æ–‡ä»¶ï¼š

```python
# src/datasources/my_source.py
from .base import DataSource
from typing import Any, Dict, Optional
from loguru import logger

class MyDataSource(DataSource):
    """è‡ªå®šä¹‰æ•°æ®æº"""
    
    def __init__(self, name: str, connection_params: Dict):
        super().__init__(name, "my_custom_type")
        self.params = connection_params
        self.connection = None
    
    def connect(self) -> bool:
        """å»ºç«‹è¿æ¥"""
        try:
            # å®ç°è¿æ¥é€»è¾‘
            self.connection = establish_connection(self.params)
            logger.info(f"âœ… å·²è¿æ¥åˆ° {self.name}")
            return True
        except Exception as e:
            logger.error(f"âŒ è¿æ¥å¤±è´¥: {e}")
            return False
    
    def query(self, query: str, **kwargs) -> Dict[str, Any]:
        """æ‰§è¡ŒæŸ¥è¯¢"""
        try:
            result = self.connection.execute(query)
            return {
                "success": True,
                "data": result,
                "error": None,
                "metadata": {"row_count": len(result)}
            }
        except Exception as e:
            return {
                "success": False,
                "data": None,
                "error": str(e),
                "metadata": {}
            }
    
    def get_schema(self) -> Optional[str]:
        """è¿”å›æ•°æ®ç»“æ„æè¿°"""
        return "å­—æ®µ1: ç±»å‹\nå­—æ®µ2: ç±»å‹..."
    
    def close(self):
        """å…³é—­è¿æ¥"""
        if self.connection:
            self.connection.close()
```

#### æ­¥éª¤ 2: åœ¨ Agent ä¸­æ·»åŠ æ³¨å†Œæ–¹æ³•

```python
# src/agent.py
def register_my_datasource(self, name: str, **params) -> bool:
    """æ³¨å†Œè‡ªå®šä¹‰æ•°æ®æº"""
    try:
        source = MyDataSource(name, params)
        if source.connect():
            self.analyzer.register_data_source(name, source)
            return True
        return False
    except Exception as e:
        logger.error(f"æ³¨å†Œå¤±è´¥: {e}")
        return False
```

#### æ­¥éª¤ 3: åœ¨ Web UI ä¸­æ·»åŠ ç•Œé¢

```python
# web_ui.py
def register_my_source(name: str, param1: str, param2: str):
    """Web UI å›è°ƒ"""
    if not INITIALIZED:
        return "âŒ è¯·å…ˆåˆå§‹åŒ–ç³»ç»Ÿ"
    
    success = AGENT.register_my_datasource(
        name=name,
        param1=param1,
        param2=param2
    )
    
    if success:
        return f"## âœ… æ³¨å†ŒæˆåŠŸ\n\næ•°æ®æºåç§°: {name}"
    else:
        return "âŒ æ³¨å†Œå¤±è´¥"

# æ·»åŠ  Gradio ç»„ä»¶
with gr.Column():
    gr.Markdown("### è‡ªå®šä¹‰æ•°æ®æº")
    my_name = gr.Textbox(label="åç§°")
    my_param1 = gr.Textbox(label="å‚æ•°1")
    my_param2 = gr.Textbox(label="å‚æ•°2")
    my_register_btn = gr.Button("â• æ³¨å†Œ")
    my_result = gr.Markdown()

my_register_btn.click(
    fn=register_my_source,
    inputs=[my_name, my_param1, my_param2],
    outputs=my_result
)
```

### è‡ªå®šä¹‰ Prompt æ¨¡æ¿

#### æ·»åŠ æ–°æ¨¡æ¿

```python
# config/prompts.py
class PromptTemplates:
    # æ·»åŠ è‡ªå®šä¹‰æ¨¡æ¿
    MY_CUSTOM_TEMPLATE = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„{domain}åˆ†æå¸ˆã€‚

ä»»åŠ¡ï¼š{task}

æ•°æ®ï¼š
{data}

è¦æ±‚ï¼š
1. {requirement1}
2. {requirement2}

è¾“å‡ºï¼š"""

class PromptBuilder:
    @staticmethod
    def build_my_custom_prompt(domain: str, task: str, 
                                data: str, **kwargs) -> str:
        """æ„å»ºè‡ªå®šä¹‰ Prompt"""
        return PromptTemplates.MY_CUSTOM_TEMPLATE.format(
            domain=domain,
            task=task,
            data=data,
            requirement1=kwargs.get("req1", ""),
            requirement2=kwargs.get("req2", "")
        )
```

#### ä½¿ç”¨è‡ªå®šä¹‰æ¨¡æ¿

```python
# åœ¨åˆ†æå¼•æ“æˆ– Agent ä¸­ä½¿ç”¨
from config.prompts import PromptBuilder

prompt = PromptBuilder.build_my_custom_prompt(
    domain="é‡‘è",
    task="åˆ†æè‚¡ç¥¨è¶‹åŠ¿",
    data=stock_data,
    req1="è¯†åˆ«å…³é”®è½¬æŠ˜ç‚¹",
    req2="æä¾›æŠ•èµ„å»ºè®®"
)

response = self.llm.complete(prompt)
```

### æ‰©å±•åˆ†æåŠŸèƒ½

#### æ·»åŠ è‡ªå®šä¹‰åˆ†æå™¨

```python
# src/analyzers/custom_analyzer.py
from typing import Dict, Any
from loguru import logger

class CustomAnalyzer:
    """è‡ªå®šä¹‰åˆ†æå™¨"""
    
    def __init__(self, llm):
        self.llm = llm
    
    def analyze(self, data: Any, question: str) -> Dict[str, Any]:
        """æ‰§è¡Œè‡ªå®šä¹‰åˆ†æ"""
        try:
            # æ„å»º Prompt
            prompt = self._build_prompt(data, question)
            
            # è°ƒç”¨ LLM
            response = self.llm.complete(prompt)
            
            return {
                "success": True,
                "result": response.text,
                "insights": self._extract_insights(response.text)
            }
        except Exception as e:
            logger.error(f"åˆ†æå¤±è´¥: {e}")
            return {"success": False, "error": str(e)}
    
    def _build_prompt(self, data, question):
        """æ„å»ºåˆ†æ Prompt"""
        return f"æ•°æ®: {data}\n\né—®é¢˜: {question}\n\nåˆ†æ:"
    
    def _extract_insights(self, text):
        """æå–å…³é”®æ´å¯Ÿ"""
        # å®ç°æå–é€»è¾‘
        return []
```

#### é›†æˆåˆ°ç³»ç»Ÿ

```python
# src/agent.py
from src.analyzers.custom_analyzer import CustomAnalyzer

class DataAnalystAgent:
    def __init__(self, max_history_turns: int = 10):
        # ... ç°æœ‰ä»£ç 
        self.custom_analyzer = CustomAnalyzer(self.llm)
    
    def custom_analysis(self, data: Any, question: str) -> str:
        """æ‰§è¡Œè‡ªå®šä¹‰åˆ†æ"""
        result = self.custom_analyzer.analyze(data, question)
        if result["success"]:
            return result["result"]
        else:
            return f"åˆ†æå¤±è´¥: {result['error']}"
```

---

## ğŸ§ª æµ‹è¯•

### å•å…ƒæµ‹è¯•ç¤ºä¾‹

```python
# tests/test_my_source.py
import pytest
from src.datasources.my_source import MyDataSource

def test_my_source_connect():
    """æµ‹è¯•è¿æ¥"""
    source = MyDataSource("test", {"host": "localhost"})
    assert source.connect() == True

def test_my_source_query():
    """æµ‹è¯•æŸ¥è¯¢"""
    source = MyDataSource("test", {"host": "localhost"})
    source.connect()
    result = source.query("SELECT * FROM table")
    assert result["success"] == True
    assert result["data"] is not None
```

### è¿è¡Œæµ‹è¯•

```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
pytest tests/

# è¿è¡Œç‰¹å®šæµ‹è¯•
pytest tests/test_my_source.py

# å¸¦è¦†ç›–ç‡æŠ¥å‘Š
pytest --cov=src tests/
```

---

## ğŸ“Š æ—¥å¿—å’Œè°ƒè¯•

### æ—¥å¿—ç³»ç»Ÿ

æ‰€æœ‰ LLM è°ƒç”¨è‡ªåŠ¨è®°å½•ï¼š

```python
# æ—¥å¿—ä½ç½®
logs/ai_data_analyst_YYYY-MM-DD.log

# æ—¥å¿—å†…å®¹
2024-12-21 10:00:00 | INFO | Prompt: [å®Œæ•´çš„ Prompt]
2024-12-21 10:00:05 | INFO | Response: [LLM å“åº”]
```

### æ·»åŠ è‡ªå®šä¹‰æ—¥å¿—

```python
from loguru import logger

# ä¸åŒçº§åˆ«çš„æ—¥å¿—
logger.debug("è°ƒè¯•ä¿¡æ¯")
logger.info("å¸¸è§„ä¿¡æ¯")
logger.warning("è­¦å‘Šä¿¡æ¯")
logger.error("é”™è¯¯ä¿¡æ¯")

# å¸¦ä¸Šä¸‹æ–‡çš„æ—¥å¿—
logger.info(f"å¤„ç†è¯·æ±‚: {request_id}", extra={"user": user_id})
```

---

## ğŸš€ éƒ¨ç½²

### ç”Ÿäº§ç¯å¢ƒé…ç½®

```bash
# .env.production
LLM_API_KEY=your-production-key
MAX_HISTORY_TURNS=5
LOG_LEVEL=INFO
```

### Docker éƒ¨ç½²ï¼ˆå¯é€‰ï¼‰

```dockerfile
# Dockerfile
FROM python:3.10-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .

ENV GRADIO_SERVER_NAME=0.0.0.0
ENV GRADIO_SERVER_PORT=7860

CMD ["python", "web_ui.py"]
```

```bash
# æ„å»ºå’Œè¿è¡Œ
docker build -t ai-data-analyst .
docker run -p 7860:7860 --env-file .env ai-data-analyst
```

---

## ğŸ“š API å‚è€ƒ

### DataSource æ¥å£

```python
def connect() -> bool
    """å»ºç«‹è¿æ¥ï¼Œè¿”å›æ˜¯å¦æˆåŠŸ"""

def query(query: str, **kwargs) -> Dict[str, Any]
    """æ‰§è¡ŒæŸ¥è¯¢ï¼Œè¿”å›æ ‡å‡†æ ¼å¼ç»“æœ"""
    # è¿”å›: {"success": bool, "data": Any, "error": str, "metadata": dict}

def get_schema() -> Optional[str]
    """è·å–æ•°æ®ç»“æ„æè¿°"""

def close()
    """å…³é—­è¿æ¥ï¼Œé‡Šæ”¾èµ„æº"""
```

### Agent æ¥å£

```python
def chat(message: str, source_name: Optional[str] = None) -> str
    """å¤„ç†ç”¨æˆ·æ¶ˆæ¯ï¼Œè¿”å›å›å¤"""

def clear_history()
    """æ¸…ç©ºå¯¹è¯å†å²"""

def list_data_sources() -> Dict[str, Any]
    """åˆ—å‡ºæ‰€æœ‰æ•°æ®æº"""
```

---

## ğŸ”— ç›¸å…³èµ„æº

- [ğŸ“– åŠŸèƒ½ä»‹ç»](FEATURES.md) - äº†è§£æ‰€æœ‰åŠŸèƒ½
- [ğŸ‘¤ ç”¨æˆ·æŒ‡å—](USER_GUIDE.md) - ä½¿ç”¨æ•™ç¨‹
- [LlamaIndex æ–‡æ¡£](https://docs.llamaindex.ai/) - LLM æ¡†æ¶
- [Gradio æ–‡æ¡£](https://www.gradio.app/docs/) - UI æ¡†æ¶

---

## ğŸ’¡ æœ€ä½³å®è·µ

### ä»£ç è§„èŒƒ

- ä½¿ç”¨ç±»å‹æ³¨è§£
- æ·»åŠ æ–‡æ¡£å­—ç¬¦ä¸²
- éµå¾ª PEP 8
- é”™è¯¯å¤„ç†å®Œæ•´

### Prompt è®¾è®¡

- æ˜ç¡®ä»»åŠ¡ç›®æ ‡
- æä¾›ç¤ºä¾‹
- åˆ†æ­¥éª¤æŒ‡å¯¼
- è¾“å‡ºæ ¼å¼åŒ–

### æ€§èƒ½ä¼˜åŒ–

- ç¼“å­˜å¸¸ç”¨æŸ¥è¯¢
- å¼‚æ­¥å¤„ç†IO
- é™åˆ¶LLMè°ƒç”¨
- æ•°æ®åˆ†æ‰¹å¤„ç†

---

## ğŸ¤ è´¡çŒ®æŒ‡å—

1. Fork é¡¹ç›®
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯
3. æäº¤ä»£ç 
4. ç¼–å†™æµ‹è¯•
5. æäº¤ Pull Request

æ¬¢è¿è´¡çŒ®ï¼
- å•æ•°æ®æºåˆ†æ
- å¤šæ•°æ®æºèåˆåˆ†æ
- è°ƒç”¨ LLM ç”Ÿæˆåˆ†æç»“æœ

**å…³é”®æ–¹æ³•**ï¼š
```python
class DataAnalyzer:
    def analyze_single_source(self, question: str, source_name: str, **kwargs) -> Dict[str, Any]
    def analyze_multi_sources(self, question: str, source_names: List[str], **kwargs) -> Dict[str, Any]
```

#### 4. NL2SQL å·¥å…·ï¼ˆ`src/tools/nl2sql.py`ï¼‰

`NL2SQLConverter` è´Ÿè´£è‡ªç„¶è¯­è¨€åˆ° SQL çš„è½¬æ¢ï¼š

```python
class NL2SQLConverter:
    def convert(self, question: str, database_schema: str, dialect: str = "sqlite", chat_history: Optional[str] = None) -> Dict[str, Any]
    def correct_sql(self, sql: str, error: str, database_schema: str, dialect: str = "sqlite") -> Dict[str, Any]
```

#### 5. Prompt ç®¡ç†ï¼ˆ`config/prompts.py`ï¼‰

æ‰€æœ‰ Prompt æ¨¡æ¿é›†ä¸­ç®¡ç†ï¼š

```python
class PromptTemplates:
    SYSTEM_DEFAULT = "..."
    NL2SQL_TEMPLATE = "..."
    DATA_ANALYSIS_TEMPLATE = "..."
    # ... æ›´å¤šæ¨¡æ¿

class PromptBuilder:
    @staticmethod
    def build_nl2sql_prompt(...)
    @staticmethod
    def build_data_analysis_prompt(...)
    @staticmethod
    def build_multi_source_prompt(...)
```

## äºŒæ¬¡å¼€å‘æŒ‡å—

### æ·»åŠ æ–°çš„æ•°æ®æº

#### æ­¥éª¤ 1ï¼šåˆ›å»ºæ•°æ®æºç±»

åœ¨ `src/datasources/` ç›®å½•ä¸‹åˆ›å»ºæ–°æ–‡ä»¶ï¼š

```python
from .base import DataSource
from typing import Any, Dict, Optional

class MyDataSource(DataSource):
    """è‡ªå®šä¹‰æ•°æ®æº"""
    
    def __init__(self, name: str, **kwargs):
        super().__init__(name, "my_type")
        # åˆå§‹åŒ–å‚æ•°
    
    def connect(self) -> bool:
        """è¿æ¥æ•°æ®æº"""
        try:
            # å®ç°è¿æ¥é€»è¾‘
            return True
        except Exception as e:
            logger.error(f"è¿æ¥å¤±è´¥: {e}")
            return False
    
    def query(self, query: str, **kwargs) -> Dict[str, Any]:
        """æŸ¥è¯¢æ•°æ®"""
        try:
            # å®ç°æŸ¥è¯¢é€»è¾‘
            return {
                "success": True,
                "data": ...,
                "error": None,
                "metadata": {}
            }
        except Exception as e:
            return {
                "success": False,
                "data": None,
                "error": str(e),
                "metadata": {}
            }
    
    def get_schema(self) -> Optional[str]:
        """è·å–schema"""
        # è¿”å›æ•°æ®æºçš„ç»“æ„æè¿°
        return "æ•°æ®æºç»“æ„ä¿¡æ¯"
    
    def close(self):
        """å…³é—­è¿æ¥"""
        pass
```

#### æ­¥éª¤ 2ï¼šæ³¨å†Œåˆ° Agent

åœ¨ `src/agent.py` ä¸­æ·»åŠ æ³¨å†Œæ–¹æ³•ï¼š

```python
def register_my_datasource(self, name: str, **kwargs) -> bool:
    """æ³¨å†Œè‡ªå®šä¹‰æ•°æ®æº"""
    try:
        my_source = MyDataSource(name, **kwargs)
        if my_source.connect():
            self.analyzer.register_data_source(name, my_source)
            return True
        return False
    except Exception as e:
        logger.error(f"æ³¨å†Œå¤±è´¥: {e}")
        return False
```

#### æ­¥éª¤ 3ï¼šæ·»åŠ åˆ°åˆ†æå™¨

åœ¨ `src/analyzers/data_analyzer.py` çš„ `analyze_single_source` æ–¹æ³•ä¸­æ·»åŠ å¤„ç†é€»è¾‘ï¼š

```python
def analyze_single_source(self, question: str, source_name: str, **kwargs):
    data_source = self.data_sources[source_name]
    
    if isinstance(data_source, MyDataSource):
        return self._analyze_my_datasource(question, data_source, **kwargs)
    # ... å…¶ä»–ç±»å‹
```

#### æ­¥éª¤ 4ï¼šæ›´æ–° UI

åœ¨ `web_ui.py` ä¸­æ·»åŠ æ³¨å†Œç•Œé¢å’ŒæŒ‰é’®ã€‚

### è‡ªå®šä¹‰ Prompt

#### ä¿®æ”¹ç°æœ‰ Prompt

ç¼–è¾‘ `config/prompts.py`ï¼š

```python
class PromptTemplates:
    # ä¿®æ”¹ç°æœ‰æ¨¡æ¿
    NL2SQL_TEMPLATE = """
    ä½ çš„è‡ªå®šä¹‰ Prompt...
    
    æ•°æ®åº“ä¿¡æ¯ï¼š
    {database_schema}
    
    ç”¨æˆ·é—®é¢˜ï¼š{question}
    """
```

#### æ·»åŠ æ–° Prompt

```python
class PromptTemplates:
    # æ·»åŠ æ–°æ¨¡æ¿
    MY_CUSTOM_TEMPLATE = """
    ä½ çš„è‡ªå®šä¹‰ä»»åŠ¡ Prompt...
    
    è¾“å…¥ï¼š{input}
    è¦æ±‚ï¼š{requirements}
    """

class PromptBuilder:
    @staticmethod
    def build_my_custom_prompt(input_data: str, requirements: str) -> str:
        return PromptTemplates.MY_CUSTOM_TEMPLATE.format(
            input=input_data,
            requirements=requirements,
        )
```

### æ‰©å±•åˆ†æåŠŸèƒ½

#### æ·»åŠ æ–°çš„åˆ†æç±»å‹

åœ¨ `src/analyzers/` åˆ›å»ºæ–°åˆ†æå™¨ï¼š

```python
class CustomAnalyzer:
    """è‡ªå®šä¹‰åˆ†æå™¨"""
    
    def __init__(self):
        self.llm = get_llm()
    
    def analyze(self, data: Any, question: str) -> Dict[str, Any]:
        """æ‰§è¡Œåˆ†æ"""
        # æ„å»º Prompt
        prompt = self._build_prompt(data, question)
        
        # è®°å½•æ—¥å¿—
        logger.info("=" * 70)
        logger.info("ğŸ“ [LLMè°ƒç”¨] è‡ªå®šä¹‰åˆ†æ")
        logger.info("=" * 70)
        logger.info(f"è¾“å…¥Prompt:\n{prompt}")
        logger.info("=" * 70)
        
        # è°ƒç”¨ LLM
        response = self.llm.complete(prompt)
        answer = str(response)
        
        logger.info(f"LLMå“åº”:\n{answer}")
        logger.info("=" * 70)
        
        return {
            "success": True,
            "answer": answer,
            "error": None,
        }
```

### è‡ªå®šä¹‰ UI ç»„ä»¶

ä¿®æ”¹ `web_ui.py` æ·»åŠ æ–°çš„ç•Œé¢å…ƒç´ ï¼š

```python
def create_ui():
    with gr.Blocks(...) as demo:
        # æ·»åŠ æ–°çš„ Tab
        with gr.Tab("ğŸ†• æ–°åŠŸèƒ½"):
            gr.Markdown("### è‡ªå®šä¹‰åŠŸèƒ½")
            
            # æ·»åŠ è¾“å…¥ç»„ä»¶
            input_field = gr.Textbox(label="è¾“å…¥")
            output_field = gr.Markdown()
            
            # æ·»åŠ æŒ‰é’®
            submit_btn = gr.Button("æäº¤")
            
            # ç»‘å®šäº‹ä»¶
            submit_btn.click(
                fn=your_function,
                inputs=input_field,
                outputs=output_field
            )
```

### é›†æˆæ–°çš„ LLM

#### æ–¹å¼ 1ï¼šOpenAI å…¼å®¹ API

å¦‚æœæ–° LLM å…¼å®¹ OpenAI API æ ¼å¼ï¼Œåªéœ€é…ç½® `.env`ï¼š

```bash
LLM_API_KEY=your-key
LLM_API_BASE=https://your-llm-endpoint/v1
LLM_MODEL=your-model-name
```

#### æ–¹å¼ 2ï¼šè‡ªå®šä¹‰ LLM ç±»

åœ¨ `config/llm_config.py` ä¸­æ·»åŠ ï¼š

```python
def get_llm(...):
    provider = os.getenv("LLM_PROVIDER", "openai")
    
    if provider == "my_llm":
        from llama_index.llms.my_llm import MyLLM
        return MyLLM(
            api_key=api_key,
            model=model,
            # ... å…¶ä»–å‚æ•°
        )
```

## è°ƒè¯•æŠ€å·§

### 1. æŸ¥çœ‹æ—¥å¿—

æ‰€æœ‰ LLM è°ƒç”¨éƒ½ä¼šè®°å½• Prompt å’Œå“åº”ï¼š

```bash
tail -f logs/ai_data_analyst_$(date +%Y-%m-%d).log
```

### 2. æ–­ç‚¹è°ƒè¯•

ä½¿ç”¨ Python è°ƒè¯•å™¨ï¼š

```python
import pdb; pdb.set_trace()
```

æˆ–ä½¿ç”¨ IDE çš„è°ƒè¯•åŠŸèƒ½ã€‚

### 3. æµ‹è¯•å•ä¸ªæ¨¡å—

åˆ›å»ºæµ‹è¯•è„šæœ¬ï¼š

```python
from src.datasources import SQLiteDataSource

# æµ‹è¯•æ•°æ®æº
db = SQLiteDataSource("test", "data/databases/test.db")
db.connect()
result = db.query("SELECT * FROM users LIMIT 10")
print(result)
```

### 4. Prompt ä¼˜åŒ–

1. æŸ¥çœ‹æ—¥å¿—ä¸­çš„ Prompt
2. å¤åˆ¶åˆ° LLM playground æµ‹è¯•
3. è°ƒæ•´ Prompt æ¨¡æ¿
4. é‡æ–°æµ‹è¯•

## æ€§èƒ½ä¼˜åŒ–

### 1. ç¼“å­˜æœºåˆ¶

å®ç°æŸ¥è¯¢ç»“æœç¼“å­˜ï¼š

```python
from functools import lru_cache

@lru_cache(maxsize=100)
def cached_query(query: str) -> Dict:
    # æ‰§è¡ŒæŸ¥è¯¢
    pass
```

### 2. å¹¶å‘å¤„ç†

ä½¿ç”¨å¼‚æ­¥æˆ–å¤šçº¿ç¨‹å¤„ç†å¤šä¸ªè¯·æ±‚ï¼š

```python
import asyncio

async def process_multiple_queries(queries: List[str]):
    tasks = [process_query(q) for q in queries]
    return await asyncio.gather(*tasks)
```

### 3. æ•°æ®åº“ä¼˜åŒ–

- ä¸ºå¸¸ç”¨æŸ¥è¯¢å­—æ®µæ·»åŠ ç´¢å¼•
- ä½¿ç”¨æŸ¥è¯¢è®¡åˆ’åˆ†æ
- é™åˆ¶è¿”å›æ•°æ®é‡

### 4. LLM è°ƒç”¨ä¼˜åŒ–

- ä½¿ç”¨æ›´å¿«çš„æ¨¡å‹
- æ‰¹å¤„ç†ç›¸ä¼¼è¯·æ±‚
- å®ç°è¯·æ±‚å»é‡

## æµ‹è¯•

### å•å…ƒæµ‹è¯•

åˆ›å»º `tests/` ç›®å½•å¹¶æ·»åŠ æµ‹è¯•ï¼š

```python
import unittest
from src.datasources import SQLiteDataSource

class TestSQLiteDataSource(unittest.TestCase):
    def setUp(self):
        self.db = SQLiteDataSource("test", ":memory:")
        self.db.connect()
    
    def test_query(self):
        result = self.db.query("SELECT 1")
        self.assertTrue(result["success"])
    
    def tearDown(self):
        self.db.close()
```

è¿è¡Œæµ‹è¯•ï¼š

```bash
python -m unittest discover tests/
```

### é›†æˆæµ‹è¯•

æµ‹è¯•å®Œæ•´æµç¨‹ï¼š

```python
def test_full_workflow():
    # åˆå§‹åŒ– Agent
    agent = DataAnalystAgent()
    
    # æ³¨å†Œæ•°æ®æº
    agent.register_sqlite_database("test", "test.db")
    
    # æ‰§è¡ŒæŸ¥è¯¢
    result = agent.chat("æŸ¥è¯¢æ‰€æœ‰ç”¨æˆ·", source_name="test")
    
    # éªŒè¯ç»“æœ
    assert "SQL" in result or "æ•°æ®" in result
```

## éƒ¨ç½²

### Docker éƒ¨ç½²

åˆ›å»º `Dockerfile`ï¼š

```dockerfile
FROM python:3.9

WORKDIR /app

COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .

CMD ["python", "web_ui.py"]
```

æ„å»ºå’Œè¿è¡Œï¼š

```bash
docker build -t ai-data-analyst .
docker run -p 7860:7860 ai-data-analyst
```

### ç”Ÿäº§ç¯å¢ƒé…ç½®

1. ä½¿ç”¨ Gunicorn æˆ– uWSGI
2. é…ç½®åå‘ä»£ç†ï¼ˆNginxï¼‰
3. è®¾ç½®ç¯å¢ƒå˜é‡
4. å¯ç”¨ HTTPS
5. é…ç½®æ—¥å¿—è½®è½¬
6. ç›‘æ§å’Œå‘Šè­¦

## è´¡çŒ®æŒ‡å—

### æäº¤ä»£ç 

1. Fork é¡¹ç›®
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ï¼š`git checkout -b feature/new-feature`
3. æäº¤æ›´æ”¹ï¼š`git commit -am 'Add new feature'`
4. æ¨é€åˆ†æ”¯ï¼š`git push origin feature/new-feature`
5. åˆ›å»º Pull Request

### ä»£ç è§„èŒƒ

- éµå¾ª PEP 8
- æ·»åŠ ç±»å‹æ³¨è§£
- ç¼–å†™æ–‡æ¡£å­—ç¬¦ä¸²
- æ·»åŠ å¿…è¦çš„æ³¨é‡Š
- ç¼–å†™å•å…ƒæµ‹è¯•

### æ–‡æ¡£æ›´æ–°

ä¿®æ”¹åŠŸèƒ½ååŒæ­¥æ›´æ–°ï¼š
- README.md
- FEATURES.md
- USER_GUIDE.md
- DEVELOPER_GUIDE.md

## å¸¸è§é—®é¢˜

### Q: å¦‚ä½•æ”¯æŒæ–°çš„ SQL æ–¹è¨€ï¼Ÿ

ä¿®æ”¹ `src/tools/nl2sql.py`ï¼Œæ·»åŠ æ–¹è¨€ç‰¹å®šçš„å¤„ç†é€»è¾‘ã€‚

### Q: å¦‚ä½•ä¼˜åŒ–å¤§æ•°æ®é›†çš„å¤„ç†ï¼Ÿ

1. å®ç°åˆ†é¡µæŸ¥è¯¢
2. æ·»åŠ æ•°æ®é‡‡æ ·
3. ä½¿ç”¨æµå¼å¤„ç†
4. ä¼˜åŒ– SQL æŸ¥è¯¢

### Q: å¦‚ä½•æ·»åŠ ç”¨æˆ·è®¤è¯ï¼Ÿ

åœ¨ `web_ui.py` ä¸­é›†æˆ Gradio çš„è®¤è¯åŠŸèƒ½ï¼š

```python
demo.launch(auth=("username", "password"))
```

## å‚è€ƒèµ„æº

- [LlamaIndex æ–‡æ¡£](https://docs.llamaindex.ai/)
- [Gradio æ–‡æ¡£](https://gradio.app/docs/)
- [Loguru æ–‡æ¡£](https://loguru.readthedocs.io/)
- [Pandas æ–‡æ¡£](https://pandas.pydata.org/docs/)

## è”ç³»æ–¹å¼

- GitHub Issues
- Email: [your-email]
- æ–‡æ¡£åé¦ˆï¼šæäº¤ PR

---

ç¥å¼€å‘æ„‰å¿«ï¼ğŸš€
