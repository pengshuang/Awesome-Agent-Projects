#!/usr/bin/env python3
"""
Academic Paper Q&A System - ç®€å•å¯ç”¨ç‰ˆæœ¬
ä½¿ç”¨æœ€åŸºç¡€çš„ Gradio Interfaceï¼Œä¿è¯å¯ç”¨æ€§
"""

import os
import gradio as gr
from pathlib import Path
from collections import defaultdict

# å¯¼å…¥é¡¹ç›®æ¨¡å—
from src.agent import create_agent
from src.loaders.document_loader import DocumentLoader
from init_system import initialize_system

# å…¨å±€çŠ¶æ€
AGENT = None
INDEX_BUILT = False
INITIALIZED = False
INDEX_PATH = "./data/index"
VECTOR_STORE_PATH = "./data/vector_store"  # å®é™…çš„å‘é‡å­˜å‚¨è·¯å¾„
DOCUMENTS_PATH = "./data/documents"

DEFAULT_CHUNK_SIZE = int(os.getenv("DEFAULT_CHUNK_SIZE", "1024"))
DEFAULT_TOP_K = int(os.getenv("DEFAULT_TOP_K", "3"))


def check_existing_index() -> str:
    """å¯åŠ¨æ—¶æ£€æŸ¥æ˜¯å¦å­˜åœ¨å·²æ„å»ºçš„ç´¢å¼•"""
    global AGENT, INDEX_BUILT, INITIALIZED
    
    # æ£€æŸ¥å‘é‡å­˜å‚¨ç›®å½•
    vector_store_dir = Path(VECTOR_STORE_PATH)
    
    # æ£€æŸ¥æ˜¯å¦å­˜åœ¨å‘é‡å­˜å‚¨æ–‡ä»¶ï¼ˆæ’é™¤ .gitkeepï¼‰
    has_vector_store = False
    if vector_store_dir.exists():
        # è·å–æ‰€æœ‰æ–‡ä»¶ï¼ˆæ’é™¤ .gitkeep å’Œéšè—æ–‡ä»¶ï¼‰
        vector_files = [f for f in vector_store_dir.glob("*") 
                       if f.is_file() and f.name != '.gitkeep' and not f.name.startswith('.')]
        has_vector_store = len(vector_files) > 0
    
    if not has_vector_store:
        return "â„¹ï¸ æœªå‘ç°å·²æœ‰ç´¢å¼•\nğŸ’¡ ç³»ç»Ÿå°†åœ¨é¦–æ¬¡æŸ¥è¯¢æ—¶è‡ªåŠ¨æ„å»ºç´¢å¼•ï¼Œæˆ–å‰å¾€ã€Œæ„å»ºç´¢å¼•ã€æ ‡ç­¾é¡µæ‰‹åŠ¨æ„å»º"
    
    try:
        if not INITIALIZED:
            initialize_system()
            INITIALIZED = True
        
        # å°è¯•åŠ è½½å·²æœ‰ç´¢å¼•
        AGENT = create_agent(
            documents_dir=DOCUMENTS_PATH,
            force_rebuild=False  # ä¸å¼ºåˆ¶é‡å»º
        )
        INDEX_BUILT = True
        
        # è·å–æ–‡æ¡£ç»Ÿè®¡ä¿¡æ¯
        try:
            papers = AGENT.list_papers(detailed=False)
            doc_count = len(papers)
            return f"""âœ… å·²è‡ªåŠ¨åŠ è½½ç°æœ‰ç´¢å¼•ï¼

ğŸ“Š ç´¢å¼•ä¿¡æ¯:
- å‘é‡å­˜å‚¨: {VECTOR_STORE_PATH}
- å·²ç´¢å¼•æ–‡æ¡£: {doc_count} ä¸ª
- çŠ¶æ€: å¯ç›´æ¥ä½¿ç”¨

ğŸ’¡ æç¤º:
- RAG æ¨¡å¼å·²å°±ç»ªï¼Œå¯ç›´æ¥å¼€å§‹æé—®
- å¦‚éœ€é‡æ–°æ„å»ºç´¢å¼•ï¼Œè¯·å‰å¾€ã€Œæ„å»ºç´¢å¼•ã€æ ‡ç­¾é¡µ
"""
        except:
            return f"""âœ… å·²è‡ªåŠ¨åŠ è½½ç°æœ‰ç´¢å¼•ï¼

ğŸ“Š ç´¢å¼•ä¿¡æ¯:
- å‘é‡å­˜å‚¨: {VECTOR_STORE_PATH}
- çŠ¶æ€: å¯ç›´æ¥ä½¿ç”¨

ğŸ’¡ æç¤º:
- RAG æ¨¡å¼å·²å°±ç»ªï¼Œå¯ç›´æ¥å¼€å§‹æé—®
- å¦‚éœ€é‡æ–°æ„å»ºç´¢å¼•ï¼Œè¯·å‰å¾€ã€Œæ„å»ºç´¢å¼•ã€æ ‡ç­¾é¡µ
"""
        
    except Exception as e:
        return f"""âš ï¸ ç´¢å¼•åŠ è½½å¤±è´¥: {str(e)}

ğŸ’¡ å»ºè®®:
1. å‰å¾€ã€Œæ„å»ºç´¢å¼•ã€æ ‡ç­¾é¡µé‡æ–°æ„å»º
2. æ£€æŸ¥æ–‡æ¡£ç›®å½•æ˜¯å¦å­˜åœ¨: {DOCUMENTS_PATH}
3. æŸ¥çœ‹ç³»ç»Ÿæ—¥å¿—è·å–è¯¦ç»†é”™è¯¯ä¿¡æ¯
"""


def build_index(input_dir: str, force_rebuild: bool = True) -> str:
    """æ„å»ºç´¢å¼• - è¿”å›å­—ç¬¦ä¸²çŠ¶æ€"""
    global AGENT, INDEX_BUILT, INITIALIZED
    
    try:
        if not INITIALIZED:
            initialize_system()
            INITIALIZED = True
        
        loader = DocumentLoader(
            input_dir=input_dir,
            recursive=True,
            clean_text=True,
            preserve_formatting=True
        )
        
        documents = loader.load_documents()
        
        if not documents:
            return f"âŒ æœªæ‰¾åˆ°æ–‡æ¡£ï¼Œè¯·æ£€æŸ¥è·¯å¾„: {input_dir}"
        
        # ç»Ÿè®¡æ¯ä¸ªæ–‡ä»¶çš„æ–‡æ¡£æ•°é‡
        file_doc_count = defaultdict(int)
        for doc in documents:
            file_name = doc.metadata.get('file_name', 'æœªçŸ¥æ–‡ä»¶')
            file_doc_count[file_name] += 1
        
        # åˆ›å»º agent å¹¶æ„å»ºç´¢å¼•ï¼ˆå¯èƒ½è€—æ—¶è¾ƒé•¿ï¼‰
        try:
            AGENT = create_agent(
                documents_dir=input_dir,
                force_rebuild=force_rebuild
            )
        except BrokenPipeError:
            return """âŒ æ„å»ºç´¢å¼•å¤±è´¥: è¿æ¥ä¸­æ–­ (Broken pipe)

ğŸ”§ å¯èƒ½åŸå› :
1. æµè§ˆå™¨é¡µé¢å·²å…³é—­æˆ–åˆ·æ–°
2. æ„å»ºæ—¶é—´è¿‡é•¿å¯¼è‡´è¿æ¥è¶…æ—¶
3. ç½‘ç»œè¿æ¥ä¸ç¨³å®š

ğŸ’¡ è§£å†³æ–¹æ¡ˆ:
1. ä¿æŒæµè§ˆå™¨é¡µé¢æ‰“å¼€
2. æ£€æŸ¥ç½‘ç»œè¿æ¥
3. å¦‚æœæ–‡æ¡£å¾ˆå¤šï¼Œè¯·è€å¿ƒç­‰å¾…ï¼ˆä¸è¦åˆ·æ–°é¡µé¢ï¼‰
4. å°è¯•å‡å°‘æ–‡æ¡£æ•°é‡åé‡è¯•
5. æˆ–ä½¿ç”¨å‘½ä»¤è¡Œå·¥å…·: python main.py build

â„¹ï¸ æç¤º: ç´¢å¼•å¯èƒ½å·²éƒ¨åˆ†æ„å»ºï¼Œä¸‹æ¬¡æ„å»ºæ—¶å¯ä»¥ä¸å‹¾é€‰"å¼ºåˆ¶é‡å»º"ä»¥ç»§ç»­
"""
        except Exception as build_error:
            return f"""âŒ æ„å»ºç´¢å¼•è¿‡ç¨‹å‡ºé”™: {str(build_error)}

ğŸ’¡ å»ºè®®:
1. æ£€æŸ¥æ–‡æ¡£æ ¼å¼æ˜¯å¦æ­£ç¡®
2. ç¡®ä¿æœ‰è¶³å¤Ÿçš„ç£ç›˜ç©ºé—´
3. æŸ¥çœ‹ç³»ç»Ÿæ—¥å¿—: logs/app.log
4. å°è¯•ä½¿ç”¨å‘½ä»¤è¡Œ: python main.py build
"""
        
        INDEX_BUILT = True
        
        # æ„å»ºè¯¦ç»†çš„ç»Ÿè®¡ä¿¡æ¯
        result = f"""âœ… ç´¢å¼•æ„å»ºæˆåŠŸï¼

ğŸ“Š æ€»ä½“ç»Ÿè®¡:
- æ€»æ–‡æ¡£æ•°é‡: {len(documents)} ä¸ªæ–‡æœ¬å—
- æºæ–‡ä»¶æ•°é‡: {len(file_doc_count)} ä¸ª
- æ–‡æ¡£è·¯å¾„: {input_dir}

ğŸ“„ å„æ–‡ä»¶è¯¦æƒ…:
"""
        # æŒ‰æ–‡æ¡£æ•°é‡æ’åºæ˜¾ç¤º
        for file_name, count in sorted(file_doc_count.items(), key=lambda x: x[1], reverse=True):
            result += f"  â€¢ {file_name}: {count} ä¸ªæ–‡æœ¬å—\n"
        
        result += "\nğŸ’¡ ç°åœ¨å¯ä»¥åœ¨ã€Œé—®ç­”ã€æ ‡ç­¾é¡µå¼€å§‹æé—®äº†ï¼"
        
        return result
        
    except KeyboardInterrupt:
        return """âš ï¸ æ„å»ºå·²å–æ¶ˆ

ç”¨æˆ·ä¸»åŠ¨ä¸­æ–­äº†æ„å»ºè¿‡ç¨‹ã€‚
"""
    except Exception as e:
        error_msg = str(e)
        
        # ç‰¹æ®Šé”™è¯¯å¤„ç†
        if "Broken pipe" in error_msg or "BrokenPipeError" in error_msg:
            return """âŒ æ„å»ºç´¢å¼•å¤±è´¥: è¿æ¥ä¸­æ–­

ğŸ”§ å¯èƒ½åŸå› :
1. æµè§ˆå™¨é¡µé¢å…³é—­æˆ–åˆ·æ–°
2. ç½‘ç»œè¿æ¥ä¸­æ–­
3. æ„å»ºæ—¶é—´è¿‡é•¿

ğŸ’¡ è§£å†³æ–¹æ¡ˆ:
1. ä¿æŒé¡µé¢æ‰“å¼€ï¼Œä¸è¦åˆ·æ–°
2. ä½¿ç”¨å‘½ä»¤è¡Œæ„å»º: python main.py build
3. æ£€æŸ¥ç½‘ç»œè¿æ¥
"""
        elif "Permission denied" in error_msg:
            return f"""âŒ æ„å»ºç´¢å¼•å¤±è´¥: æƒé™ä¸è¶³

é”™è¯¯: {error_msg}

ğŸ’¡ è§£å†³æ–¹æ¡ˆ:
1. æ£€æŸ¥æ–‡æ¡£ç›®å½•çš„è¯»å–æƒé™
2. æ£€æŸ¥ç´¢å¼•ç›®å½•çš„å†™å…¥æƒé™
3. å°è¯•ä½¿ç”¨ç®¡ç†å‘˜æƒé™è¿è¡Œ
"""
        elif "No space left" in error_msg:
            return """âŒ æ„å»ºç´¢å¼•å¤±è´¥: ç£ç›˜ç©ºé—´ä¸è¶³

ğŸ’¡ è§£å†³æ–¹æ¡ˆ:
1. æ¸…ç†ç£ç›˜ç©ºé—´
2. å‡å°‘æ–‡æ¡£æ•°é‡
3. æ›´æ”¹ç´¢å¼•å­˜å‚¨ä½ç½®
"""
        else:
            return f"""âŒ æ„å»ºç´¢å¼•å¤±è´¥: {error_msg}

ğŸ’¡ å»ºè®®:
1. æ£€æŸ¥æ–‡æ¡£è·¯å¾„æ˜¯å¦æ­£ç¡®: {input_dir}
2. ç¡®è®¤æ–‡æ¡£æ ¼å¼æ”¯æŒ (PDF, DOCX, TXT, MD)
3. æŸ¥çœ‹è¯¦ç»†æ—¥å¿—: logs/app.log
4. å°è¯•ä½¿ç”¨å‘½ä»¤è¡Œ: python main.py build
"""


def get_available_documents():
    """è·å–å¯ç”¨æ–‡æ¡£åˆ—è¡¨"""
    global AGENT, INITIALIZED
    
    try:
        # ç¡®ä¿æœ‰ agent å®ä¾‹ï¼ˆå³ä½¿æ²¡æœ‰æ„å»ºç´¢å¼•ä¹Ÿå¯ä»¥åˆ—å‡ºæ–‡æ¡£ï¼‰
        if not INITIALIZED:
            initialize_system()
            INITIALIZED = True
        
        if AGENT is None:
            from src.agent import AcademicAgent
            AGENT = AcademicAgent(documents_dir=DOCUMENTS_PATH, auto_load=False)
        
        return AGENT.list_available_documents()
    except Exception as e:
        print(f"è·å–æ–‡æ¡£åˆ—è¡¨å¤±è´¥: {e}")
        return []


def query_question(question: str, mode: str, enable_web_search: bool, top_k: int, selected_docs: list) -> str:
    """
    æŸ¥è¯¢é—®é¢˜ - æ”¯æŒ RAG å’Œ LLM ä¸¤ç§æ¨¡å¼
    
    Args:
        question: ç”¨æˆ·é—®é¢˜
        mode: æŸ¥è¯¢æ¨¡å¼ï¼ˆ"RAG æ¨¡å¼" æˆ– "LLM æ¨¡å¼"ï¼‰
        enable_web_search: æ˜¯å¦å¯ç”¨è”ç½‘æœç´¢
        top_k: æ£€ç´¢æ–‡æ¡£æ•°é‡ï¼ˆä»… RAG æ¨¡å¼ï¼‰
        selected_docs: é€‰ä¸­çš„æ–‡æ¡£åˆ—è¡¨ï¼ˆä»… LLM æ¨¡å¼ä½¿ç”¨ï¼‰
    """
    global AGENT, INDEX_BUILT, INITIALIZED
    
    if not question or not question.strip():
        return "âš ï¸ è¯·è¾“å…¥é—®é¢˜"
    
    # LLM æ¨¡å¼ä¸éœ€è¦ç´¢å¼•
    if mode == "LLM æ¨¡å¼":
        try:
            # åˆå§‹åŒ–ç³»ç»Ÿ
            if not INITIALIZED:
                initialize_system()
                INITIALIZED = True
            
            # ç¡®ä¿ AGENT å­˜åœ¨ï¼ˆå³ä½¿æ²¡æœ‰ç´¢å¼•ï¼‰
            if AGENT is None:
                from src.agent import AcademicAgent
                AGENT = AcademicAgent(documents_dir=DOCUMENTS_PATH, auto_load=False)
            
            # ä½¿ç”¨ query_direct æ–¹æ³•ï¼ˆæ”¯æŒæ–‡æ¡£é™„ä»¶ï¼‰
            result = AGENT.query_direct(
                question=question,
                enable_web_search=enable_web_search,
                document_files=selected_docs if selected_docs else None
            )
            
            # æå–ç­”æ¡ˆ
            if isinstance(result, dict):
                answer = result.get('answer', str(result))
                web_sources = result.get('web_sources', [])
                document_sources = result.get('document_sources', [])
                metadata = result.get('metadata', {})
            else:
                answer = str(result)
                web_sources = []
                document_sources = []
                metadata = {}
            
            # æ·»åŠ æ¨¡å¼æ ‡è¯†
            response = f"ğŸ¤– **LLM ç›´æ¥å¯¹è¯æ¨¡å¼**\n"
            if enable_web_search:
                response += "ğŸŒ **å·²å¯ç”¨è”ç½‘æœç´¢**\n"
            if document_sources:
                response += f"ğŸ“ **å·²é™„åŠ  {len(document_sources)} ä¸ªæ–‡æ¡£**\n"
            response += "\n" + "=" * 70 + "\n\n"
            response += answer
            
            # æ·»åŠ æ–‡æ¡£é™„ä»¶ä¿¡æ¯
            if document_sources:
                response += "\n\n" + "=" * 70
                response += "\nğŸ“ ä½¿ç”¨çš„æ–‡æ¡£é™„ä»¶:\n" + "=" * 70 + "\n"
                for i, doc in enumerate(document_sources, 1):
                    response += f"\nã€æ–‡æ¡£ {i}ã€‘\n"
                    response += f"ğŸ“„ æ–‡ä»¶: {doc}\n"
            
            # æ·»åŠ ç½‘ç»œæ¥æºä¿¡æ¯
            if web_sources:
                response += "\n\n" + "=" * 70
                response += "\nğŸŒ ç½‘ç»œå‚è€ƒæ¥æº:\n" + "=" * 70 + "\n"
                for i, source in enumerate(web_sources[:3], 1):
                    response += f"\nã€ç½‘ç»œæ¥æº {i}ã€‘\n"
                    response += f"ğŸ”— URL: {source.get('url', 'N/A')}\n"
                    response += f"ğŸ“Œ æ ‡é¢˜: {source.get('title', 'N/A')}\n"
                    snippet = source.get('snippet', '')
                    if snippet:
                        response += f"ğŸ“ æ‘˜è¦: {snippet[:200]}...\n"
                    response += "\n"
            
            return response
            
        except Exception as e:
            return f"âŒ LLM æŸ¥è¯¢å‡ºé”™: {str(e)}\n\nè¯·æ£€æŸ¥:\n1. API é…ç½®æ˜¯å¦æ­£ç¡®\n2. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸\n3. API å¯†é’¥æ˜¯å¦æœ‰æ•ˆ"
    
    # RAG æ¨¡å¼éœ€è¦ç´¢å¼•
    else:  # RAG æ¨¡å¼
        if not INDEX_BUILT or AGENT is None:
            return "âš ï¸ RAG æ¨¡å¼éœ€è¦å…ˆæ„å»ºç´¢å¼•ï¼\n\næ­¥éª¤:\n1. åˆ‡æ¢åˆ°ã€Œæ„å»ºç´¢å¼•ã€æ ‡ç­¾é¡µ\n2. è¾“å…¥æ–‡æ¡£ç›®å½•è·¯å¾„\n3. ç‚¹å‡»ã€Œæäº¤ã€æŒ‰é’®\n4. ç­‰å¾…æ„å»ºå®Œæˆ\n5. è¿”å›ã€Œé—®ç­”ã€æ ‡ç­¾é¡µå¹¶é€‰æ‹© RAG æ¨¡å¼"
        
        try:
            result = AGENT.query(
                question=question,
                top_k=top_k,
                enable_web_search=enable_web_search
            )
            
            # æå–ç­”æ¡ˆï¼ˆå­—å…¸æ ¼å¼ï¼‰
            if isinstance(result, dict):
                answer = result.get('answer', str(result))
                source_nodes = result.get('source_nodes', [])
                web_sources = result.get('web_sources', [])
            else:
                # å…¼å®¹æ—§æ ¼å¼
                answer = str(result)
                source_nodes = []
                web_sources = []
            
            # æ„å»ºå“åº”
            response = f"ğŸ“š **RAG æ£€ç´¢å¢å¼ºæ¨¡å¼**\n"
            if enable_web_search:
                response += "ğŸŒ **å·²å¯ç”¨è”ç½‘æœç´¢**\n"
            response += f"ğŸ¯ æ£€ç´¢æ–‡æ¡£æ•°: {top_k}\n"
            response += "\n" + "=" * 70 + "\n\n"
            response += answer
            
            # æ·»åŠ æ–‡æ¡£æ¥æºä¿¡æ¯
            if source_nodes:
                response += "\n\n" + "=" * 70
                response += "\nğŸ“š æ–‡æ¡£å‚è€ƒæ¥æº:\n" + "=" * 70 + "\n"
                
                for i, node in enumerate(source_nodes[:3], 1):
                    file_name = node.metadata.get('file_name', 'æœªçŸ¥æ–‡æ¡£')
                    score = node.score if hasattr(node, 'score') else 0
                    
                    # è·å–æ–‡æœ¬ç‰‡æ®µ
                    text_snippet = ""
                    if hasattr(node, 'text') and node.text:
                        text_snippet = node.text.strip().replace('\n', ' ')
                        if len(text_snippet) > 200:
                            text_snippet = text_snippet[:200] + "..."
                    
                    response += f"\nã€æ–‡æ¡£æ¥æº {i}ã€‘\n"
                    response += f"ğŸ“„ æ–‡ä»¶: {file_name}\n"
                    response += f"ğŸ¯ ç›¸ä¼¼åº¦: {score:.4f}\n"
                    if text_snippet:
                        response += f"ğŸ“ ç‰‡æ®µ: {text_snippet}\n"
                    response += "\n"
            
            # æ·»åŠ ç½‘ç»œæ¥æºä¿¡æ¯
            if web_sources:
                response += "\n" + "=" * 70
                response += "\nğŸŒ ç½‘ç»œå‚è€ƒæ¥æº:\n" + "=" * 70 + "\n"
                for i, source in enumerate(web_sources[:3], 1):
                    response += f"\nã€ç½‘ç»œæ¥æº {i}ã€‘\n"
                    response += f"ğŸ”— URL: {source.get('url', 'N/A')}\n"
                    response += f"ğŸ“Œ æ ‡é¢˜: {source.get('title', 'N/A')}\n"
                    snippet = source.get('snippet', '')
                    if snippet:
                        response += f"ğŸ“ æ‘˜è¦: {snippet[:200]}...\n"
                    response += "\n"
            
            return response
            
        except Exception as e:
            return f"âŒ RAG æŸ¥è¯¢å‡ºé”™: {str(e)}\n\nè¯·å°è¯•:\n1. é‡æ–°è¡¨è¿°é—®é¢˜\n2. æ£€æŸ¥ç´¢å¼•æ˜¯å¦æ­£ç¡®æ„å»º\n3. è°ƒæ•´æ£€ç´¢å‚æ•°\n4. æŸ¥çœ‹ç³»ç»Ÿæ—¥å¿—"


# åˆ›å»ºé—®ç­”ç•Œé¢
interface_qa = gr.Interface(
    fn=query_question,
    inputs=[
        gr.Textbox(
            lines=3,
            placeholder="åœ¨è¿™é‡Œè¾“å…¥æ‚¨çš„é—®é¢˜...\nä¾‹å¦‚: è¯·æ€»ç»“è¿™ç¯‡è®ºæ–‡çš„ä¸»è¦è´¡çŒ®",
            label="â“ è¾“å…¥é—®é¢˜"
        ),
        gr.Radio(
            choices=["RAG æ¨¡å¼", "LLM æ¨¡å¼"],
            value="RAG æ¨¡å¼",
            label="ğŸ”§ æŸ¥è¯¢æ¨¡å¼",
            info="RAG: åŸºäºæ–‡æ¡£æ£€ç´¢å¢å¼º | LLM: ç›´æ¥å¯¹è¯"
        ),
        gr.Checkbox(
            value=False,
            label="ğŸŒ å¯ç”¨è”ç½‘æœç´¢",
            info="è”ç½‘è·å–æœ€æ–°ä¿¡æ¯ï¼ˆä¸¤ç§æ¨¡å¼å‡å¯ç”¨ï¼‰"
        ),
        gr.Slider(
            minimum=1,
            maximum=10,
            value=DEFAULT_TOP_K,
            step=1,
            label="ğŸ“Š æ£€ç´¢æ–‡æ¡£æ•°é‡ (Top-K)",
            info="ä»… RAG æ¨¡å¼æœ‰æ•ˆï¼Œæ§åˆ¶è¿”å›çš„ç›¸å…³æ–‡æ¡£æ•°é‡"
        ),
        gr.CheckboxGroup(
            choices=get_available_documents(),
            label="ğŸ“ é™„åŠ æ–‡æ¡£ (ä»… LLM æ¨¡å¼)",
            info="é€‰æ‹©è¦ä½œä¸ºé™„ä»¶å‘é€ç»™ LLM çš„æ–‡æ¡£"
        )
    ],
    outputs=gr.Textbox(
        lines=25,
        label="ğŸ’¬ å›ç­”"
    ),
    title="ğŸ’¬ æ™ºèƒ½é—®ç­”",
    description="""
    **åŠŸèƒ½è¯´æ˜:**
    - **RAG æ¨¡å¼**: åŸºäºå·²æ„å»ºçš„çŸ¥è¯†åº“æ£€ç´¢ç›¸å…³æ–‡æ¡£åç”Ÿæˆç­”æ¡ˆ
      * ç³»ç»Ÿå¯åŠ¨æ—¶ä¼šè‡ªåŠ¨æ£€æµ‹å¹¶åŠ è½½å·²æœ‰ç´¢å¼•
      * å¦‚æ˜¾ç¤ºã€Œâœ… å·²è‡ªåŠ¨åŠ è½½ã€åˆ™å¯ç›´æ¥ä½¿ç”¨ï¼Œæ— éœ€æ‰‹åŠ¨æ„å»º
      * å¦‚æ˜¾ç¤ºã€Œâ„¹ï¸ æœªå‘ç°å·²æœ‰ç´¢å¼•ã€åˆ™éœ€å…ˆåœ¨ã€Œæ„å»ºç´¢å¼•ã€æ ‡ç­¾é¡µæ„å»º
    - **LLM æ¨¡å¼**: ç›´æ¥ä¸å¤§è¯­è¨€æ¨¡å‹å¯¹è¯ï¼Œæ— éœ€æ„å»ºç´¢å¼•
      * æ”¯æŒé™„åŠ æ–‡æ¡£ï¼šå¯é€‰æ‹© data/documents ç›®å½•ä¸‹çš„æ–‡æ¡£ä½œä¸ºé™„ä»¶å‘é€ç»™ LLM
      * æ–‡æ¡£ä¼šé€šè¿‡ Moonshot API ä¸Šä¼ å¹¶æå–å†…å®¹ï¼Œä¾› LLM åˆ†æ
    - **è”ç½‘æœç´¢**: å¯é€‰åŠŸèƒ½ï¼Œä¸¤ç§æ¨¡å¼å‡æ”¯æŒï¼Œè·å–å®æ—¶ç½‘ç»œä¿¡æ¯
    """,
    examples=[
        ["è¯·æ€»ç»“è¿™ç¯‡è®ºæ–‡çš„ä¸»è¦è´¡çŒ®", "RAG æ¨¡å¼", False, 3, []],
        ["è¿™ç¯‡è®ºæ–‡ä½¿ç”¨äº†ä»€ä¹ˆç ”ç©¶æ–¹æ³•ï¼Ÿ", "RAG æ¨¡å¼", False, 3, []],
        ["ä»€ä¹ˆæ˜¯å¤§è¯­è¨€æ¨¡å‹ï¼Ÿ", "LLM æ¨¡å¼", False, 3, []],
        ["æœ€æ–°çš„ AI æŠ€æœ¯è¶‹åŠ¿æ˜¯ä»€ä¹ˆï¼Ÿ", "LLM æ¨¡å¼", True, 3, []],
        ["è§£é‡Šä¸€ä¸‹ Transformer æ¶æ„", "RAG æ¨¡å¼", True, 5, []]
    ],
    cache_examples=False
)

interface_build = gr.Interface(
    fn=build_index,
    inputs=[
        gr.Textbox(
            value="./data/documents",
            placeholder="è¾“å…¥æ–‡æ¡£æ‰€åœ¨ç›®å½•çš„è·¯å¾„",
            label="ğŸ“ æ–‡æ¡£ç›®å½•è·¯å¾„"
        ),
        gr.Checkbox(
            value=True,
            label="å¼ºåˆ¶é‡å»ºç´¢å¼•",
            info="å‹¾é€‰å°†åˆ é™¤æ—§ç´¢å¼•å¹¶é‡æ–°æ„å»ºï¼Œä¸å‹¾é€‰åˆ™å°è¯•å¢é‡æ›´æ–°"
        )
    ],
    outputs=gr.Textbox(
        lines=20,
        label="ğŸ“Š æ„å»ºçŠ¶æ€"
    ),
    title="ğŸ“š æ„å»ºçŸ¥è¯†åº“ç´¢å¼•",
    description="""
    **â„¹ï¸ é‡è¦æç¤º:**
    - å¦‚æœå¯åŠ¨æ—¶æ˜¾ç¤ºã€Œâœ… å·²è‡ªåŠ¨åŠ è½½ç°æœ‰ç´¢å¼•ã€ï¼Œè¯´æ˜ç´¢å¼•å·²å°±ç»ª
    - **æ— éœ€é‡å¤æ„å»º**ï¼Œå¯ç›´æ¥ä½¿ç”¨ RAG æ¨¡å¼é—®ç­”
    - ä»…åœ¨ä»¥ä¸‹æƒ…å†µéœ€è¦é‡æ–°æ„å»º:
      * æ·»åŠ äº†æ–°çš„æ–‡æ¡£
      * åˆ é™¤æˆ–ä¿®æ”¹äº†ç°æœ‰æ–‡æ¡£
      * æƒ³è¦è°ƒæ•´ç´¢å¼•å‚æ•°
    
    **æ„å»ºæ­¥éª¤:**
    1. å°†è®ºæ–‡æ–‡æ¡£æ”¾å…¥æŒ‡å®šç›®å½•ï¼ˆæ”¯æŒ PDF, DOCX, Markdown, TXTï¼‰
    2. è¾“å…¥æ–‡æ¡£ç›®å½•è·¯å¾„ï¼ˆé»˜è®¤: ./data/documentsï¼‰
    3. å‹¾é€‰ã€Œå¼ºåˆ¶é‡å»ºç´¢å¼•ã€ï¼ˆæ¨èï¼‰
    4. ç‚¹å‡»ã€Œæäº¤ã€æŒ‰é’®å¼€å§‹æ„å»º
    5. æŸ¥çœ‹è¯¦ç»†çš„æ–‡ä»¶ç»Ÿè®¡ä¿¡æ¯
    6. æ„å»ºæˆåŠŸåï¼Œå‰å¾€ã€Œé—®ç­”ã€æ ‡ç­¾é¡µä½¿ç”¨ RAG æ¨¡å¼
    """
)

# ç»„åˆä¸¤ä¸ªæ ‡ç­¾é¡µ
demo = gr.TabbedInterface(
    [interface_qa, interface_build],
    tab_names=["ğŸ’¬ é—®ç­”", "ğŸ“š æ„å»ºç´¢å¼•"],
    title="ğŸ“‘ å­¦æœ¯è®ºæ–‡é—®ç­”ç³»ç»Ÿ"
)


if __name__ == "__main__":
    print("=" * 70)
    print("Academic Paper Q&A System - Web UI")
    print("=" * 70)
    print("\nğŸš€ æ­£åœ¨å¯åŠ¨ Web æœåŠ¡...\n")
    
    # å¯åŠ¨æ—¶æ£€æŸ¥å·²æœ‰ç´¢å¼•
    print("ğŸ” æ£€æŸ¥å·²æœ‰ç´¢å¼•...")
    status = check_existing_index()
    print(status)
    print()
    
    demo.launch(
        server_name="127.0.0.1",
        server_port=7860,
        share=False
    )
    
    print("\n" + "=" * 70)
    print("âœ… Web UI å·²å¯åŠ¨ï¼")
    print("=" * 70)
    print("\nğŸ“± è®¿é—®åœ°å€: http://127.0.0.1:7860")
    print("\nâŒ¨ï¸  æŒ‰ Ctrl+C åœæ­¢æœåŠ¡")
    print("=" * 70)
    
    print("\n" + "=" * 70)
    print("âœ… Web UI å·²å¯åŠ¨ï¼")
    print("=" * 70)
    print("\nğŸ“± è®¿é—®åœ°å€: http://127.0.0.1:7860")
    print("\nâŒ¨ï¸  æŒ‰ Ctrl+C åœæ­¢æœåŠ¡")
    print("=" * 70)
