# ğŸ‘¨â€ğŸ’» å¼€å‘è€…æ–‡æ¡£

## ç›®å½•
- [é¡¹ç›®æ¶æ„](#é¡¹ç›®æ¶æ„)
- [æ ¸å¿ƒæ¨¡å—](#æ ¸å¿ƒæ¨¡å—)
- [API å‚è€ƒ](#api-å‚è€ƒ)
- [æ‰©å±•å¼€å‘](#æ‰©å±•å¼€å‘)
- [æµ‹è¯•æŒ‡å—](#æµ‹è¯•æŒ‡å—)
- [éƒ¨ç½²æŒ‡å—](#éƒ¨ç½²æŒ‡å—)

---

## é¡¹ç›®æ¶æ„

### æ•´ä½“æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    User Layer                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚   Web UI     â”‚              â”‚   CLI        â”‚    â”‚
â”‚  â”‚  (Gradio)    â”‚              â”‚   (Typer)    â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Application Layer                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              Agent (main.py)                  â”‚  â”‚
â”‚  â”‚  â€¢ Query Processing                          â”‚  â”‚
â”‚  â”‚  â€¢ Context Management                        â”‚  â”‚
â”‚  â”‚  â€¢ Response Generation                       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼               â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Document   â”‚ â”‚   Retrieval â”‚ â”‚    LLM     â”‚
â”‚   Loader     â”‚ â”‚   Engine    â”‚ â”‚  Service   â”‚
â”‚              â”‚ â”‚             â”‚ â”‚            â”‚
â”‚ â€¢ PDF        â”‚ â”‚ â€¢ Vector    â”‚ â”‚ â€¢ OpenAI   â”‚
â”‚ â€¢ DOCX       â”‚ â”‚   Store     â”‚ â”‚ â€¢ Moonshot â”‚
â”‚ â€¢ Markdown   â”‚ â”‚ â€¢ Semantic  â”‚ â”‚ â€¢ DeepSeek â”‚
â”‚ â€¢ TXT        â”‚ â”‚   Search    â”‚ â”‚            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚               â”‚               â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Storage Layer                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Chroma     â”‚  â”‚   Config     â”‚  â”‚   Logs   â”‚ â”‚
â”‚  â”‚ Vector Store â”‚  â”‚    (.env)    â”‚  â”‚          â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ç›®å½•ç»“æ„

```
academic-paper-qa/
â”œâ”€â”€ src/                        # æ ¸å¿ƒæºä»£ç 
â”‚   â”œâ”€â”€ agent/                  # Agent æ¨¡å—
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ rag_agent.py       # RAG Agent å®ç°
â”‚   â”œâ”€â”€ loaders/               # æ–‡æ¡£åŠ è½½å™¨
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ document_loader.py # æ–‡æ¡£åŠ è½½ä¸»ç±»
â”‚   â”‚   â”œâ”€â”€ pdf_loader.py      # PDF åŠ è½½å™¨
â”‚   â”‚   â”œâ”€â”€ docx_loader.py     # DOCX åŠ è½½å™¨
â”‚   â”‚   â””â”€â”€ markdown_loader.py # Markdown åŠ è½½å™¨
â”‚   â”œâ”€â”€ retrieval/             # æ£€ç´¢å¼•æ“
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ vector_store.py    # å‘é‡å­˜å‚¨
â”‚   â”‚   â””â”€â”€ hybrid_retriever.py # æ··åˆæ£€ç´¢å™¨
â”‚   â”œâ”€â”€ llm/                   # LLM æœåŠ¡
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py            # LLM åŸºç±»
â”‚   â”‚   â”œâ”€â”€ openai_llm.py      # OpenAI å®ç°
â”‚   â”‚   â””â”€â”€ moonshot_llm.py    # Moonshot å®ç°
â”‚   â”œâ”€â”€ config/                # é…ç½®ç®¡ç†
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ llm_config.py      # LLM é…ç½®
â”‚   â”‚   â”œâ”€â”€ embedding_config.py # Embedding é…ç½®
â”‚   â”‚   â””â”€â”€ search_config.py   # æœç´¢é…ç½®
â”‚   â””â”€â”€ utils/                 # å·¥å…·å‡½æ•°
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ logger.py          # æ—¥å¿—å·¥å…·
â”‚       â”œâ”€â”€ text_processor.py  # æ–‡æœ¬å¤„ç†
â”‚       â””â”€â”€ validators.py      # éªŒè¯å™¨
â”œâ”€â”€ web_ui.py                  # Web UI å…¥å£
â”œâ”€â”€ main.py                    # CLI å…¥å£
â”œâ”€â”€ init_system.py             # ç³»ç»Ÿåˆå§‹åŒ–
â”œâ”€â”€ config/                    # é…ç½®æ–‡ä»¶
â”‚   â””â”€â”€ prompts.yaml          # Prompt æ¨¡æ¿
â”œâ”€â”€ data/                      # æ•°æ®ç›®å½•
â”‚   â”œâ”€â”€ documents/            # æ–‡æ¡£å­˜å‚¨
â”‚   â””â”€â”€ vector_store/         # å‘é‡ç´¢å¼•
â”œâ”€â”€ tests/                     # æµ‹è¯•ä»£ç 
â”‚   â”œâ”€â”€ unit/                 # å•å…ƒæµ‹è¯•
â”‚   â”œâ”€â”€ integration/          # é›†æˆæµ‹è¯•
â”‚   â””â”€â”€ fixtures/             # æµ‹è¯•æ•°æ®
â”œâ”€â”€ docs/                      # æ–‡æ¡£
â”‚   â”œâ”€â”€ FEATURES.md           # åŠŸèƒ½ä»‹ç»
â”‚   â”œâ”€â”€ USER_GUIDE.md         # ä½¿ç”¨æŒ‡å—
â”‚   â””â”€â”€ DEVELOPER_GUIDE.md    # å¼€å‘è€…æ–‡æ¡£
â”œâ”€â”€ examples/                  # ç¤ºä¾‹ä»£ç 
â”‚   â”œâ”€â”€ custom_loader.py      # è‡ªå®šä¹‰åŠ è½½å™¨ç¤ºä¾‹
â”‚   â”œâ”€â”€ custom_retriever.py   # è‡ªå®šä¹‰æ£€ç´¢å™¨ç¤ºä¾‹
â”‚   â””â”€â”€ api_usage.py          # API ä½¿ç”¨ç¤ºä¾‹
â”œâ”€â”€ .env.example              # é…ç½®æ¨¡æ¿
â”œâ”€â”€ requirements.txt          # ä¾èµ–åˆ—è¡¨
â””â”€â”€ README.md                 # é¡¹ç›®è¯´æ˜
```

---

## æ ¸å¿ƒæ¨¡å—

### 1. Document Loaderï¼ˆæ–‡æ¡£åŠ è½½å™¨ï¼‰

**ä½ç½®**ï¼š`src/loaders/document_loader.py`

**èŒè´£**ï¼š
- åŠ è½½å„ç§æ ¼å¼çš„æ–‡æ¡£
- æ–‡æœ¬æå–å’Œæ¸…ç†
- æ–‡æ¡£å…ƒæ•°æ®ç®¡ç†
- æ–‡æœ¬åˆ†å—

**æ ¸å¿ƒç±»ï¼š**

```python
class DocumentLoader:
    """æ–‡æ¡£åŠ è½½å™¨ä¸»ç±»"""
    
    def __init__(
        self,
        input_dir: str,
        recursive: bool = True,
        clean_text: bool = True,
        preserve_formatting: bool = False,
        supported_formats: List[str] = None
    ):
        """
        å‚æ•°:
            input_dir: æ–‡æ¡£ç›®å½•
            recursive: æ˜¯å¦é€’å½’æ‰«æå­ç›®å½•
            clean_text: æ˜¯å¦æ¸…ç†æ–‡æœ¬
            preserve_formatting: æ˜¯å¦ä¿ç•™æ ¼å¼
            supported_formats: æ”¯æŒçš„æ–‡ä»¶æ ¼å¼åˆ—è¡¨
        """
        pass
    
    def load_documents(self) -> List[Document]:
        """åŠ è½½æ‰€æœ‰æ–‡æ¡£"""
        pass
    
    def _load_single_file(self, file_path: str) -> List[Document]:
        """åŠ è½½å•ä¸ªæ–‡ä»¶"""
        pass
```

**ä½¿ç”¨ç¤ºä¾‹ï¼š**

```python
from src.loaders import DocumentLoader

# åŸºç¡€ä½¿ç”¨
loader = DocumentLoader(input_dir="./data/documents")
documents = loader.load_documents()

# é«˜çº§é…ç½®
loader = DocumentLoader(
    input_dir="./data/documents",
    recursive=True,
    clean_text=True,
    preserve_formatting=False,
    supported_formats=[".pdf", ".docx", ".md"]
)
documents = loader.load_documents()

# ç»Ÿè®¡ä¿¡æ¯
print(f"åŠ è½½äº† {len(documents)} ä¸ªæ–‡æ¡£å—")
for doc in documents:
    print(f"æ–‡ä»¶: {doc.metadata['file_name']}, é•¿åº¦: {len(doc.text)}")
```

**æ‰©å±•å¼€å‘ï¼šæ·»åŠ æ–°çš„æ–‡æ¡£æ ¼å¼**

```python
from src.loaders.base import BaseLoader
from typing import List
from llama_index.core import Document

class CustomLoader(BaseLoader):
    """è‡ªå®šä¹‰åŠ è½½å™¨ç¤ºä¾‹"""
    
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.supported_extensions = [".custom"]
    
    def load(self, file_path: str) -> List[Document]:
        """åŠ è½½è‡ªå®šä¹‰æ ¼å¼æ–‡ä»¶"""
        # å®ç°ä½ çš„åŠ è½½é€»è¾‘
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # åˆ›å»ºæ–‡æ¡£å¯¹è±¡
        doc = Document(
            text=content,
            metadata={
                'file_name': os.path.basename(file_path),
                'file_path': file_path,
                'format': 'custom'
            }
        )
        return [doc]
```

### 2. Vector Storeï¼ˆå‘é‡å­˜å‚¨ï¼‰

**ä½ç½®**ï¼š`src/retrieval/vector_store.py`

**èŒè´£**ï¼š
- æ–‡æ¡£å‘é‡åŒ–
- å‘é‡ç´¢å¼•æ„å»º
- è¯­ä¹‰æ£€ç´¢
- ç´¢å¼•æŒä¹…åŒ–

**æ ¸å¿ƒç±»ï¼š**

```python
class VectorStore:
    """å‘é‡å­˜å‚¨ç®¡ç†å™¨"""
    
    def __init__(
        self,
        persist_dir: str,
        embedding_model: str = "BAAI/bge-small-zh-v1.5",
        collection_name: str = "documents"
    ):
        """
        å‚æ•°:
            persist_dir: æŒä¹…åŒ–ç›®å½•
            embedding_model: Embedding æ¨¡å‹åç§°
            collection_name: é›†åˆåç§°
        """
        pass
    
    def build_index(
        self,
        documents: List[Document],
        chunk_size: int = 512,
        chunk_overlap: int = 50
    ) -> VectorStoreIndex:
        """æ„å»ºå‘é‡ç´¢å¼•"""
        pass
    
    def query(
        self,
        query_text: str,
        top_k: int = 5,
        similarity_threshold: float = 0.7
    ) -> List[NodeWithScore]:
        """æŸ¥è¯¢ç›¸ä¼¼æ–‡æ¡£"""
        pass
    
    def delete_index(self):
        """åˆ é™¤ç´¢å¼•"""
        pass
```

**ä½¿ç”¨ç¤ºä¾‹ï¼š**

```python
from src.retrieval import VectorStore
from src.loaders import DocumentLoader

# 1. åŠ è½½æ–‡æ¡£
loader = DocumentLoader(input_dir="./data/documents")
documents = loader.load_documents()

# 2. æ„å»ºç´¢å¼•
vector_store = VectorStore(
    persist_dir="./data/vector_store",
    embedding_model="BAAI/bge-small-zh-v1.5"
)
index = vector_store.build_index(
    documents=documents,
    chunk_size=512,
    chunk_overlap=50
)

# 3. æŸ¥è¯¢
results = vector_store.query(
    query_text="Transformer æ¨¡å‹çš„æ ¸å¿ƒåˆ›æ–°",
    top_k=5,
    similarity_threshold=0.7
)

# 4. å¤„ç†ç»“æœ
for result in results:
    print(f"ç›¸ä¼¼åº¦: {result.score}")
    print(f"å†…å®¹: {result.node.text[:100]}...")
    print(f"æ¥æº: {result.node.metadata['file_name']}")
```

### 3. RAG Agentï¼ˆé—®ç­”å¼•æ“ï¼‰

**ä½ç½®**ï¼š`src/agent/rag_agent.py`

**èŒè´£**ï¼š
- é—®é¢˜ç†è§£
- æ–‡æ¡£æ£€ç´¢
- ä¸Šä¸‹æ–‡æ„å»º
- ç­”æ¡ˆç”Ÿæˆ
- æ¥æºè¿½æº¯

**æ ¸å¿ƒç±»ï¼š**

```python
class RAGAgent:
    """RAG é—®ç­” Agent"""
    
    def __init__(
        self,
        vector_store: VectorStore,
        llm: BaseLLM,
        prompt_template: str = None
    ):
        """
        å‚æ•°:
            vector_store: å‘é‡å­˜å‚¨
            llm: è¯­è¨€æ¨¡å‹
            prompt_template: Prompt æ¨¡æ¿
        """
        pass
    
    def query(
        self,
        question: str,
        top_k: int = 5,
        return_sources: bool = True
    ) -> Dict[str, Any]:
        """
        RAG é—®ç­”
        
        è¿”å›:
            {
                'answer': str,              # ç”Ÿæˆçš„ç­”æ¡ˆ
                'sources': List[Dict],      # æ¥æºåˆ—è¡¨
                'confidence': float,        # ç½®ä¿¡åº¦
                'retrieval_time': float,    # æ£€ç´¢è€—æ—¶
                'generation_time': float    # ç”Ÿæˆè€—æ—¶
            }
        """
        pass
    
    def _build_context(self, retrieved_nodes: List[NodeWithScore]) -> str:
        """æ„å»ºä¸Šä¸‹æ–‡"""
        pass
    
    def _format_sources(self, nodes: List[NodeWithScore]) -> List[Dict]:
        """æ ¼å¼åŒ–æ¥æºä¿¡æ¯"""
        pass
```

**ä½¿ç”¨ç¤ºä¾‹ï¼š**

```python
from src.agent import RAGAgent
from src.retrieval import VectorStore
from src.llm import MoonshotLLM

# 1. åˆå§‹åŒ–ç»„ä»¶
vector_store = VectorStore(persist_dir="./data/vector_store")
llm = MoonshotLLM()

# 2. åˆ›å»º Agent
agent = RAGAgent(
    vector_store=vector_store,
    llm=llm,
    prompt_template="åŸºäºä»¥ä¸‹å†…å®¹å›ç­”é—®é¢˜:\n{context}\n\né—®é¢˜: {question}"
)

# 3. æé—®
result = agent.query(
    question="Transformer çš„æ ¸å¿ƒåˆ›æ–°æ˜¯ä»€ä¹ˆï¼Ÿ",
    top_k=5,
    return_sources=True
)

# 4. è·å–ç»“æœ
print(f"ç­”æ¡ˆ: {result['answer']}")
print(f"ç½®ä¿¡åº¦: {result['confidence']}")
print(f"æ£€ç´¢è€—æ—¶: {result['retrieval_time']:.2f}s")
print(f"ç”Ÿæˆè€—æ—¶: {result['generation_time']:.2f}s")

for i, source in enumerate(result['sources'], 1):
    print(f"\næ¥æº {i}:")
    print(f"  æ–‡ä»¶: {source['file_name']}")
    print(f"  ç›¸ä¼¼åº¦: {source['similarity']:.2f}")
    print(f"  å†…å®¹: {source['text'][:100]}...")
```

### 4. LLM Serviceï¼ˆè¯­è¨€æ¨¡å‹æœåŠ¡ï¼‰

**ä½ç½®**ï¼š`src/llm/`

**èŒè´£**ï¼š
- ç»Ÿä¸€ LLM æ¥å£
- å¤šæä¾›å•†æ”¯æŒ
- è¯·æ±‚ç®¡ç†
- é”™è¯¯å¤„ç†

**æ ¸å¿ƒæ¥å£ï¼š**

```python
from abc import ABC, abstractmethod
from typing import List, Dict, Any

class BaseLLM(ABC):
    """LLM åŸºç±»"""
    
    @abstractmethod
    def __init__(self, config: Dict[str, Any]):
        """åˆå§‹åŒ– LLM"""
        pass
    
    @abstractmethod
    def complete(
        self,
        prompt: str,
        temperature: float = 0.7,
        max_tokens: int = 1000,
        **kwargs
    ) -> str:
        """æ–‡æœ¬è¡¥å…¨"""
        pass
    
    @abstractmethod
    def chat(
        self,
        messages: List[Dict[str, str]],
        temperature: float = 0.7,
        max_tokens: int = 1000,
        **kwargs
    ) -> str:
        """å¤šè½®å¯¹è¯"""
        pass
```

**å®ç°ç¤ºä¾‹ï¼š**

```python
from src.llm.base import BaseLLM
import requests

class CustomLLM(BaseLLM):
    """è‡ªå®šä¹‰ LLM å®ç°"""
    
    def __init__(self, config: Dict[str, Any]):
        self.api_key = config.get('api_key')
        self.api_base = config.get('api_base')
        self.model = config.get('model')
    
    def complete(
        self,
        prompt: str,
        temperature: float = 0.7,
        max_tokens: int = 1000,
        **kwargs
    ) -> str:
        """å®ç°æ–‡æœ¬è¡¥å…¨"""
        response = requests.post(
            f"{self.api_base}/completions",
            json={
                "model": self.model,
                "prompt": prompt,
                "temperature": temperature,
                "max_tokens": max_tokens
            },
            headers={"Authorization": f"Bearer {self.api_key}"}
        )
        return response.json()['choices'][0]['text']
    
    def chat(
        self,
        messages: List[Dict[str, str]],
        temperature: float = 0.7,
        max_tokens: int = 1000,
        **kwargs
    ) -> str:
        """å®ç°å¤šè½®å¯¹è¯"""
        response = requests.post(
            f"{self.api_base}/chat/completions",
            json={
                "model": self.model,
                "messages": messages,
                "temperature": temperature,
                "max_tokens": max_tokens
            },
            headers={"Authorization": f"Bearer {self.api_key}"}
        )
        return response.json()['choices'][0]['message']['content']
```

---

## API å‚è€ƒ

### create_agent()

åˆ›å»º RAG Agent å®ä¾‹ã€‚

```python
def create_agent(
    documents_dir: str = "./data/documents",
    vector_store_dir: str = "./data/vector_store",
    force_rebuild: bool = False,
    chunk_size: int = 512,
    chunk_overlap: int = 50,
    embedding_model: str = "BAAI/bge-small-zh-v1.5",
    llm_provider: str = "moonshot",
    **kwargs
) -> RAGAgent:
    """
    åˆ›å»º RAG Agent
    
    å‚æ•°:
        documents_dir: æ–‡æ¡£ç›®å½•
        vector_store_dir: å‘é‡å­˜å‚¨ç›®å½•
        force_rebuild: æ˜¯å¦å¼ºåˆ¶é‡å»ºç´¢å¼•
        chunk_size: æ–‡æœ¬å—å¤§å°
        chunk_overlap: æ–‡æœ¬å—é‡å 
        embedding_model: Embedding æ¨¡å‹
        llm_provider: LLM æä¾›å•†
        **kwargs: å…¶ä»–å‚æ•°
    
    è¿”å›:
        RAGAgent å®ä¾‹
    
    å¼‚å¸¸:
        FileNotFoundError: æ–‡æ¡£ç›®å½•ä¸å­˜åœ¨
        ValueError: é…ç½®å‚æ•°æ— æ•ˆ
    """
```

**ä½¿ç”¨ç¤ºä¾‹ï¼š**

```python
from src.agent import create_agent

# åŸºç¡€ä½¿ç”¨
agent = create_agent()

# è‡ªå®šä¹‰é…ç½®
agent = create_agent(
    documents_dir="./my_papers",
    force_rebuild=True,
    chunk_size=256,
    llm_provider="openai"
)
```

### query()

æ‰§è¡Œ RAG æŸ¥è¯¢ã€‚

```python
def query(
    agent: RAGAgent,
    question: str,
    mode: str = "rag",
    web_search: bool = False,
    top_k: int = 5,
    temperature: float = 0.7,
    **kwargs
) -> Dict[str, Any]:
    """
    æ‰§è¡ŒæŸ¥è¯¢
    
    å‚æ•°:
        agent: RAG Agent å®ä¾‹
        question: ç”¨æˆ·é—®é¢˜
        mode: æŸ¥è¯¢æ¨¡å¼ ('rag' æˆ– 'llm')
        web_search: æ˜¯å¦å¯ç”¨è”ç½‘æœç´¢
        top_k: æ£€ç´¢æ•°é‡
        temperature: æ¸©åº¦å‚æ•°
        **kwargs: å…¶ä»–å‚æ•°
    
    è¿”å›:
        {
            'answer': str,
            'sources': List[Dict],
            'mode': str,
            'web_results': List[Dict]  # å¦‚æœå¯ç”¨è”ç½‘æœç´¢
        }
    """
```

---

## æ‰©å±•å¼€å‘

### 1. æ·»åŠ æ–°çš„ LLM æä¾›å•†

**æ­¥éª¤ï¼š**

1. åˆ›å»ºæ–°çš„ LLM ç±»ï¼š

```python
# src/llm/custom_llm.py
from src.llm.base import BaseLLM

class CustomLLM(BaseLLM):
    def __init__(self, config):
        self.api_key = config.get('api_key')
        # åˆå§‹åŒ–ä½ çš„ LLM å®¢æˆ·ç«¯
    
    def complete(self, prompt, **kwargs):
        # å®ç°è¡¥å…¨é€»è¾‘
        pass
    
    def chat(self, messages, **kwargs):
        # å®ç°å¯¹è¯é€»è¾‘
        pass
```

2. æ³¨å†Œåˆ°é…ç½®ï¼š

```python
# src/config/llm_config.py
LLM_PROVIDERS = {
    'openai': OpenAILLM,
    'moonshot': MoonshotLLM,
    'custom': CustomLLM,  # æ·»åŠ æ–°æä¾›å•†
}
```

3. æ›´æ–° .env.exampleï¼š

```bash
# æ·»åŠ æ–°çš„é…ç½®é¡¹
LLM_PROVIDER=custom
CUSTOM_API_KEY=your-key
CUSTOM_API_BASE=https://api.custom.com/v1
```

### 2. è‡ªå®šä¹‰æ£€ç´¢ç­–ç•¥

**ç¤ºä¾‹ï¼šå®ç°æ··åˆæ£€ç´¢ï¼ˆå…³é”®è¯ + è¯­ä¹‰ï¼‰**

```python
# src/retrieval/hybrid_retriever.py
from src.retrieval.vector_store import VectorStore
from typing import List
from llama_index.core import QueryBundle
from llama_index.core.schema import NodeWithScore

class HybridRetriever:
    """æ··åˆæ£€ç´¢å™¨ï¼šç»“åˆå…³é”®è¯å’Œè¯­ä¹‰æ£€ç´¢"""
    
    def __init__(
        self,
        vector_store: VectorStore,
        keyword_weight: float = 0.3,
        semantic_weight: float = 0.7
    ):
        self.vector_store = vector_store
        self.keyword_weight = keyword_weight
        self.semantic_weight = semantic_weight
    
    def retrieve(
        self,
        query: str,
        top_k: int = 5
    ) -> List[NodeWithScore]:
        """æ··åˆæ£€ç´¢"""
        # 1. è¯­ä¹‰æ£€ç´¢
        semantic_results = self.vector_store.query(query, top_k=top_k)
        
        # 2. å…³é”®è¯æ£€ç´¢
        keyword_results = self._keyword_search(query, top_k=top_k)
        
        # 3. èåˆç»“æœ
        merged_results = self._merge_results(
            semantic_results,
            keyword_results
        )
        
        return merged_results[:top_k]
    
    def _keyword_search(self, query: str, top_k: int) -> List[NodeWithScore]:
        """å…³é”®è¯æœç´¢å®ç°"""
        # å®ç° BM25 æˆ–å…¶ä»–å…³é”®è¯æ£€ç´¢ç®—æ³•
        pass
    
    def _merge_results(
        self,
        semantic: List[NodeWithScore],
        keyword: List[NodeWithScore]
    ) -> List[NodeWithScore]:
        """èåˆæ£€ç´¢ç»“æœ"""
        # å®ç° RRF (Reciprocal Rank Fusion) æˆ–å…¶ä»–èåˆç­–ç•¥
        pass
```

### 3. è‡ªå®šä¹‰ Prompt æ¨¡æ¿

**åˆ›å»º Prompt é…ç½®æ–‡ä»¶ï¼š**

```yaml
# config/prompts.yaml
rag_prompt: |
  ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å­¦æœ¯è®ºæ–‡åˆ†æåŠ©æ‰‹ã€‚
  
  åŸºäºä»¥ä¸‹æ–‡æ¡£å†…å®¹å›ç­”ç”¨æˆ·é—®é¢˜ï¼š
  {context}
  
  é—®é¢˜: {question}
  
  è¦æ±‚:
  1. ç­”æ¡ˆå¿…é¡»åŸºäºæä¾›çš„æ–‡æ¡£å†…å®¹
  2. å¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·æ˜ç¡®è¯´æ˜
  3. å¼•ç”¨å…·ä½“çš„æ®µè½æ”¯æŒä½ çš„ç­”æ¡ˆ
  
  ç­”æ¡ˆ:

analysis_prompt: |
  è¯·æ·±åº¦åˆ†æä»¥ä¸‹è®ºæ–‡å†…å®¹ï¼š
  {context}
  
  åˆ†æç»´åº¦ï¼š
  1. ç ”ç©¶é—®é¢˜å’ŒåŠ¨æœº
  2. æŠ€æœ¯æ–¹æ³•
  3. å®éªŒè®¾è®¡
  4. ä¸»è¦ç»“è®º
  5. åˆ›æ–°ç‚¹å’Œå±€é™æ€§
  
  åˆ†æç»“æœ:
```

**ä½¿ç”¨è‡ªå®šä¹‰ Promptï¼š**

```python
from src.utils import load_prompts

# åŠ è½½ Prompt æ¨¡æ¿
prompts = load_prompts("config/prompts.yaml")

# åˆ›å»º Agent æ—¶æŒ‡å®š
agent = RAGAgent(
    vector_store=vector_store,
    llm=llm,
    prompt_template=prompts['rag_prompt']
)
```

### 4. æ·»åŠ åå¤„ç†å™¨

**ç¤ºä¾‹ï¼šç­”æ¡ˆè´¨é‡è¯„ä¼°**

```python
# src/utils/postprocessor.py
class AnswerQualityEvaluator:
    """ç­”æ¡ˆè´¨é‡è¯„ä¼°å™¨"""
    
    def __init__(self, llm):
        self.llm = llm
    
    def evaluate(self, question: str, answer: str, sources: List[Dict]) -> Dict:
        """è¯„ä¼°ç­”æ¡ˆè´¨é‡"""
        # 1. ç›¸å…³æ€§è¯„åˆ†
        relevance_score = self._evaluate_relevance(question, answer)
        
        # 2. å®Œæ•´æ€§è¯„åˆ†
        completeness_score = self._evaluate_completeness(answer, sources)
        
        # 3. å‡†ç¡®æ€§è¯„åˆ†
        accuracy_score = self._evaluate_accuracy(answer, sources)
        
        return {
            'relevance': relevance_score,
            'completeness': completeness_score,
            'accuracy': accuracy_score,
            'overall': (relevance_score + completeness_score + accuracy_score) / 3
        }
    
    def _evaluate_relevance(self, question: str, answer: str) -> float:
        """è¯„ä¼°ç›¸å…³æ€§"""
        prompt = f"é—®é¢˜: {question}\nç­”æ¡ˆ: {answer}\n\nè¯·è¯„ä¼°ç­”æ¡ˆä¸é—®é¢˜çš„ç›¸å…³æ€§(0-1):"
        # ä½¿ç”¨ LLM è¯„ä¼°
        pass
```

---

## æµ‹è¯•æŒ‡å—

### å•å…ƒæµ‹è¯•

**ä½ç½®**ï¼š`tests/unit/`

**è¿è¡Œæµ‹è¯•ï¼š**

```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
pytest tests/

# è¿è¡Œç‰¹å®šæµ‹è¯•
pytest tests/unit/test_document_loader.py

# è¿è¡Œå¹¶æŸ¥çœ‹è¦†ç›–ç‡
pytest --cov=src tests/

# ç”ŸæˆHTMLæŠ¥å‘Š
pytest --cov=src --cov-report=html tests/
```

**æµ‹è¯•ç¤ºä¾‹ï¼š**

```python
# tests/unit/test_document_loader.py
import pytest
from src.loaders import DocumentLoader

class TestDocumentLoader:
    """DocumentLoader å•å…ƒæµ‹è¯•"""
    
    @pytest.fixture
    def loader(self):
        """æµ‹è¯•fixture"""
        return DocumentLoader(
            input_dir="tests/fixtures/documents",
            recursive=True
        )
    
    def test_load_pdf(self, loader):
        """æµ‹è¯• PDF åŠ è½½"""
        documents = loader.load_documents()
        assert len(documents) > 0
        assert any(doc.metadata['format'] == 'pdf' for doc in documents)
    
    def test_metadata(self, loader):
        """æµ‹è¯•å…ƒæ•°æ®"""
        documents = loader.load_documents()
        for doc in documents:
            assert 'file_name' in doc.metadata
            assert 'file_path' in doc.metadata
            assert 'format' in doc.metadata
```

### é›†æˆæµ‹è¯•

**ä½ç½®**ï¼š`tests/integration/`

```python
# tests/integration/test_rag_pipeline.py
import pytest
from src.agent import create_agent

class TestRAGPipeline:
    """RAG ç®¡é“é›†æˆæµ‹è¯•"""
    
    @pytest.fixture(scope="class")
    def agent(self):
        """åˆ›å»ºæµ‹è¯• Agent"""
        return create_agent(
            documents_dir="tests/fixtures/documents",
            force_rebuild=True
        )
    
    def test_end_to_end_query(self, agent):
        """ç«¯åˆ°ç«¯æŸ¥è¯¢æµ‹è¯•"""
        result = agent.query(
            question="æµ‹è¯•é—®é¢˜",
            top_k=3
        )
        
        assert 'answer' in result
        assert 'sources' in result
        assert len(result['sources']) <= 3
    
    def test_query_performance(self, agent):
        """æ€§èƒ½æµ‹è¯•"""
        import time
        
        start = time.time()
        result = agent.query("æµ‹è¯•é—®é¢˜")
        elapsed = time.time() - start
        
        assert elapsed < 10  # 10ç§’å†…å®Œæˆ
```

---

## éƒ¨ç½²æŒ‡å—

### Docker éƒ¨ç½²

**åˆ›å»º Dockerfileï¼š**

```dockerfile
FROM python:3.9-slim

WORKDIR /app

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    build-essential \
    && rm -rf /var/lib/apt/lists/*

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY . .

# åˆ›å»ºæ•°æ®ç›®å½•
RUN mkdir -p /app/data/documents /app/data/vector_store /app/logs

# æš´éœ²ç«¯å£
EXPOSE 7860

# å¯åŠ¨åº”ç”¨
CMD ["python", "web_ui.py", "--server-port", "7860", "--server-name", "0.0.0.0"]
```

**åˆ›å»º docker-compose.ymlï¼š**

```yaml
version: '3.8'

services:
  app:
    build: .
    ports:
      - "7860:7860"
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
    environment:
      - LLM_API_KEY=${LLM_API_KEY}
      - LLM_API_BASE=${LLM_API_BASE}
      - LLM_MODEL=${LLM_MODEL}
    restart: unless-stopped
```

**éƒ¨ç½²å‘½ä»¤ï¼š**

```bash
# æ„å»ºé•œåƒ
docker-compose build

# å¯åŠ¨æœåŠ¡
docker-compose up -d

# æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f

# åœæ­¢æœåŠ¡
docker-compose down
```

---

## è´¡çŒ®æŒ‡å—

### ä»£ç é£æ ¼

- éµå¾ª PEP 8
- ä½¿ç”¨ç±»å‹æ³¨è§£
- ç¼–å†™æ–‡æ¡£å­—ç¬¦ä¸²
- ä¿æŒå‡½æ•°ç®€æ´ï¼ˆ< 50 è¡Œï¼‰

### æäº¤æµç¨‹

1. Fork é¡¹ç›®
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯
3. ç¼–å†™ä»£ç å’Œæµ‹è¯•
4. æäº¤ Pull Request

---

## ä¸‹ä¸€æ­¥

- ğŸ“‹ æŸ¥çœ‹ [åŠŸèƒ½ä»‹ç»](FEATURES.md) äº†è§£ç³»ç»Ÿèƒ½åŠ›
- ğŸ“– é˜…è¯» [ä½¿ç”¨æŒ‡å—](USER_GUIDE.md) å¼€å§‹ä½¿ç”¨
- ğŸš€ å¼€å§‹å¼€å‘ä½ çš„æ‰©å±•åŠŸèƒ½
