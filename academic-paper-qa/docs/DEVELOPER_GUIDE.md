# ğŸ‘¨â€ğŸ’» å¼€å‘æŒ‡å—

> é¢å‘éœ€è¦äºŒæ¬¡å¼€å‘ã€æ‰©å±•åŠŸèƒ½çš„å¼€å‘è€…

## ç›®å½•

- [é¡¹ç›®æ¶æ„](#é¡¹ç›®æ¶æ„)
- [æ ¸å¿ƒæ¨¡å—](#æ ¸å¿ƒæ¨¡å—)
- [Pydantic é…ç½®ç³»ç»Ÿ](#pydantic-é…ç½®ç³»ç»Ÿ)
- [API å‚è€ƒ](#api-å‚è€ƒ)
- [æ‰©å±•å¼€å‘](#æ‰©å±•å¼€å‘)
- [æµ‹è¯•](#æµ‹è¯•)

---

## é¡¹ç›®æ¶æ„

### ç›®å½•ç»“æ„

```
academic-paper-qa/
â”œâ”€â”€ config/              # é…ç½®æ¨¡å—ï¼ˆPydanticï¼‰
â”‚   â”œâ”€â”€ models.py       # Pydantic é…ç½®æ¨¡å‹
â”‚   â”œâ”€â”€ settings.py     # å…¨å±€è®¾ç½®
â”‚   â”œâ”€â”€ llm_config.py   # LLM é…ç½®
â”‚   â””â”€â”€ prompts.py      # Prompt æ¨¡æ¿
â”œâ”€â”€ src/                # æ ¸å¿ƒä»£ç 
â”‚   â”œâ”€â”€ agent.py        # Agent æ ¸å¿ƒ
â”‚   â”œâ”€â”€ models.py       # æ•°æ®æ¨¡å‹ï¼ˆPydanticï¼‰
â”‚   â”œâ”€â”€ indexing/       # ç´¢å¼•æ„å»º
â”‚   â”œâ”€â”€ query/          # æŸ¥è¯¢å¼•æ“
â”‚   â”œâ”€â”€ loaders/        # æ–‡æ¡£åŠ è½½
â”‚   â”œâ”€â”€ tools/          # å·¥å…·ï¼ˆæœç´¢ç­‰ï¼‰
â”‚   â””â”€â”€ utils/          # å·¥å…·å‡½æ•°
â”œâ”€â”€ data/               # æ•°æ®ç›®å½•
â”œâ”€â”€ examples/           # ç¤ºä¾‹ä»£ç 
â”œâ”€â”€ docs/               # æ–‡æ¡£
â””â”€â”€ *.py               # å¯åŠ¨è„šæœ¬
```

### æŠ€æœ¯æ ˆ

- **RAG æ¡†æ¶**: LlamaIndex
- **å‘é‡æ•°æ®åº“**: Chroma
- **é…ç½®ç®¡ç†**: Pydantic 2.0+
- **Web UI**: Gradio 4.0+
- **Embedding**: HuggingFace / OpenAI

---

## æ ¸å¿ƒæ¨¡å—

### AcademicAgent

æ ¸å¿ƒ Agent ç±»ï¼Œè´Ÿè´£æ–‡æ¡£ç®¡ç†å’Œé—®ç­”ã€‚

```python
from src.agent import AcademicAgent

# åˆå§‹åŒ–
agent = AcademicAgent(
    documents_dir="data/documents",
    index_dir="data/vector_store",
    max_history_turns=10
)

# æ„å»ºç´¢å¼•
agent.build_index()

# å•è½®é—®ç­”
response = agent.query("è¿™ç¯‡è®ºæ–‡è®²ä»€ä¹ˆï¼Ÿ")

# å¤šè½®å¯¹è¯
response = agent.chat("ä»€ä¹ˆæ˜¯Transformerï¼Ÿ")
response = agent.chat("å®ƒçš„ä¼˜åŠ¿æ˜¯ä»€ä¹ˆï¼Ÿ")  # å¸¦ä¸Šä¸‹æ–‡
```

### æ–‡æ¡£åŠ è½½

```python
from src.loaders import DocumentLoader

loader = DocumentLoader()
documents = loader.load_documents("data/documents")
```

æ”¯æŒæ ¼å¼ï¼šPDFã€DOCXã€Markdownã€TXT

### ç´¢å¼•æ„å»º

```python
from src.indexing import Indexer

indexer = Indexer()
index = indexer.build_index(documents)
indexer.save_index(index, "data/vector_store")
```

### æŸ¥è¯¢å¼•æ“

```python
from src.query import QAEngine

qa_engine = QAEngine(index, top_k=5)
answer = qa_engine.query("é—®é¢˜")
```

---

## Pydantic é…ç½®ç³»ç»Ÿ

### é…ç½®åŠ è½½

```python
from config.models import get_config

# è·å–å…¨å±€é…ç½®ï¼ˆå•ä¾‹ï¼‰
config = get_config()

# è®¿é—®é…ç½®ï¼ˆç±»å‹å®‰å…¨ï¼‰
api_key = config.llm.api_key
model = config.llm.model
chunk_size = config.rag.chunk_size
```

### é…ç½®æ¨¡å‹

#### LLMConfig

```python
class LLMConfig(BaseSettings):
    api_key: str                    # API Key
    api_base: str = "..."          # API ç«¯ç‚¹
    model: str = "gpt-3.5-turbo"   # æ¨¡å‹
    temperature: float = 0.1        # æ¸©åº¦ (0-2)
    max_tokens: Optional[int] = None
```

#### RAGConfig

```python
class RAGConfig(BaseSettings):
    chunk_size: int = 512           # åˆ†å—å¤§å° (1-4096)
    chunk_overlap: int = 50         # é‡å å¤§å°
    retrieval_top_k: int = 5        # Top-K (1-50)
    retrieval_similarity_threshold: float = 0.7
    enable_reranking: bool = False
```

### æ•°æ®æ¨¡å‹

```python
from src.models import QueryRequest, QueryResponse

# æŸ¥è¯¢è¯·æ±‚
request = QueryRequest(
    question="ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ",
    top_k=5,
    similarity_threshold=0.7
)

# æŸ¥è¯¢å“åº”
response = QueryResponse(
    answer="æœºå™¨å­¦ä¹ æ˜¯...",
    sources=[...],
    query_time=1.23
)
```

### å‘åå…¼å®¹

```python
from config import SystemConfig

# æ—§ä»£ç ä»ç„¶æœ‰æ•ˆ
chunk_size = SystemConfig.CHUNK_SIZE
docs_dir = SystemConfig.DOCUMENTS_DIR
```

---

## API å‚è€ƒ

### AcademicAgent API

#### åˆå§‹åŒ–

```python
agent = AcademicAgent(
    documents_dir: str = "data/documents",
    index_dir: str = "data/vector_store",
    auto_load: bool = True,
    max_history_turns: int = 10
)
```

#### æ–¹æ³•

**ç´¢å¼•ç®¡ç†ï¼š**
- `build_index(force_rebuild=False)` - æ„å»ºç´¢å¼•
- `load_index()` - åŠ è½½ç´¢å¼•
- `list_papers()` - åˆ—å‡ºæ–‡æ¡£

**é—®ç­”ï¼š**
- `query(question, mode="rag", enable_web_search=False)` - å•è½®é—®ç­”
- `chat(question, mode="rag", enable_web_search=False)` - å¤šè½®å¯¹è¯

**å†å²ç®¡ç†ï¼š**
- `get_chat_history()` - è·å–å†å²
- `clear_chat_history()` - æ¸…ç©ºå†å²

### é…ç½® API

```python
from config.models import get_config, reload_config

# è·å–é…ç½®
config = get_config()

# é‡æ–°åŠ è½½
config = reload_config()

# å¯¼å‡ºé…ç½®
json_str = config.model_dump_json(indent=2)
dict_data = config.model_dump()
```

---

## æ‰©å±•å¼€å‘

### è‡ªå®šä¹‰ Prompt

ç¼–è¾‘ `config/prompts.py`ï¼š

```python
CUSTOM_SYSTEM_PROMPT = """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å­¦æœ¯åŠ©æ‰‹...
"""
```

### æ·»åŠ æ–°çš„æ–‡æ¡£åŠ è½½å™¨

```python
from src.loaders import DocumentLoader

class MyLoader(DocumentLoader):
    def load_my_format(self, file_path):
        # å®ç°åŠ è½½é€»è¾‘
        pass
```

### é›†æˆæ–°çš„æœç´¢å¼•æ“

```python
from src.tools import WebSearchTool

class MySearchTool(WebSearchTool):
    def search(self, query):
        # å®ç°æœç´¢é€»è¾‘
        pass
```

### è‡ªå®šä¹‰æ•°æ®æ¨¡å‹

```python
from pydantic import BaseModel, Field

class MyModel(BaseModel):
    field1: str = Field(..., description="å­—æ®µ1")
    field2: int = Field(default=0, ge=0)
```

---

## æµ‹è¯•

### è¿è¡Œæµ‹è¯•

```bash
# æ‰€æœ‰æµ‹è¯•
pytest tests/

# ç‰¹å®šæµ‹è¯•
pytest tests/test_agent_core.py

# è¯¦ç»†è¾“å‡º
pytest -v tests/
```

### ç¼–å†™æµ‹è¯•

```python
import pytest
from src.agent import AcademicAgent

def test_agent_initialization():
    agent = AcademicAgent()
    assert agent is not None

def test_query():
    agent = AcademicAgent()
    response = agent.query("test question")
    assert isinstance(response, str)
```

---

## å¼€å‘è§„èŒƒ

### ä»£ç é£æ ¼

- éµå¾ª PEP 8
- ä½¿ç”¨ç±»å‹æ³¨è§£
- æ·»åŠ æ–‡æ¡£å­—ç¬¦ä¸²

```python
def my_function(param: str) -> int:
    """
    å‡½æ•°è¯´æ˜
    
    Args:
        param: å‚æ•°è¯´æ˜
        
    Returns:
        è¿”å›å€¼è¯´æ˜
    """
    pass
```

### Git å·¥ä½œæµ

```bash
# 1. åˆ›å»ºåˆ†æ”¯
git checkout -b feature/my-feature

# 2. å¼€å‘å’Œæµ‹è¯•
# ...

# 3. æäº¤
git commit -m "Add: æ–°åŠŸèƒ½è¯´æ˜"

# 4. æ¨é€
git push origin feature/my-feature

# 5. åˆ›å»º Pull Request
```

### æäº¤ä¿¡æ¯è§„èŒƒ

- `Add:` æ–°å¢åŠŸèƒ½
- `Fix:` ä¿®å¤ Bug
- `Update:` æ›´æ–°åŠŸèƒ½
- `Refactor:` é‡æ„ä»£ç 
- `Docs:` æ–‡æ¡£æ›´æ–°

---

## æ€§èƒ½ä¼˜åŒ–

### ç´¢å¼•ä¼˜åŒ–

```python
# è°ƒæ•´ chunk å‚æ•°
config.rag.chunk_size = 1024
config.rag.chunk_overlap = 100

# è°ƒæ•´æ£€ç´¢å‚æ•°
config.rag.retrieval_top_k = 10
```

### ç¼“å­˜

```python
# å¯ç”¨ç¼“å­˜
config.system.enable_cache = True
```

---

## éƒ¨ç½²

### Docker éƒ¨ç½²

```dockerfile
FROM python:3.9
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
CMD ["python", "web_ui_multi_turn.py"]
```

### ç¯å¢ƒå˜é‡

ç”Ÿäº§ç¯å¢ƒå»ºè®®é€šè¿‡ç¯å¢ƒå˜é‡é…ç½®ï¼š

```bash
export LLM_API_KEY=xxx
export LLM_MODEL=gpt-4
export LOG_LEVEL=INFO
```

---

## è·å–å¸®åŠ©

- ğŸ“š æŸ¥çœ‹ç¤ºä¾‹ä»£ç ï¼š`examples/`
- ğŸ“– é˜…è¯» [Pydantic é…ç½®æŒ‡å—](PYDANTIC_GUIDE.md)
- ğŸ› æäº¤ Issue
- ğŸ’¬ å‚ä¸è®¨è®º

---

**æ›´æ–°æ—¶é—´ï¼š** 2025-12-21
