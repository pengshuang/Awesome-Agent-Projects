# ğŸ“š Academic Paper Intelligent Q&A System

> Intelligent paper reading assistant based on RAG technology, supporting multi-turn conversations, Web UI, and web search to help you understand academic papers easily

[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![LlamaIndex](https://img.shields.io/badge/Powered%20by-LlamaIndex-orange)](https://www.llamaindex.ai/)
[![Pydantic](https://img.shields.io/badge/Config-Pydantic-blue)](https://docs.pydantic.dev/)

[ä¸­æ–‡](README.md) | English

---

## ğŸ“– Documentation Navigation

| Document | Description |
|----------|-------------|
| [README_EN.md](README_EN.md) | **Project Overview & Quick Start** |
| [docs/USER_GUIDE_EN.md](docs/USER_GUIDE_EN.md) | **User Guide** (Configuration, UI usage, FAQ) |
| [docs/DEVELOPER_GUIDE_EN.md](docs/DEVELOPER_GUIDE_EN.md) | **Developer Guide** (Architecture, API, Pydantic config) |

---

## ğŸŒŸ Core Features

- ğŸ’¬ **Multi-turn Dialogue** - Context memory, continuous questioning
- ğŸ§  **RAG Q&A** - Precise answers based on vector retrieval
- ğŸŒ **Web UI** - Beautiful and easy to use, supports Markdown rendering
- ğŸ“„ **Multi-format** - PDF, DOCX, Markdown, TXT
- ğŸ” **Semantic Retrieval** - Vector database, millisecond response
- ğŸ“Š **Source Tracing** - Answers annotated with original sources
- ğŸŒ **Web Search** - DuckDuckGo for latest information
- ğŸ¨ **Dual Mode** - RAG (document-based) + LLM (open conversation)
- âš™ï¸ **Pydantic Config** - Type-safe, automatic validation

---

## ğŸš€ Quick Start
git clone <repository-url>

See unified quick start: `../docs/QUICK_START.md`.

---

## ğŸ’¬ Multi-turn Dialogue vs Single-turn Q&A

### ğŸ¯ When to Use Multi-turn Dialogue?

**Suitable Scenarios:**
- ğŸ“– **In-depth Learning**: Gradually understand complex concepts, continuous questioning
- ğŸ” **Literature Review**: Compare multiple papers, associate contexts
- ğŸ’­ **Academic Discussion**: Brainstorming, in-depth analysis
- ğŸ“ **Paper Interpretation**: Complete understanding of paper structure and content

**Dialogue Example:**
```
ğŸ‘¤: What is Transformer?
ğŸ¤–: Transformer is a neural network architecture based on attention mechanism...

ğŸ‘¤: What are its applications?              # â† Automatically understands "its" refers to Transformer
ğŸ¤–: Transformer is mainly applied in NLP, CV and other fields...

ğŸ‘¤: Can you elaborate on NLP applications?  # â† Continue in-depth based on context
```

### âš¡ When to Use Single-turn Q&A?

**Suitable Scenarios:**
- ğŸ” **Quick Query**: Look up definitions, concepts, formulas
- ğŸ“ **Independent Questions**: Each question is independent without correlation
- ğŸ’¡ **Keyword Extraction**: Extract key information

**Q&A Example:**
```
Q: What is the full name of Transformer?
A: "Attention is All You Need"

Q: What is BERT?
A: BERT (Bidirectional Encoder Representations from Transformers)...
```

---

## ğŸ’¡ Usage Examples

### Add Documents and Ask Questions

```bash
# 1. Add paper
cp paper.pdf ./data/documents/

# 2. Start Web UI
./start_web_multi.sh

# 3. Build index â†’ Start asking
```

### Dialogue Example

```
ğŸ‘¤: What is the main contribution of this paper?
ğŸ¤–: The main contribution is proposing the Transformer architecture...

ğŸ‘¤: What problem does it solve?
ğŸ¤–: Transformer solves the sequential dependency problem of RNN...
```

Detailed instructions: [User Guide](docs/USER_GUIDE_EN.md)

---

## ğŸ› ï¸ Tech Stack

- **RAG Framework**: LlamaIndex
- **Vector Database**: Chroma
- **Embedding**: BAAI/bge-small-zh-v1.5
- **LLM**: OpenAI / DeepSeek / Moonshot
- **Web UI**: Gradio 4.0+
- **Configuration Management**: Pydantic 2.0+

---

## ğŸ“ Project Structure

```
academic-paper-qa/
â”œâ”€â”€ config/              # Configuration module (Pydantic)
â”œâ”€â”€ src/                 # Core code
â”‚   â”œâ”€â”€ agent.py        # Agent core
â”‚   â”œâ”€â”€ models.py       # Data models
â”‚   â”œâ”€â”€ indexing/       # Index building
â”‚   â”œâ”€â”€ query/          # Query engine
â”‚   â”œâ”€â”€ loaders/        # Document loading
â”‚   â””â”€â”€ tools/          # Web search and other tools
â”œâ”€â”€ data/               # Data directory
â”‚   â”œâ”€â”€ documents/      # Place papers (PDF/DOCX/TXT)
â”‚   â””â”€â”€ vector_store/   # Vector index
â”œâ”€â”€ examples/           # Example code
â”œâ”€â”€ docs/               # Documentation
â””â”€â”€ *.py               # Launch scripts
```

---

## â“ FAQ

**Q: What file formats are supported?**  
A: PDF, DOCX, Markdown, TXT

**Q: Is GPU required?**  
A: No, CPU is sufficient

**Q: Are local models supported?**  
A: Embedding supports local models, LLM requires API

**Q: How to adjust history turns?**  
A: See [User Guide - History Control](docs/USER_GUIDE_EN.md#history-control)

More questions: [User Guide - Troubleshooting](docs/USER_GUIDE_EN.md#troubleshooting)

---

## ğŸ¤ Contributing

Issues and Pull Requests are welcome!

---

## ğŸ“„ License

MIT License

<details>
<summary><b>Q: How many papers can be loaded at once?</b></summary>

A: Theoretically unlimited, practically limited by memory and model context length. Tested with 100+ papers, retrieval performance remains good.
</details>
