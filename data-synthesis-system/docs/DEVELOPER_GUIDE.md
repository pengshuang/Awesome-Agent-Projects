# å¼€å‘è€…æŒ‡å—

æœ¬æŒ‡å—é¢å‘éœ€è¦è¿›è¡ŒäºŒæ¬¡å¼€å‘çš„å¼€å‘è€…ï¼ŒåŒ…å«é¡¹ç›®ç»“æ„ã€æ ¸å¿ƒä»£ç è¯´æ˜å’Œæ‰©å±•æŒ‡å—ã€‚

---

## ç›®å½•

- [é¡¹ç›®ç»“æ„](#é¡¹ç›®ç»“æ„)
- [æŠ€æœ¯æ ˆ](#æŠ€æœ¯æ ˆ)
- [æ ¸å¿ƒæ¨¡å—](#æ ¸å¿ƒæ¨¡å—)
- [æ‰©å±•å¼€å‘](#æ‰©å±•å¼€å‘)
- [è°ƒè¯•æŠ€å·§](#è°ƒè¯•æŠ€å·§)

---

## é¡¹ç›®ç»“æ„

```
data-synthesis-system/
â”œâ”€â”€ config/                      # é…ç½®æ¨¡å—
â”‚   â”œâ”€â”€ settings.py             # ç³»ç»Ÿè®¾ç½®ï¼ˆç¯å¢ƒå˜é‡ï¼‰
â”‚   â”œâ”€â”€ llm_config.py           # LLMå®ä¾‹åŒ–
â”‚   â””â”€â”€ prompts.py              # Promptæ¨¡æ¿
â”‚
â”œâ”€â”€ src/                        # æ ¸å¿ƒä»£ç 
â”‚   â”œâ”€â”€ models.py               # Pydanticæ•°æ®æ¨¡å‹
â”‚   â”œâ”€â”€ agents.py               # ä¸‰ä¸ªAgentå®ç°
â”‚   â”œâ”€â”€ graph.py                # LangGraphå·¥ä½œæµ
â”‚   â””â”€â”€ utils.py                # å·¥å…·å‡½æ•°
â”‚
â”œâ”€â”€ data/                       # æ•°æ®ç›®å½•
â”‚   â”œâ”€â”€ uploads/                # ä¸Šä¼ æ–‡æ¡£
â”‚   â””â”€â”€ outputs/                # è¾“å‡ºJSON
â”‚
â”œâ”€â”€ logs/                       # æ—¥å¿—æ–‡ä»¶
â”œâ”€â”€ docs/                       # æ–‡æ¡£
â”œâ”€â”€ web_ui.py                   # Webç•Œé¢å…¥å£
â””â”€â”€ requirements.txt            # ä¾èµ–åˆ—è¡¨
```

### æ ¸å¿ƒæ–‡ä»¶è¯´æ˜

| æ–‡ä»¶ | è¯´æ˜ | ä¿®æ”¹åœºæ™¯ |
|------|------|----------|
| `config/settings.py` | ç¯å¢ƒå˜é‡é…ç½® | æ·»åŠ æ–°é…ç½®é¡¹ |
| `config/prompts.py` | Promptæ¨¡æ¿ | ä¼˜åŒ–ç”Ÿæˆè´¨é‡ |
| `src/models.py` | æ•°æ®æ¨¡å‹ | æ‰©å±•æ•°æ®ç»“æ„ |
| `src/agents.py` | Agentå®ç° | ä¿®æ”¹Agentè¡Œä¸º |
| `src/graph.py` | å·¥ä½œæµç¼–æ’ | è°ƒæ•´æµç¨‹é€»è¾‘ |
| `web_ui.py` | Webç•Œé¢ | ä¿®æ”¹UIåŠŸèƒ½ |

---

## æŠ€æœ¯æ ˆ

### æ ¸å¿ƒæ¡†æ¶

- **LangGraph**: å¤šAgentå·¥ä½œæµç¼–æ’
- **LangChain**: LLMè°ƒç”¨å’Œç®¡ç†
- **Pydantic**: æ•°æ®éªŒè¯
- **Gradio**: Web UI

### ä¾èµ–åº“

```
langgraph>=0.0.30
langchain>=0.1.0
langchain-openai>=0.0.5
gradio>=4.0.0
pydantic>=2.0.0
pydantic-settings>=2.0.0
loguru>=0.7.0
python-dotenv>=1.0.0
```

---

## æ ¸å¿ƒæ¨¡å—

### 1. æ•°æ®æ¨¡å‹ (src/models.py)

**ä¸»è¦æ¨¡å‹**ï¼š

```python
class TaskType(Enum):
    """ä»»åŠ¡ç±»å‹æšä¸¾"""
    LOGICAL_REASONING = "é€»è¾‘æ¨ç†ç±»"
    NUMERICAL_CALCULATION = "æ•°å€¼è®¡ç®—ç±»"
    INFORMATION_QUERY = "ä¿¡æ¯æŸ¥è¯¢ç±»"
    SUMMARIZATION = "æ€»ç»“æ‘˜è¦ç±»"

class QAPair(BaseModel):
    """é—®ç­”å¯¹"""
    question: str
    answer: str
    reasoning: str
    task_type: TaskType
    iteration: int
    score: float
    timestamp: datetime

class ProposerOutput(BaseModel):
    """æè®®è€…è¾“å‡º"""
    question: str
    answer: str
    reasoning: str

class SolverOutput(BaseModel):
    """æ±‚è§£è€…è¾“å‡º"""
    reasoning_steps: List[str]
    final_answer: str

class ValidatorOutput(BaseModel):
    """éªŒè¯è€…è¾“å‡ºï¼ˆè¯„åˆ†åˆ¶ï¼‰"""
    score: float  # 1-10åˆ†
    reasoning: str
    feedback: str
```

### 2. Agentå®ç° (src/agents.py)

**ä¸‰ä¸ªAgent**ï¼š

```python
class ProposerAgent:
    """æè®®è€…ï¼šç”Ÿæˆé—®ç­”å¯¹"""
    def generate_qa_pair(
        document: str,
        task_type: TaskType,
        history_buffer: List[QAPair]
    ) -> ProposerOutput

class SolverAgent:
    """æ±‚è§£è€…ï¼šå°è¯•å›ç­”"""
    def solve(
        document: str,
        question: str
    ) -> SolverOutput

class ValidatorAgent:
    """éªŒè¯è€…ï¼šè¯„åˆ†1-10"""
    def validate(
        question: str,
        reference_answer: str,
        solver_answer: str
    ) -> ValidatorOutput
```

**é”™è¯¯å¤„ç†**ï¼š
- JSONè§£æå®¹é”™
- è¿”å›é»˜è®¤å€¼è€ŒéæŠ›å‡ºå¼‚å¸¸
- ä¼˜é›…é™çº§æœºåˆ¶

### 3. å·¥ä½œæµç¼–æ’ (src/graph.py)

**LangGraphçŠ¶æ€å›¾**ï¼š

```python
class DataSynthesisGraph:
    """æ•°æ®åˆæˆå·¥ä½œæµ"""
    
    # å››ä¸ªèŠ‚ç‚¹
    def _propose_node(state) -> dict
    def _solve_node(state) -> dict
    def _validate_node(state) -> dict
    def _update_node(state) -> dict
    
    # æ¡ä»¶åˆ†æ”¯
    def _should_continue(state) -> str
    
    # æµå¼æ‰§è¡Œ
    def stream(state_dict) -> Iterator[dict]
```

**èŠ‚ç‚¹æµè½¬**ï¼š
```
START â†’ propose â†’ solve â†’ validate â†’ update
         â†‘                             â†“
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ å¾ªç¯ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â†“
                                      END
```

### 4. Web UI (web_ui.py)

**ä¸»è¦åŠŸèƒ½**ï¼š
- æ–‡æ¡£è¾“å…¥ï¼ˆæ–‡æœ¬/æ–‡ä»¶ï¼‰
- å‚æ•°é…ç½®ï¼ˆæ¸©åº¦/é˜ˆå€¼ï¼‰
- Promptsç¼–è¾‘
- å®æ—¶ç›‘æ§
- åœæ­¢æ§åˆ¶

**å…³é”®å‡½æ•°**ï¼š
```python
def synthesis_workflow_generator(...)
    """ç”Ÿæˆå™¨å‡½æ•°ï¼Œæµå¼è¾“å‡ºçŠ¶æ€"""
    
def format_iteration_detail(detail, iteration)
    """æ ¼å¼åŒ–è¿­ä»£è¯¦æƒ…ï¼Œå½©è‰²åŒºå—æ˜¾ç¤º"""
    
def stop_synthesis()
    """åœæ­¢æ§åˆ¶"""
```

---

## æ‰©å±•å¼€å‘

### æ·»åŠ æ–°ä»»åŠ¡ç±»å‹

**1. ä¿®æ”¹æ¨¡å‹ (src/models.py)**

```python
class TaskType(str, Enum):
    LOGICAL_REASONING = "é€»è¾‘æ¨ç†ç±»"
    # ...ç°æœ‰ç±»å‹...
    YOUR_NEW_TYPE = "ä½ çš„æ–°ç±»å‹"  # æ·»åŠ è¿™é‡Œ
```

**2. æ›´æ–°Prompt (config/prompts.py)**

åœ¨proposerçš„system promptä¸­æ·»åŠ æ–°ç±»å‹è¯´æ˜ï¼š

```python
ä»»åŠ¡ç±»å‹è¯´æ˜ï¼š
- é€»è¾‘æ¨ç†ç±»ï¼š...
- ä½ çš„æ–°ç±»å‹ï¼šç‰¹ç‚¹å’Œè¦æ±‚  # æ·»åŠ è¿™é‡Œ
```

**3. æ›´æ–°UI (web_ui.py)**

Task typeé€‰æ‹©å™¨ä¼šè‡ªåŠ¨è¯»å–TaskTypeæšä¸¾ï¼Œæ— éœ€ä¿®æ”¹ã€‚

### æ·»åŠ æ–°Agent

**1. å®ç°Agentç±» (src/agents.py)**

```python
class YourNewAgent:
    def __init__(self):
        self.llm = get_llm(...)
    
    def your_method(self, ...):
        # å®ç°é€»è¾‘
        pass
```

**2. æ›´æ–°å·¥ä½œæµ (src/graph.py)**

```python
def __init__(self):
    self.your_agent = YourNewAgent()
    
def _your_node(self, state):
    output = self.your_agent.your_method(...)
    state["your_output"] = output
    return state

# åœ¨_build_graphä¸­æ·»åŠ èŠ‚ç‚¹
workflow.add_node("your_node", self._your_node)
workflow.add_edge("validate", "your_node")
workflow.add_edge("your_node", "update")
```

### è‡ªå®šä¹‰è¯„åˆ†æ ‡å‡†

**ä¿®æ”¹ config/prompts.py**ï¼š

```python
"validator": {
    "system": """
    ä½ æ˜¯ä¸“ä¸šè¯„ä¼°è€…ï¼Œä½¿ç”¨ä»¥ä¸‹æ ‡å‡†ï¼š
    1. è‡ªå®šä¹‰æ ‡å‡†1ï¼ˆæƒé‡40%ï¼‰
    2. è‡ªå®šä¹‰æ ‡å‡†2ï¼ˆæƒé‡30%ï¼‰
    ...
    """
}
```

**ä¿®æ”¹ src/graph.py**ï¼š

```python
# å¯ä»¥å®ç°è‡ªå®šä¹‰é˜ˆå€¼é€»è¾‘
score_threshold = state.get("score_threshold", settings.score_threshold)
custom_threshold = calculate_custom_threshold(...)  # è‡ªå®šä¹‰è®¡ç®—
is_valid = score >= custom_threshold
```

### æ·»åŠ æ–°é…ç½®å‚æ•°

**1. æ·»åŠ åˆ° settings.py**ï¼š

```python
class Settings(BaseSettings):
    # ...ç°æœ‰é…ç½®...
    your_new_param: str = "default_value"
```

**2. åœ¨ .env ä¸­è®¾ç½®**ï¼š

```bash
YOUR_NEW_PARAM=your_value
```

**3. åœ¨ä»£ç ä¸­ä½¿ç”¨**ï¼š

```python
from config import settings
value = settings.your_new_param
```

---

## è°ƒè¯•æŠ€å·§

### æ—¥å¿—æŸ¥çœ‹

**å®æ—¶æ—¥å¿—**ï¼š
```bash
tail -f logs/web_ui_*.log
```

**ç­›é€‰é”™è¯¯**ï¼š
```bash
grep ERROR logs/*.log
```

**æŸ¥çœ‹ç‰¹å®šAgent**ï¼š
```bash
grep "ProposerAgent" logs/*.log
```

### è°ƒè¯•æ¨¡å¼

**å¯ç”¨è¯¦ç»†æ—¥å¿—** (config/llm_config.py)ï¼š

```python
def get_llm(...):
    return ChatOpenAI(
        ...
        verbose=True,  # æ·»åŠ è¿™è¡Œ
    )
```

**è°ƒè¯•å•ä¸ªAgent**ï¼š

```python
from src.agents import ProposerAgent
from src.models import TaskType

agent = ProposerAgent()
output = agent.generate_qa_pair(
    document="æµ‹è¯•æ–‡æ¡£",
    task_type=TaskType.LOGICAL_REASONING,
    history_buffer=[]
)
print(output)
```

### æµ‹è¯•å·¥ä½œæµ

```python
from src.graph import DataSynthesisGraph

state = {
    "document": "æµ‹è¯•æ–‡æ¡£",
    "task_type": "é€»è¾‘æ¨ç†ç±»",
    "max_iterations": 3,
    "score_threshold": 7.0,
}

graph = DataSynthesisGraph()
result = graph.run(state)
print(f"ç”Ÿæˆ{len(result['valid_pairs'])}ä¸ªé—®ç­”å¯¹")
```

### å¸¸è§é—®é¢˜æ’æŸ¥

**1. JSONè§£æé”™è¯¯**
- æ£€æŸ¥LLMè¿”å›æ ¼å¼
- æŸ¥çœ‹logsä¸­çš„"Raw content"
- è°ƒæ•´Promptä½¿è¾“å‡ºæ›´è§„èŒƒ

**2. éªŒè¯æ€»æ˜¯å¤±è´¥**
- é™ä½score_threshold
- æ£€æŸ¥Validatorçš„prompt
- æŸ¥çœ‹feedbackäº†è§£å¤±è´¥åŸå› 

**3. ç”Ÿæˆé€Ÿåº¦æ…¢**
- æ£€æŸ¥APIå“åº”æ—¶é—´
- è€ƒè™‘ä½¿ç”¨æ›´å¿«çš„æ¨¡å‹
- å‡å°‘max_tokens

**4. å†…å­˜å ç”¨é«˜**
- æ¸…ç†history_buffer
- å‡å°‘max_iterations
- ä¼˜åŒ–æ–‡æ¡£é•¿åº¦

---

## APIå‚è€ƒ

### ä¸»è¦ç±»å’Œå‡½æ•°

**DataSynthesisGraph**ï¼š
```python
graph = DataSynthesisGraph()
# æµå¼æ‰§è¡Œ
for output in graph.stream(state):
    process(output)
# æˆ–ä¸€æ¬¡æ€§æ‰§è¡Œ
result = graph.run(state)
```

**å·¥å…·å‡½æ•°** (src/utils.py)ï¼š
```python
# ä¿å­˜é—®ç­”å¯¹
save_qa_pairs(qa_pairs, task_type) -> str

# è¯»å–æ–‡æ¡£
read_document_file(file_path) -> str

# æ ¼å¼åŒ–æ˜¾ç¤º
format_qa_for_display(qa, index) -> str
```

---

## è´¡çŒ®æŒ‡å—

### ä»£ç è§„èŒƒ

- ä½¿ç”¨ç±»å‹æç¤º
- æ·»åŠ docstring
- éµå¾ªPEP 8
- ç¼–å†™å•å…ƒæµ‹è¯•

### æäº¤æµç¨‹

1. Forké¡¹ç›®
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯
3. æäº¤ä»£ç 
4. å‘èµ·Pull Request

### æµ‹è¯•

```bash
# è¿è¡Œæµ‹è¯•ï¼ˆå¦‚æœæœ‰ï¼‰
python -m pytest tests/

# ä»£ç æ£€æŸ¥
flake8 src/
mypy src/
```

---

## æ€§èƒ½ä¼˜åŒ–

### å¹¶è¡Œå¤„ç†

å¯ä»¥ä¿®æ”¹ä¸ºå¹¶è¡Œç”Ÿæˆï¼š

```python
import asyncio
from langchain.callbacks import get_openai_callback

async def parallel_generation():
    tasks = [
        agent.generate_qa_pair_async(...)
        for _ in range(batch_size)
    ]
    results = await asyncio.gather(*tasks)
    return results
```

### ç¼“å­˜ç­–ç•¥

```python
from functools import lru_cache

@lru_cache(maxsize=100)
def cached_llm_call(prompt):
    return llm.invoke(prompt)
```

---

## è”ç³»ä¸æ”¯æŒ

- ğŸ“§ æäº¤Issue: [GitHub Issues](https://github.com/your-repo/issues)
- ğŸ’¬ è®¨è®ºåŒº: [GitHub Discussions](https://github.com/your-repo/discussions)
- ğŸ“– æ–‡æ¡£: [docs/](docs/)
