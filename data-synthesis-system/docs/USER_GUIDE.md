# 用户使用指南

欢迎使用 Multi-Agent 数据合成系统！本指南将帮助你快速上手并充分利用系统功能。

## 📚 目录

- [系统简介](#系统简介)
- [快速开始](#快速开始)
- [界面介绍](#界面介绍)
- [使用流程](#使用流程)
- [任务类型选择](#任务类型选择)
- [参数调优](#参数调优)
- [常见问题](#常见问题)
- [最佳实践](#最佳实践)

## 系统简介

Multi-Agent 数据合成系统是一个专为大模型训练设计的数据生成工具。它通过三个智能体（提议者、求解者、验证者）的协作，自动生成高质量、高难度的问答数据。

### 核心优势

- ✅ **自动质量保证**：只保留通过验证的问答对
- ✅ **难度递增**：后续问题比之前的更难、更有深度
- ✅ **多样性保证**：避免重复模式，生成创新问题
- ✅ **即用训练**：输出可直接用于模型 Pretrain 和 SFT

## 快速开始

### 1. 系统启动

在终端中运行：

```bash
cd data-synthesis-system
./start.sh
```

首次运行会自动安装依赖，后续启动会更快。

### 2. 访问界面

启动成功后，浏览器自动打开或手动访问：

```
http://localhost:7860
```

### 3. 配置 API Key

确保 `.env` 文件中已配置正确的 API Key：

```bash
OPENAI_API_KEY=your-api-key-here
OPENAI_API_BASE=https://api.openai.com/v1
```

## 界面介绍

### 左侧：输入配置区

#### 1. 文档内容输入

**方式一：直接粘贴文本**
- 在文本框中粘贴你的文档内容
- 支持任意长度的文本（建议 500-5000 字）
- 可以是文章、报告、教材、论文等

**方式二：上传文件**
- 点击上传按钮选择文件
- 支持格式：`.txt`, `.md`
- 文件优先级高于文本框输入

#### 2. 任务类型选择

选择你想要生成的数据类型：

- **逻辑推理类**：需要多步推理、因果分析的问题
- **数值计算类**：需要数学计算、数据分析的问题
- **信息查询类**：需要查找、整合信息的问题
- **总结摘要类**：需要概括、提炼的问题

#### 3. 迭代次数设置

- **范围**：1-20 次
- **建议**：5-15 次
- **说明**：
  - 次数越多，生成的问答对越多
  - 但同时耗时和成本也会增加
  - 建议从 5 次开始测试

### 右侧：结果展示区

#### 1. 状态栏

实时显示当前执行状态：
- ✅ 成功生成的问答对数量
- ⏳ 当前执行进度
- ❌ 错误信息（如有）

#### 2. 问答对展示

以 Markdown 格式展示生成的每个问答对：
- 问题内容
- 答案内容
- 生成理由（为什么这是个好问题）
- 迭代次数

#### 3. 下载按钮

生成完成后，点击下载按钮获取 JSON 文件，包含所有问答对。

## 使用流程

### 完整示例

假设你想为一篇关于"机器学习算法"的文章生成逻辑推理类问答对：

**步骤 1：准备文档**

```
机器学习是人工智能的一个分支，它使计算机系统能够从数据中学习并改进...
（完整文章内容）
```

**步骤 2：配置参数**

- 任务类型：选择"逻辑推理类"
- 迭代次数：设置为 10

**步骤 3：开始生成**

点击"🚀 开始合成"按钮

**步骤 4：观察过程**

系统会显示：
```
=== Iteration 1/10 ===
Proposer generating new question...
✓ Question generated: 为什么监督学习需要标注数据？

Solver attempting to answer...
✓ Solver answer: 监督学习需要标注数据是因为...

Validator checking answer...
✓ Validation PASSED
Valid QA pairs: 1

=== Iteration 2/10 ===
...
```

**步骤 5：查看结果**

在右侧看到生成的问答对：

```markdown
### 问答对 1

**问题：**
为什么监督学习需要标注数据，而无监督学习不需要？

**答案：**
监督学习需要标注数据是因为...

**推理：**
这个问题需要理解监督学习和无监督学习的本质区别...

**迭代次数：** 1
```

**步骤 6：下载数据**

点击下载按钮，获得 `qa_pairs_逻辑推理类_20241224_103000.json`

## 任务类型选择

### 如何选择合适的任务类型？

根据你的文档内容和训练目标选择：

#### 逻辑推理类

**适用场景：**
- 文档包含观点、论证、因果关系
- 想训练模型的推理能力
- 需要多步思考的问题

**示例问题：**
- "为什么作者认为 X 比 Y 更有效？"
- "如果 A 发生，那么 B 会如何变化？"
- "文档中的观点 1 和观点 2 有什么矛盾？"

#### 数值计算类

**适用场景：**
- 文档包含数据、统计、公式
- 想训练模型的计算能力
- 需要数学推导

**示例问题：**
- "根据文档数据，计算平均增长率"
- "如果参数 X 增加 10%，结果会是多少？"
- "比较表格中哪个指标最高"

#### 信息查询类

**适用场景：**
- 文档信息量大、结构复杂
- 想训练模型的检索能力
- 需要整合多处信息

**示例问题：**
- "文档中提到了哪些应用场景？"
- "作者在第三段和第七段分别讨论了什么？"
- "整合文档信息，列出所有优势"

#### 总结摘要类

**适用场景：**
- 文档较长、需要概括
- 想训练模型的总结能力
- 需要提炼核心内容

**示例问题：**
- "总结文档的核心观点"
- "用一段话概括作者的主要论证"
- "提炼文档中的关键信息点"

## 参数调优

### 迭代次数

| 次数 | 适用场景 | 预期输出 | 预计耗时 |
|------|----------|----------|----------|
| 1-3  | 快速测试 | 1-3 个问答对 | 1-2 分钟 |
| 5-10 | 标准使用 | 3-8 个问答对 | 3-8 分钟 |
| 10-15 | 大量数据 | 8-12 个问答对 | 8-15 分钟 |
| 15-20 | 极限模式 | 12-18 个问答对 | 15-25 分钟 |

**注意：**
- 实际生成数量 < 迭代次数（因为有些问答对可能无法通过验证）
- 通过率通常在 60-80%

### 文档长度

| 长度 | 适用场景 | 建议迭代次数 |
|------|----------|--------------|
| 500-1000 字 | 短文章 | 3-5 次 |
| 1000-3000 字 | 标准文章 | 5-10 次 |
| 3000-5000 字 | 长文章 | 10-15 次 |
| 5000+ 字 | 超长文档 | 15-20 次 |

**建议：**
- 文档越长，信息点越多，可设置更多迭代次数
- 太短的文档可能难以生成高难度问题

### LLM 模型选择

在 `.env` 文件中配置：

```bash
# 使用更强的模型获得更好质量
PROPOSER_MODEL=gpt-4-turbo-preview
SOLVER_MODEL=gpt-4-turbo-preview
VALIDATOR_MODEL=gpt-4-turbo-preview

# 或使用更经济的模型
PROPOSER_MODEL=gpt-3.5-turbo
SOLVER_MODEL=gpt-3.5-turbo
VALIDATOR_MODEL=gpt-4-turbo-preview  # 验证者建议使用更强模型
```

## 常见问题

### Q1: 生成的问答对数量少于迭代次数？

**原因：** 某些问答对未通过验证

**解决：**
- 增加迭代次数以获得更多有效数据
- 检查文档质量，确保信息充分
- 调整 Prompt（高级用户）

### Q2: 所有问答对都未通过验证？

**原因：** 文档质量或任务类型不匹配

**解决：**
- 检查文档是否太短或信息不足
- 尝试其他任务类型
- 查看日志了解具体失败原因

### Q3: 系统运行很慢？

**原因：** LLM API 调用需要时间

**解决：**
- 这是正常现象，每次迭代需要 3 次 LLM 调用
- 减少迭代次数以加快速度
- 使用更快的 LLM API

### Q4: API 调用失败？

**原因：** API Key 配置错误或网络问题

**解决：**
- 检查 `.env` 文件中的 API Key 是否正确
- 检查 `OPENAI_API_BASE` 是否配置正确
- 查看日志文件 `logs/system_*.log` 了解详情

### Q5: 生成的问题不够难？

**原因：** 可能是前几轮迭代

**解决：**
- 增加迭代次数，后续问题会更难
- 调整 Prompt 提高难度要求（高级用户）
- 使用更强大的 LLM 模型

## 最佳实践

### 1. 文档准备

✅ **好的文档：**
- 信息充分、结构清晰
- 包含观点、论证、数据
- 长度适中（1000-3000 字）
- 主题明确、内容连贯

❌ **不好的文档：**
- 过短或信息稀少
- 纯列表或目录
- 格式混乱、缺乏逻辑
- 多个不相关主题混杂

### 2. 任务类型匹配

| 文档类型 | 推荐任务类型 |
|----------|--------------|
| 学术论文 | 逻辑推理类 |
| 技术文档 | 信息查询类 |
| 数据报告 | 数值计算类 |
| 新闻文章 | 总结摘要类 |

### 3. 迭代策略

**初次使用：**
1. 从 5 次迭代开始测试
2. 观察生成质量
3. 根据结果调整参数

**批量生成：**
1. 为每个文档生成 10-15 个问答对
2. 人工筛选最优质的数据
3. 合并多个文档的结果

### 4. 质量评估

生成后，建议人工检查：
- ✓ 问题是否基于文档内容
- ✓ 答案是否准确完整
- ✓ 问题是否有难度和深度
- ✓ 是否避免了重复模式

### 5. 成本控制

**估算成本：**
- 每次迭代 ≈ 3 次 LLM 调用
- 每次调用 ≈ 1000-2000 tokens
- 10 次迭代 ≈ 30 次调用 ≈ 30,000-60,000 tokens

**节省成本：**
- 使用更经济的模型（如 GPT-3.5）
- 减少不必要的迭代次数
- 批量处理多个文档

## 输出数据使用

### JSON 格式说明

```json
[
  {
    "question": "问题内容",
    "answer": "答案内容",
    "reasoning": "为什么这是个好问题",
    "task_type": "逻辑推理类",
    "iteration": 1,
    "timestamp": "2024-12-24T10:30:00"
  }
]
```

### 转换为训练格式

**SFT 格式：**

```python
import json

# 读取生成的数据
with open('qa_pairs_xxx.json', 'r') as f:
    data = json.load(f)

# 转换为 SFT 格式
sft_data = []
for item in data:
    sft_data.append({
        "instruction": item["question"],
        "output": item["answer"]
    })

# 保存
with open('sft_data.json', 'w') as f:
    json.dump(sft_data, f, ensure_ascii=False, indent=2)
```

### 数据合并

合并多个文档生成的数据：

```python
import json
from glob import glob

all_data = []
for file in glob('data/outputs/qa_pairs_*.json'):
    with open(file, 'r') as f:
        all_data.extend(json.load(f))

# 去重（基于问题）
unique_data = []
seen_questions = set()
for item in all_data:
    if item['question'] not in seen_questions:
        unique_data.append(item)
        seen_questions.add(item['question'])

# 保存合并结果
with open('merged_qa_pairs.json', 'w') as f:
    json.dump(unique_data, f, ensure_ascii=False, indent=2)
```

## 技术支持

遇到问题？

1. 查看日志文件：`logs/system_*.log`
2. 阅读开发指南：`docs/DEVELOPER_GUIDE.md`
3. 提交 Issue：在 GitHub 上报告问题

---

祝使用愉快！如有任何问题或建议，欢迎反馈。
