# å¼€å‘æŒ‡å—

> ğŸ“˜ **é¢å‘äººç¾¤**ï¼šå¼€å‘è€…ã€è´¡çŒ®è€…  
> ğŸ“Œ **æ–‡æ¡£ç›®çš„**ï¼šäºŒæ¬¡å¼€å‘ã€æ¨¡å—æ‰©å±•ã€ä»£ç è¯´æ˜

---

## ğŸ“‹ å¿«é€Ÿå¯¼èˆª

- [å¼€å‘ç¯å¢ƒ](#å¼€å‘ç¯å¢ƒæ­å»º) - ç¯å¢ƒé…ç½®ä¸ä¾èµ–å®‰è£…
- [é¡¹ç›®ç»“æ„](#é¡¹ç›®ç»“æ„) - ç›®å½•ç»„ç»‡ä¸æ¨¡å—è¯´æ˜
- [æ ¸å¿ƒæ¨¡å—](#æ ¸å¿ƒæ¨¡å—è¯¦è§£) - ä»£ç å®ç°è¯¦è§£
- [æ‰©å±•å¼€å‘](#æ‰©å±•æŒ‡å—) - è‡ªå®šä¹‰åŠŸèƒ½å¼€å‘
- [æµ‹è¯•è°ƒè¯•](#æµ‹è¯•ä¸è°ƒè¯•) - å•å…ƒæµ‹è¯•ä¸è°ƒè¯•æŠ€å·§
- [éƒ¨ç½²ä¸Šçº¿](#éƒ¨ç½²æŒ‡å—) - ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²æ–¹æ¡ˆ

---

## å¼€å‘ç¯å¢ƒæ­å»º

### ç³»ç»Ÿè¦æ±‚

| é¡¹ç›® | è¦æ±‚ |
|------|------|
| **æ“ä½œç³»ç»Ÿ** | macOS / Linux / Windows (WSL2) |
| **Python** | 3.10+ |
| **å†…å­˜** | æœ€å° 4GBï¼Œæ¨è 8GB+ |
| **ç£ç›˜** | 500MB+ |

### å¿«é€Ÿå¼€å§‹

\`\`\`bash
# 1. å…‹éš†é¡¹ç›®
git clone https://github.com/pengshuang/Awesome-Agent-Projects.git
cd Awesome-Agent-Projects/interview-coach

# 2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆæ¨è condaï¼‰
conda create -n interview-coach python=3.10
conda activate interview-coach

# 3. å®‰è£…ä¾èµ–
pip install -r requirements.txt        # ç”Ÿäº§ä¾èµ–
pip install -r requirements-dev.txt    # å¼€å‘å·¥å…·

# 4. é…ç½®ç¯å¢ƒ
cp .env.example .env
# ç¼–è¾‘ .env å¡«å†™ LLM_API_KEY ç­‰é…ç½®

# 5. éªŒè¯å®‰è£…
pytest -v                              # è¿è¡Œæµ‹è¯•
python web_ui.py                       # å¯åŠ¨åº”ç”¨
\`\`\`

### å¼€å‘å·¥å…·é…ç½®

**æ¨è VS Code æ’ä»¶**ï¼š
- Python (Pylance)
- Black Formatter
- isort
- GitLens

**ä»£ç è´¨é‡å·¥å…·**ï¼š
\`\`\`bash
# ä»£ç æ ¼å¼åŒ–
black .
isort .

# ä»£ç æ£€æŸ¥
flake8 src/ tests/
mypy src/

# è¿è¡Œæµ‹è¯•
pytest --cov=src --cov-report=html
\`\`\`

---

## é¡¹ç›®ç»“æ„

\`\`\`
interview-coach/
â”œâ”€â”€ config/                 # é…ç½®ç®¡ç†
â”‚   â”œâ”€â”€ settings.py        # SystemConfig (Pydantic Settings)
â”‚   â”œâ”€â”€ llm_config.py      # LLM å®¢æˆ·ç«¯å·¥å‚
â”‚   â””â”€â”€ prompts.py         # Prompt æ¨¡æ¿ç®¡ç†
â”‚
â”œâ”€â”€ src/                    # æ ¸å¿ƒä¸šåŠ¡é€»è¾‘
â”‚   â”œâ”€â”€ models/            # Pydantic æ•°æ®æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ resume.py      # ç®€å†æ•°æ®æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ evaluation.py  # è¯„ä¼°ç»“æœæ¨¡å‹
â”‚   â”‚   â””â”€â”€ interview.py   # é¢è¯•ä¼šè¯æ¨¡å‹
â”‚   â”‚
â”‚   â”œâ”€â”€ loaders/           # æ–‡ä»¶åŠ è½½å™¨
â”‚   â”‚   â””â”€â”€ resume_loader.py  # PDF è§£æ
â”‚   â”‚
â”‚   â”œâ”€â”€ evaluator/         # ç®€å†è¯„ä¼°å¼•æ“
â”‚   â”‚   â””â”€â”€ resume_evaluator.py
â”‚   â”‚
â”‚   â”œâ”€â”€ interview/         # é¢è¯•ä»£ç†
â”‚   â”‚   â””â”€â”€ interview_agent.py
â”‚   â”‚
â”‚   â”œâ”€â”€ tools/             # å¤–éƒ¨å·¥å…·
â”‚   â”‚   â””â”€â”€ web_search.py  # DuckDuckGo æœç´¢
â”‚   â”‚
â”‚   â””â”€â”€ utils/             # é€šç”¨å·¥å…·
â”‚       â”œâ”€â”€ logger.py      # Loguru æ—¥å¿—
â”‚       â””â”€â”€ helpers.py     # è¾…åŠ©å‡½æ•°
â”‚
â”œâ”€â”€ tests/                 # å•å…ƒæµ‹è¯•
â”œâ”€â”€ docs/                  # æ–‡æ¡£
â”œâ”€â”€ web_ui.py              # Gradio UI å…¥å£
â””â”€â”€ requirements.txt       # ä¾èµ–æ¸…å•
\`\`\`

### æ¨¡å—èŒè´£åˆ’åˆ†

| æ¨¡å— | èŒè´£ | æ ¸å¿ƒç±»/å‡½æ•° |
|------|------|------------|
| `config` | é…ç½®ç®¡ç† | `SystemConfig`, `get_config()` |
| `src/models` | æ•°æ®å»ºæ¨¡ | `ResumeData`, `EvaluationResult` |
| `src/loaders` | æ–‡ä»¶è§£æ | `ResumeLoader` |
| `src/evaluator` | ç®€å†è¯„ä¼° | `ResumeEvaluator` |
| `src/interview` | é¢è¯•å¯¹è¯ | `InterviewAgent` |
| `src/tools` | å¤–éƒ¨å·¥å…· | `WebSearchTool` |

---

## æ ¸å¿ƒæ¨¡å—è¯¦è§£

### 1. é…ç½®ç®¡ç† (config/)

#### SystemConfig - é…ç½®ç±»

ä½¿ç”¨ **Pydantic Settings** å®ç°ç±»å‹å®‰å…¨é…ç½®ï¼Œè‡ªåŠ¨ä» `.env` åŠ è½½ã€‚

\`\`\`python
# config/settings.py
from pydantic import Field
from pydantic_settings import BaseSettings

class SystemConfig(BaseSettings):
    \"\"\"ç³»ç»Ÿé…ç½®\"\"\"
    model_config = SettingsConfigDict(env_file=".env")
    
    # LLM é…ç½®
    llm_api_key: str = Field(..., alias="LLM_API_KEY")
    llm_api_base: str = Field(default="https://api.openai.com/v1")
    llm_model: str = Field(default="gpt-3.5-turbo")
    temperature: float = Field(default=0.7, ge=0.0, le=2.0)
    
    # é¢è¯•é…ç½®
    max_history_turns: int = Field(default=20, ge=1, le=100)
    
# å•ä¾‹æ¨¡å¼
def get_config() -> SystemConfig:
    global _config
    if _config is None:
        _config = SystemConfig()
    return _config
\`\`\`

**æ‰©å±•é…ç½®**ï¼šåœ¨ `SystemConfig` ç±»ä¸­æ·»åŠ æ–°å­—æ®µå³å¯ã€‚

#### LLM å®¢æˆ·ç«¯å·¥å‚

\`\`\`python
# config/llm_config.py
from openai import OpenAI

def get_llm_client(api_key: str, api_base: str, model: str, temperature: float):
    client = OpenAI(api_key=api_key, base_url=api_base)
    return client, model, temperature
\`\`\`

---

### 2. æ•°æ®æ¨¡å‹ (src/models/)

#### resume.py - ç®€å†æ•°æ®

\`\`\`python
from pydantic import BaseModel, Field, field_validator

class ResumeMetadata(BaseModel):
    \"\"\"ç®€å†å…ƒæ•°æ®\"\"\"
    file_name: str
    file_size: int = Field(ge=0)
    content_length: int = Field(ge=0)
    load_time: float = Field(ge=0)
    
    @field_validator("file_size")
    @classmethod
    def validate_file_size(cls, v: int) -> int:
        if v > 100 * 1024 * 1024:  # 100MB
            raise ValueError("æ–‡ä»¶ä¸èƒ½è¶…è¿‡ 100MB")
        return v

class ResumeData(BaseModel):
    \"\"\"ç®€å†å®Œæ•´æ•°æ®\"\"\"
    content: str = Field(min_length=1)
    metadata: ResumeMetadata
\`\`\`

**æ‰©å±•ç¤ºä¾‹**ï¼šæ·»åŠ ç« èŠ‚è§£æ
\`\`\`python
class ResumeData(BaseModel):
    content: str
    metadata: ResumeMetadata
    parsed_sections: dict[str, str] = Field(default_factory=dict)  # æ–°å¢
\`\`\`

#### evaluation.py - è¯„ä¼°ç»“æœ

\`\`\`python
class ScoreDetails(BaseModel):
    \"\"\"6 ç»´åº¦è¯„åˆ†\"\"\"
    basic_info: int = Field(ge=0, le=10)
    work_experience: int = Field(ge=0, le=10)
    project_quality: int = Field(ge=0, le=10)
    skills_match: int = Field(ge=0, le=10)
    education: int = Field(ge=0, le=10)
    overall_impression: int = Field(ge=0, le=10)
    
    def get_total_score(self) -> float:
        \"\"\"æ€»åˆ†ï¼ˆ0-100ï¼‰\"\"\"
        scores = [self.basic_info, self.work_experience, ...]
        return round(sum(scores) / len(scores) * 10, 1)
\`\`\`

---

### 3. ç®€å†åŠ è½½å™¨ (src/loaders/)

#### ResumeLoader - PDF è§£æ

\`\`\`python
import pymupdf
from pathlib import Path
from src.models.resume import ResumeData, ResumeMetadata

class ResumeLoader:
    SUPPORTED_FORMATS = [".pdf"]
    
    def load_resume(self, file_path: str) -> ResumeData:
        \"\"\"åŠ è½½ç®€å†\"\"\"
        path_obj = Path(file_path)
        
        # éªŒè¯æ–‡ä»¶
        if not path_obj.exists():
            raise FileNotFoundError(file_path)
        if path_obj.suffix not in self.SUPPORTED_FORMATS:
            raise UnsupportedFileFormatError(path_obj.suffix)
        
        # è§£æ PDF
        content = self._load_pdf_pymupdf(path_obj)
        
        # æ„å»ºå…ƒæ•°æ®
        metadata = ResumeMetadata(
            file_name=path_obj.name,
            file_size=path_obj.stat().st_size,
            content_length=len(content),
            load_time=elapsed_time,
        )
        
        return ResumeData(content=content, metadata=metadata)
    
    def _load_pdf_pymupdf(self, file_path: Path) -> str:
        \"\"\"ä½¿ç”¨ PyMuPDF è§£æ\"\"\"
        text_content = []
        with pymupdf.open(file_path) as doc:
            for page in doc:
                text_content.append(page.get_text())
        return "\\n\\n".join(text_content)
\`\`\`

**æ‰©å±•æ”¯æŒ Word**ï¼š
\`\`\`python
import docx

def _load_docx(self, file_path: Path) -> str:
    doc = docx.Document(file_path)
    return "\\n\\n".join([p.text for p in doc.paragraphs if p.text.strip()])
\`\`\`

---

### 4. ç®€å†è¯„ä¼°å™¨ (src/evaluator/)

#### ResumeEvaluator - è¯„ä¼°å¼•æ“

\`\`\`python
from config import get_config, get_llm_client
from config.prompts import PromptTemplates

class ResumeEvaluator:
    def __init__(self):
        config = get_config()
        self.client, self.model, self.temperature = get_llm_client(
            api_key=config.llm_api_key,
            api_base=config.llm_api_base,
            model=config.llm_model,
            temperature=config.temperature,
        )
    
    def evaluate(self, resume_content: str, position: str = None) -> dict:
        \"\"\"å®Œæ•´è¯„ä¼°\"\"\"
        # æ„å»º Prompt
        prompt = PromptTemplates.get_evaluation_prompt(
            resume_content=resume_content,
            position=position or "é€šç”¨å²—ä½",
        )
        
        # è°ƒç”¨ LLM
        response = self.client.chat.completions.create(
            model=self.model,
            messages=[{"role": "user", "content": prompt}],
            temperature=self.temperature,
        )
        
        return {
            "evaluation": response.choices[0].message.content,
            "metadata": {"model": self.model}
        }
\`\`\`

---

### 5. é¢è¯•ä»£ç† (src/interview/)

#### InterviewAgent - å¯¹è¯ç®¡ç†

\`\`\`python
class InterviewAgent:
    def __init__(self, resume_content: str, interview_type: str, max_history_turns: int):
        config = get_config()
        self.client, self.model, self.temperature = get_llm_client(...)
        self.chat_history = []
        self.max_history_turns = max_history_turns
    
    def start_interview(self) -> dict:
        \"\"\"ç”Ÿæˆå¼€åœºç™½\"\"\"
        prompt = f"{self.system_prompt}\\n\\nè¯·ç»™å‡ºå¼€åœºç™½å¹¶æå‡ºç¬¬ä¸€ä¸ªé—®é¢˜ã€‚"
        response = self.client.chat.completions.create(...)
        opening = response.choices[0].message.content
        self.chat_history.append({"role": "assistant", "content": opening})
        return {"opening": opening}
    
    def chat(self, user_message: str) -> dict:
        \"\"\"å¤„ç†ç”¨æˆ·æ¶ˆæ¯\"\"\"
        self.chat_history.append({"role": "user", "content": user_message})
        
        # æ„å»ºæ¶ˆæ¯ï¼ˆä¿ç•™æœ€è¿‘ N è½®ï¼‰
        messages = [{"role": "system", "content": self.system_prompt}]
        messages.extend(self.chat_history[-self.max_history_turns:])
        
        # è°ƒç”¨ LLM
        response = self.client.chat.completions.create(...)
        assistant_message = response.choices[0].message.content
        
        self.chat_history.append({"role": "assistant", "content": assistant_message})
        return {"response": assistant_message}
\`\`\`

---

## æ‰©å±•æŒ‡å—

### 1. æ·»åŠ æ–°çš„ LLM æä¾›å•†

**éœ€æ±‚**ï¼šæ”¯æŒ Anthropic Claude

**æ­¥éª¤**ï¼š
1. åœ¨ `config/llm_config.py` æ·»åŠ å®¢æˆ·ç«¯å·¥å‚
2. æ›´æ–° `SystemConfig` æ·»åŠ é…ç½®é¡¹
3. æ›´æ–° `.env.example`

\`\`\`python
# config/llm_config.py
def get_claude_client(api_key: str, model: str = "claude-3-opus"):
    from anthropic import Anthropic
    client = Anthropic(api_key=api_key)
    return client, model, 0.7

# config/settings.py
class SystemConfig(BaseSettings):
    llm_provider: Literal["openai", "claude"] = "openai"
    claude_api_key: Optional[str] = None
\`\`\`

### 2. è‡ªå®šä¹‰è¯„ä¼°ç»´åº¦

**éœ€æ±‚**ï¼šæ·»åŠ "åˆ›æ–°èƒ½åŠ›"è¯„åˆ†ç»´åº¦

\`\`\`python
# src/models/evaluation.py
class ScoreDetails(BaseModel):
    basic_info: int = Field(ge=0, le=10)
    # ... å…¶ä»–ç»´åº¦
    innovation: int = Field(ge=0, le=10, description="åˆ›æ–°èƒ½åŠ›")  # æ–°å¢
    
    def get_total_score(self) -> float:
        scores = [self.basic_info, ..., self.innovation]  # åŒ…å«æ–°ç»´åº¦
        return round(sum(scores) / len(scores) * 10, 1)

# config/prompts.py
RESUME_EVALUATION = \"\"\"
è¯·ä»ä»¥ä¸‹7ä¸ªç»´åº¦è¯„åˆ†ï¼š
1. åŸºæœ¬ä¿¡æ¯å®Œæ•´æ€§
...
7. åˆ›æ–°èƒ½åŠ›  # æ–°å¢
\"\"\"
\`\`\`

### 3. æ·»åŠ æ–°å·¥å…·æ¨¡å—

**éœ€æ±‚**ï¼šç®€å†å…³é”®è¯æå–

\`\`\`python
# src/tools/keyword_extractor.py
import jieba

class KeywordExtractor:
    def __init__(self, top_k: int = 20):
        self.top_k = top_k
    
    def extract(self, text: str) -> list[str]:
        words = jieba.cut(text)
        # å®ç° TF-IDF ç®—æ³•
        return list(words)[:self.top_k]

# src/tools/__init__.py
from .keyword_extractor import KeywordExtractor
__all__ = ["WebSearchTool", "KeywordExtractor"]
\`\`\`

---

## æµ‹è¯•ä¸è°ƒè¯•

### å•å…ƒæµ‹è¯•

\`\`\`bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
pytest

# æµ‹è¯•ç‰¹å®šæ¨¡å—
pytest tests/test_loader.py

# æ˜¾ç¤ºè¯¦ç»†è¾“å‡º
pytest -v -s

# ä»£ç è¦†ç›–ç‡
pytest --cov=src --cov-report=html
\`\`\`

### ç¼–å†™æµ‹è¯•ç”¨ä¾‹

\`\`\`python
# tests/test_loader.py
import pytest
from src.loaders import ResumeLoader

@pytest.fixture
def loader():
    return ResumeLoader()

def test_load_pdf(loader, sample_pdf_path):
    result = loader.load_resume(sample_pdf_path)
    assert result.content
    assert result.metadata.file_size > 0

def test_load_nonexistent_file(loader):
    with pytest.raises(FileNotFoundError):
        loader.load_resume("nonexistent.pdf")
\`\`\`

### è°ƒè¯•æŠ€å·§

**1. æ—¥å¿—è°ƒè¯•**ï¼š
\`\`\`python
from loguru import logger
logger.debug("è°ƒè¯•ä¿¡æ¯: {}", variable)
logger.info("æ­£å¸¸ä¿¡æ¯")
\`\`\`

**2. IPython æ–­ç‚¹**ï¼š
\`\`\`python
from IPython import embed
embed()  # åœ¨æ­¤å¤„æš‚åœï¼Œè¿›å…¥äº¤äº’å¼ shell
\`\`\`

**3. VS Code è°ƒè¯•é…ç½®**ï¼š
\`\`\`json
// .vscode/launch.json
{
    "configurations": [
        {
            "name": "Python: Web UI",
            "type": "python",
            "request": "launch",
            "program": "${workspaceFolder}/web_ui.py"
        }
    ]
}
\`\`\`

---

## éƒ¨ç½²æŒ‡å—

### æœ¬åœ°éƒ¨ç½²

\`\`\`bash
python web_ui.py
# æˆ–
./start.sh
\`\`\`

### Docker éƒ¨ç½²

\`\`\`dockerfile
# Dockerfile
FROM python:3.10-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt
COPY . .
EXPOSE 7860
CMD ["python", "web_ui.py"]
\`\`\`

\`\`\`bash
docker build -t interview-coach .
docker run -p 7860:7860 --env-file .env interview-coach
\`\`\`

### ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²

**ä½¿ç”¨ Gunicorn**ï¼š
\`\`\`bash
pip install gunicorn uvicorn
gunicorn web_ui:app -w 4 -k uvicorn.workers.UvicornWorker --bind 0.0.0.0:7860
\`\`\`

**Nginx åå‘ä»£ç†**ï¼š
\`\`\`nginx
server {
    listen 80;
    location / {
        proxy_pass http://127.0.0.1:7860;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
    }
}
\`\`\`

---

## è´¡çŒ®è§„èŒƒ

### ä»£ç é£æ ¼

\`\`\`bash
# æ ¼å¼åŒ–ä»£ç 
black .
isort .

# ä»£ç æ£€æŸ¥
flake8 src/ tests/
mypy src/
\`\`\`

### Commit Message è§„èŒƒ

éµå¾ª [Conventional Commits](https://www.conventionalcommits.org/)ï¼š

- `feat`: æ–°åŠŸèƒ½
- `fix`: Bug ä¿®å¤
- `docs`: æ–‡æ¡£æ›´æ–°
- `refactor`: ä»£ç é‡æ„
- `test`: æµ‹è¯•ç›¸å…³
- `chore`: æ„å»º/å·¥å…·ç›¸å…³

**ç¤ºä¾‹**ï¼š
\`\`\`
feat: add Word document support
fix: handle empty PDF files
docs: update developer guide
\`\`\`

### Pull Request æ£€æŸ¥æ¸…å•

- [ ] ä»£ç å·²æ ¼å¼åŒ–ï¼ˆBlack + isortï¼‰
- [ ] é€šè¿‡æ‰€æœ‰æµ‹è¯•ï¼ˆpytestï¼‰
- [ ] æ·»åŠ å¿…è¦çš„æµ‹è¯•ç”¨ä¾‹
- [ ] æ›´æ–°ç›¸å…³æ–‡æ¡£
- [ ] Commit message ç¬¦åˆè§„èŒƒ

---

## å¸¸è§é—®é¢˜

**Q: Pydantic ä¸ Gradio å…¼å®¹æ€§é—®é¢˜ï¼Ÿ**  
A: åœ¨ `gr.Blocks()` ä¸­è®¾ç½® `show_api=False`ï¼Œæˆ–å°† computed_field æ”¹ä¸ºæ™®é€šæ–¹æ³•ã€‚

**Q: å¦‚ä½•è°ƒè¯• LLM API è°ƒç”¨ï¼Ÿ**  
A: åœ¨è°ƒç”¨å‰åæ·»åŠ  logger.info() æ‰“å° Prompt å’Œ Responseã€‚

**Q: å¦‚ä½•ä¼˜åŒ– LLM å“åº”é€Ÿåº¦ï¼Ÿ**  
A: ä½¿ç”¨æ›´å¿«çš„æ¨¡å‹ã€å®ç°ç¼“å­˜ã€å¼‚æ­¥å¤„ç†ã€æµå¼è¾“å‡ºã€‚

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**æœ€åæ›´æ–°**: 2025-12-27  
**ç›¸å…³æ–‡æ¡£**: [ç”¨æˆ·æŒ‡å—](USER_GUIDE.md) | [æ¶æ„æ–‡æ¡£](../ARCHITECTURE.md)
