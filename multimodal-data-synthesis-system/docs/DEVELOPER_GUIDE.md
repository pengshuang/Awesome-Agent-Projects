# å¼€å‘æŒ‡å—

æœ¬æ–‡æ¡£é¢å‘éœ€è¦å¯¹ç³»ç»Ÿè¿›è¡ŒäºŒæ¬¡å¼€å‘ã€å®šåˆ¶æˆ–æ·±å…¥ç†è§£ä»£ç çš„å¼€å‘è€…ã€‚

---

## ğŸ“– ç›®å½•

- [é¡¹ç›®ç»“æ„](#é¡¹ç›®ç»“æ„)
- [æ ¸å¿ƒæ¨¡å—è¯¦è§£](#æ ¸å¿ƒæ¨¡å—è¯¦è§£)
- [å¼€å‘ç¯å¢ƒæ­å»º](#å¼€å‘ç¯å¢ƒæ­å»º)
- [æ‰©å±•å¼€å‘](#æ‰©å±•å¼€å‘)
- [è°ƒè¯•æŠ€å·§](#è°ƒè¯•æŠ€å·§)
- [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–)

---

## ğŸ“ é¡¹ç›®ç»“æ„

```
multimodal-data-synthesis-system/
â”œâ”€â”€ config/                      # é…ç½®æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ llm_config.py           # LLM API é…ç½®
â”‚   â”œâ”€â”€ prompts.py              # Prompt æ¨¡æ¿é…ç½®
â”‚   â””â”€â”€ settings.py             # ç³»ç»Ÿè®¾ç½®
â”œâ”€â”€ src/                         # æºä»£ç 
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ agents.py               # Agent å®ç°
â”‚   â”œâ”€â”€ graph.py                # LangGraph å·¥ä½œæµ
â”‚   â”œâ”€â”€ models.py               # æ•°æ®æ¨¡å‹ï¼ˆPydanticï¼‰
â”‚   â””â”€â”€ utils.py                # å·¥å…·å‡½æ•°
â”œâ”€â”€ data/                        # æ•°æ®ç›®å½•
â”‚   â”œâ”€â”€ uploads/                # ä¸Šä¼ çš„å›¾ç‰‡
â”‚   â””â”€â”€ outputs/                # ç”Ÿæˆçš„æ•°æ®é›†
â”œâ”€â”€ logs/                        # æ—¥å¿—æ–‡ä»¶
â”œâ”€â”€ docs/                        # æ–‡æ¡£
â”‚   â”œâ”€â”€ USER_GUIDE.md
â”‚   â”œâ”€â”€ DEVELOPER_GUIDE.md
â”‚   â””â”€â”€ ARCHITECTURE.md
â”œâ”€â”€ web_ui.py                    # Gradio Web ç•Œé¢
â”œâ”€â”€ init_system.py               # ç³»ç»Ÿåˆå§‹åŒ–è„šæœ¬
â”œâ”€â”€ requirements.txt             # Python ä¾èµ–
â”œâ”€â”€ start.sh                     # å¯åŠ¨è„šæœ¬
â”œâ”€â”€ .env.example                 # ç¯å¢ƒå˜é‡ç¤ºä¾‹
â””â”€â”€ README.md                    # é¡¹ç›®è¯´æ˜
```

---

## ğŸ”§ æ ¸å¿ƒæ¨¡å—è¯¦è§£

### 1. é…ç½®æ¨¡å— (`config/`)

#### `llm_config.py` - LLM é…ç½®

**èŒè´£**ï¼šç®¡ç† LLM API çš„é…ç½®å‚æ•°

```python
from config.llm_config import llm_config

# è®¿é—®é…ç½®
print(llm_config.api_key)
print(llm_config.model_name)

# ä¿®æ”¹é…ç½®
llm_config.temperature = 0.5
```

**å…³é”®å±æ€§**ï¼š
- `api_key`: API å¯†é’¥
- `base_url`: API åœ°å€
- `model_name`: æ¨¡å‹åç§°
- `temperature`: æ¸©åº¦å‚æ•°
- `max_tokens`: æœ€å¤§ token æ•°

**æ‰©å±•ç¤ºä¾‹**ï¼šæ·»åŠ æ–°æ¨¡å‹é…ç½®

```python
# åœ¨ llm_config.py ä¸­æ·»åŠ 
class LLMConfig(BaseModel):
    # ... ç°æœ‰é…ç½® ...
    
    # æ–°å¢ï¼šæ”¯æŒå¤šä¸ªæ¨¡å‹é…ç½®
    models: Dict[str, str] = Field(
        default={
            "vision": "gpt-4-vision-preview",
            "text": "gpt-4-turbo",
            "embedding": "text-embedding-3-large"
        }
    )
```

#### `prompts.py` - Prompt é…ç½®

**èŒè´£**ï¼šç®¡ç†æ‰€æœ‰ Agent çš„ Prompt æ¨¡æ¿

**æ ¸å¿ƒæ–¹æ³•**ï¼š

```python
from config.prompts import prompts_config

# æ ¼å¼åŒ–æè®®è€… Prompt
system_prompt, user_prompt = prompts_config.format_proposer_prompt(
    task_type="å›¾ç‰‡é—®ç­”ç±»",
    difficulty_level=0.5,
    history_qa_pairs=[...]
)
```

**æ‰©å±•ç¤ºä¾‹**ï¼šæ·»åŠ æ–°çš„ä»»åŠ¡ç±»å‹

```python
# åœ¨ prompts.py çš„ PromptsConfig ç±»ä¸­
task_descriptions: Dict[str, str] = Field(
    default={
        # ... ç°æœ‰ä»»åŠ¡ç±»å‹ ...
        
        # æ–°å¢ï¼šå›¾è¡¨åˆ†æç±»
        "å›¾è¡¨åˆ†æç±»": "ç”Ÿæˆå…³äºå›¾è¡¨æ•°æ®è§£è¯»ã€è¶‹åŠ¿åˆ†æã€å¯¹æ¯”çš„é—®é¢˜",
        
        # æ–°å¢ï¼šè‰ºæœ¯é‰´èµç±»
        "è‰ºæœ¯é‰´èµç±»": "ç”Ÿæˆå…³äºè‰ºæœ¯ä½œå“é£æ ¼ã€æŠ€æ³•ã€æƒ…æ„Ÿè¡¨è¾¾çš„é—®é¢˜"
    }
)
```

#### `settings.py` - ç³»ç»Ÿè®¾ç½®

**èŒè´£**ï¼šç®¡ç†ç³»ç»Ÿçº§åˆ«çš„é…ç½®

**å…³é”®é…ç½®**ï¼š

```python
from config.settings import settings

# è®¿é—®ç›®å½•é…ç½®
print(settings.UPLOAD_DIR)
print(settings.OUTPUT_DIR)

# è®¿é—®è¿è¡Œå‚æ•°
print(settings.MAX_ITERATIONS)
print(settings.DIFFICULTY_INCREMENT)
```

**è‡ªå®šä¹‰é…ç½®**ï¼š

```python
# åˆ›å»ºè‡ªå®šä¹‰è®¾ç½®å®ä¾‹
custom_settings = SystemSettings(
    MAX_ITERATIONS=20,
    INITIAL_DIFFICULTY=0.5
)
```

---

### 2. æ•°æ®æ¨¡å‹ (`src/models.py`)

**ä½¿ç”¨ Pydantic è¿›è¡Œæ•°æ®éªŒè¯å’Œåºåˆ—åŒ–**

#### æ ¸å¿ƒæ¨¡å‹

**`QAPair` - é—®ç­”å¯¹**

```python
from src.models import QAPair

qa = QAPair(
    question="å›¾ç‰‡ä¸­æœ‰ä»€ä¹ˆï¼Ÿ",
    answer="ä¸€åªçŒ«",
    difficulty=0.3,
    iteration=1
)

# éªŒè¯ä¼šè‡ªåŠ¨è¿›è¡Œ
print(qa.dict())  # è½¬æ¢ä¸ºå­—å…¸
print(qa.json())  # è½¬æ¢ä¸º JSON
```

**`SynthesisTask` - åˆæˆä»»åŠ¡**

```python
from src.models import SynthesisTask, ImageInfo

task = SynthesisTask(
    task_id="task_001",
    task_type="å›¾ç‰‡é—®ç­”ç±»",
    images=[ImageInfo(path="/path/to/img.jpg", filename="img.jpg")],
    max_iterations=10
)
```

**`AgentState` - Agent çŠ¶æ€**

è¿™æ˜¯ LangGraph çš„æ ¸å¿ƒçŠ¶æ€å¯¹è±¡ï¼š

```python
from src.models import AgentState

state = AgentState(
    task=task,
    image_paths=["/path/to/img.jpg"],
    current_iteration=0,
    history_qa_pairs=[]
)
```

#### æ‰©å±•æ–°æ¨¡å‹

**åœºæ™¯**ï¼šæ·»åŠ ç”¨æˆ·åé¦ˆåŠŸèƒ½

```python
# åœ¨ models.py ä¸­æ·»åŠ 
class UserFeedback(BaseModel):
    """ç”¨æˆ·åé¦ˆ"""
    qa_id: str = Field(..., description="é—®ç­”å¯¹ID")
    rating: int = Field(..., ge=1, le=5, description="è¯„åˆ†1-5")
    comment: Optional[str] = Field(None, description="è¯„è®º")
    created_at: datetime = Field(default_factory=datetime.now)

# æ‰©å±• QAPair
class QAPair(BaseModel):
    # ... ç°æœ‰å­—æ®µ ...
    
    feedbacks: List[UserFeedback] = Field(
        default_factory=list,
        description="ç”¨æˆ·åé¦ˆåˆ—è¡¨"
    )
```

---

### 3. Agent æ¨¡å— (`src/agents.py`)

#### `MultimodalLLMClient` - LLM å®¢æˆ·ç«¯

**èŒè´£**ï¼šå°è£…å¤šæ¨¡æ€ LLM API è°ƒç”¨

**æ ¸å¿ƒæ–¹æ³•**ï¼š

```python
from src.agents import MultimodalLLMClient

client = MultimodalLLMClient()

response = client.call_with_images(
    system_prompt="ä½ æ˜¯ä¸€ä¸ªåŠ©æ‰‹",
    user_prompt="æè¿°è¿™å¼ å›¾ç‰‡",
    image_paths=["/path/to/image.jpg"],
    temperature=0.7
)
```

**å†…éƒ¨å®ç°**ï¼š

```python
def call_with_images(self, system_prompt, user_prompt, image_paths, temperature):
    # 1. æ„å»ºæ¶ˆæ¯
    messages = [
        {"role": "system", "content": system_prompt},
        {
            "role": "user",
            "content": [
                {"type": "text", "text": user_prompt},
                # å°†å›¾ç‰‡ç¼–ç ä¸º base64
                *[{"type": "image_url", "image_url": {"url": get_image_data_url(path)}}
                  for path in image_paths]
            ]
        }
    ]
    
    # 2. è°ƒç”¨ OpenAI API
    response = self.client.chat.completions.create(
        model=self.config.model_name,
        messages=messages,
        temperature=temperature,
        max_tokens=self.config.max_tokens
    )
    
    return response.choices[0].message.content
```

#### `ProposerAgent` - æè®®è€…

**èŒè´£**ï¼šç”Ÿæˆæ–°çš„é—®ç­”å¯¹

**å…³é”®æ–¹æ³•**ï¼š

```python
def propose(self, image_paths, task_type, difficulty, history_qa_pairs):
    # 1. æ ¼å¼åŒ– Prompt
    system_prompt, user_prompt = self.prompts_config.format_proposer_prompt(...)
    
    # 2. è°ƒç”¨ LLM
    response = self.llm_client.call_with_images(...)
    
    # 3. è§£æ JSON å“åº”
    result = extract_json_from_text(response)
    
    # 4. è¿”å›ç»“æ„åŒ–è¾“å‡º
    return ProposerOutput(
        question=result["question"],
        answer=result["answer"]
    )
```

**æ‰©å±•ç¤ºä¾‹**ï¼šæ·»åŠ é—®é¢˜å¤šæ ·æ€§æ£€æŸ¥

```python
def propose(self, image_paths, task_type, difficulty, history_qa_pairs):
    max_retries = 3
    
    for attempt in range(max_retries):
        output = self._generate_qa(...)
        
        # æ£€æŸ¥é—®é¢˜æ˜¯å¦ä¸å†å²é‡å¤
        if self._is_diverse_enough(output.question, history_qa_pairs):
            return output
        
        logger.warning(f"é—®é¢˜é‡å¤ï¼Œé‡è¯• {attempt + 1}/{max_retries}")
    
    raise Exception("æ— æ³•ç”Ÿæˆå¤šæ ·åŒ–çš„é—®é¢˜")

def _is_diverse_enough(self, new_question, history):
    # ä½¿ç”¨ç¼–è¾‘è·ç¦»æˆ–è¯­ä¹‰ç›¸ä¼¼åº¦åˆ¤æ–­
    from difflib import SequenceMatcher
    
    for qa in history:
        similarity = SequenceMatcher(None, new_question, qa.question).ratio()
        if similarity > 0.8:  # ç›¸ä¼¼åº¦è¿‡é«˜
            return False
    
    return True
```

#### `SolverAgent` - æ±‚è§£è€…

**èŒè´£**ï¼šå°è¯•å›ç­”é—®é¢˜

```python
def solve(self, image_paths, question):
    # è°ƒç”¨ LLM åŸºäºå›¾ç‰‡å›ç­”é—®é¢˜
    system_prompt, user_prompt = self.prompts_config.format_solver_prompt(question)
    response = self.llm_client.call_with_images(...)
    result = extract_json_from_text(response)
    return SolverOutput(answer=result["answer"])
```

#### `ValidatorAgent` - éªŒè¯è€…

**èŒè´£**ï¼šè¯„ä¼°ç­”æ¡ˆè´¨é‡

```python
def validate(self, image_paths, question, reference_answer, predicted_answer):
    # è°ƒç”¨ LLM æ¯”è¾ƒä¸¤ä¸ªç­”æ¡ˆçš„è¯­ä¹‰ç›¸ä¼¼åº¦
    system_prompt, user_prompt = self.prompts_config.format_validator_prompt(...)
    response = self.llm_client.call_with_images(...)
    result = extract_json_from_text(response)
    
    return ValidationResult(
        is_valid=result["is_valid"],
        similarity_score=result["similarity_score"],
        reason=result["reason"]
    )
```

**æ‰©å±•ç¤ºä¾‹**ï¼šæ·»åŠ åŸºäºè§„åˆ™çš„éªŒè¯

```python
def validate(self, image_paths, question, reference_answer, predicted_answer):
    # 1. LLM éªŒè¯
    llm_validation = self._llm_validate(...)
    
    # 2. è§„åˆ™éªŒè¯
    rule_validation = self._rule_validate(reference_answer, predicted_answer)
    
    # 3. ç»¼åˆåˆ¤æ–­
    final_score = 0.7 * llm_validation.similarity_score + \
                  0.3 * rule_validation.score
    
    return ValidationResult(
        is_valid=final_score > self.validation_threshold,
        similarity_score=final_score,
        reason=f"LLM: {llm_validation.reason}, è§„åˆ™: {rule_validation.reason}"
    )

def _rule_validate(self, ref, pred):
    """åŸºäºè§„åˆ™çš„éªŒè¯"""
    # ç¤ºä¾‹ï¼šå…³é”®è¯åŒ¹é…
    ref_keywords = set(ref.lower().split())
    pred_keywords = set(pred.lower().split())
    
    overlap = len(ref_keywords & pred_keywords)
    score = overlap / len(ref_keywords) if ref_keywords else 0
    
    return SimpleNamespace(
        score=score,
        reason=f"å…³é”®è¯é‡å åº¦: {score:.2f}"
    )
```

---

### 4. å·¥ä½œæµæ¨¡å— (`src/graph.py`)

**åŸºäº LangGraph å®ç°çŠ¶æ€æœºå·¥ä½œæµ**

#### å·¥ä½œæµç»“æ„

```
check_continue â†’ propose â†’ solve â†’ validate â†’ update_state â†’ check_continue
       â†“                                                            â†‘
      END â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### æ ¸å¿ƒæ–¹æ³•

**`_build_graph()` - æ„å»ºå·¥ä½œæµ**

```python
def _build_graph(self):
    workflow = StateGraph(AgentState)
    
    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("check_continue", self._check_continue)
    workflow.add_node("propose", self._propose_node)
    workflow.add_node("solve", self._solve_node)
    workflow.add_node("validate", self._validate_node)
    workflow.add_node("update_state", self._update_state_node)
    
    # è®¾ç½®å…¥å£
    workflow.set_entry_point("check_continue")
    
    # æ·»åŠ æ¡ä»¶è¾¹
    workflow.add_conditional_edges(
        "check_continue",
        self._should_continue,
        {"continue": "propose", "end": END}
    )
    
    # æ·»åŠ é¡ºåºè¾¹
    workflow.add_edge("propose", "solve")
    workflow.add_edge("solve", "validate")
    workflow.add_edge("validate", "update_state")
    workflow.add_edge("update_state", "check_continue")
    
    return workflow.compile()
```

**èŠ‚ç‚¹å‡½æ•°**ï¼š

æ¯ä¸ªèŠ‚ç‚¹å‡½æ•°æ¥æ”¶ `AgentState`ï¼Œä¿®æ”¹å¹¶è¿”å›ï¼š

```python
def _propose_node(self, state: AgentState) -> AgentState:
    try:
        output = self.proposer.propose(...)
        state.current_state.proposed_qa = output
        state.current_state.status = "proposing"
    except Exception as e:
        state.current_state.error = str(e)
        state.current_state.status = "failed"
    
    return state
```

#### æ‰©å±•å·¥ä½œæµ

**åœºæ™¯ 1ï¼šæ·»åŠ äººå·¥å®¡æ ¸èŠ‚ç‚¹**

```python
def _build_graph(self):
    workflow = StateGraph(AgentState)
    
    # ... ç°æœ‰èŠ‚ç‚¹ ...
    
    # æ–°å¢ï¼šäººå·¥å®¡æ ¸èŠ‚ç‚¹
    workflow.add_node("human_review", self._human_review_node)
    
    # ä¿®æ”¹è¾¹ï¼švalidate â†’ human_review â†’ update_state
    workflow.add_edge("validate", "human_review")
    workflow.add_edge("human_review", "update_state")
    
    return workflow.compile()

def _human_review_node(self, state: AgentState) -> AgentState:
    """äººå·¥å®¡æ ¸èŠ‚ç‚¹"""
    qa = state.current_state.proposed_qa
    validation = state.current_state.validation
    
    # å¦‚æœéªŒè¯åˆ†æ•°åœ¨ä¸´ç•ŒåŒºé—´ï¼Œè§¦å‘äººå·¥å®¡æ ¸
    if 0.7 <= validation.similarity_score < 0.8:
        # å®ç°ï¼šå‘é€åˆ°å®¡æ ¸é˜Ÿåˆ—ï¼Œç­‰å¾…äººå·¥æ ‡æ³¨
        approved = self._request_human_approval(qa, validation)
        
        if not approved:
            state.current_state.status = "rejected_by_human"
            validation.is_valid = False
    
    return state
```

**åœºæ™¯ 2ï¼šæ·»åŠ é‡è¯•æœºåˆ¶**

```python
def _propose_node(self, state: AgentState) -> AgentState:
    max_retries = 3
    
    for attempt in range(max_retries):
        try:
            output = self.proposer.propose(...)
            state.current_state.proposed_qa = output
            state.current_state.status = "proposing"
            return state
        except Exception as e:
            logger.warning(f"æè®®å¤±è´¥ï¼Œé‡è¯• {attempt + 1}/{max_retries}: {e}")
            if attempt == max_retries - 1:
                state.current_state.error = str(e)
                state.current_state.status = "failed"
    
    return state
```

---

### 5. Web UI æ¨¡å— (`web_ui.py`)

**åŸºäº Gradio å®ç°**

#### æ ¸å¿ƒç»„ä»¶

**`MultimodalSynthesisUI` ç±»**

```python
class MultimodalSynthesisUI:
    def __init__(self):
        self.graph = None
        self.current_task_id = None
    
    def create_interface(self):
        """åˆ›å»º Gradio ç•Œé¢"""
        with gr.Blocks() as interface:
            # æ„å»º UI ç»„ä»¶
            ...
        return interface
```

#### äº‹ä»¶å¤„ç†

**å›¾ç‰‡ä¸Šä¼ **ï¼š

```python
def handle_image_upload(files):
    if not files:
        return []
    return [file.name for file in files]

image_input.change(
    fn=handle_image_upload,
    inputs=[image_input],
    outputs=[uploaded_images]
)
```

**å¼€å§‹åˆæˆ**ï¼š

```python
def start_synthesis(files, task_type, ...):
    # ä½¿ç”¨ yield å®ç°æµå¼æ›´æ–°
    for iteration in range(max_iterations):
        # æ‰§è¡Œä¸€æ¬¡è¿­ä»£
        ...
        
        # æ›´æ–° UI
        yield progress_md, iteration_md, validated_md
```

#### è‡ªå®šä¹‰ UI æ ·å¼

```python
custom_css = """
.proposer-output {
    background: #e3f2fd;
    border-left: 4px solid #2196F3;
}
.solver-output {
    background: #f3e5f5;
    border-left: 4px solid #9c27b0;
}
"""

interface = gr.Blocks(css=custom_css)
```

#### æ‰©å±• UI

**åœºæ™¯ï¼šæ·»åŠ æ•°æ®ç»Ÿè®¡ä»ªè¡¨æ¿**

```python
with gr.Tab("ğŸ“Š æ•°æ®ç»Ÿè®¡"):
    gr.Markdown("### ç”Ÿæˆæ•°æ®ç»Ÿè®¡")
    
    # ç»Ÿè®¡å›¾è¡¨
    stats_chart = gr.Plot(label="éš¾åº¦åˆ†å¸ƒ")
    qa_count = gr.Number(label="æ€»é—®ç­”å¯¹æ•°", interactive=False)
    avg_difficulty = gr.Number(label="å¹³å‡éš¾åº¦", interactive=False)
    
    refresh_stats_btn = gr.Button("ğŸ”„ åˆ·æ–°ç»Ÿè®¡")
    
    def refresh_statistics():
        # è¯»å–æ‰€æœ‰è¾“å‡ºæ–‡ä»¶ï¼Œè®¡ç®—ç»Ÿè®¡
        import json
        from pathlib import Path
        
        all_qa = []
        for file in Path("data/outputs").glob("*.json"):
            with open(file) as f:
                data = json.load(f)
                all_qa.extend(data["qa_pairs"])
        
        # è®¡ç®—ç»Ÿè®¡
        difficulties = [qa["difficulty"] for qa in all_qa]
        avg_diff = sum(difficulties) / len(difficulties) if difficulties else 0
        
        # ç»˜åˆ¶åˆ†å¸ƒå›¾
        import matplotlib.pyplot as plt
        fig, ax = plt.subplots()
        ax.hist(difficulties, bins=10)
        ax.set_xlabel("éš¾åº¦")
        ax.set_ylabel("æ•°é‡")
        
        return fig, len(all_qa), avg_diff
    
    refresh_stats_btn.click(
        fn=refresh_statistics,
        outputs=[stats_chart, qa_count, avg_difficulty]
    )
```

---

## ğŸ› ï¸ å¼€å‘ç¯å¢ƒæ­å»º

### æœ¬åœ°å¼€å‘

```bash
# 1. å…‹éš†é¡¹ç›®
git clone <your-repo>
cd multimodal-data-synthesis-system

# 2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python3 -m venv venv
source venv/bin/activate

# 3. å®‰è£…å¼€å‘ä¾èµ–
pip install -r requirements.txt
pip install pytest black flake8 mypy  # å¼€å‘å·¥å…·

# 4. é…ç½®ç¯å¢ƒå˜é‡
cp .env.example .env
# ç¼–è¾‘ .env æ–‡ä»¶

# 5. è¿è¡Œæµ‹è¯•
pytest tests/

# 6. å¯åŠ¨å¼€å‘æœåŠ¡å™¨
python web_ui.py
```

### ä»£ç è§„èŒƒ

**ä½¿ç”¨ Black æ ¼å¼åŒ–**ï¼š

```bash
black src/ config/ web_ui.py
```

**ä½¿ç”¨ Flake8 æ£€æŸ¥**ï¼š

```bash
flake8 src/ config/ --max-line-length=100
```

**ç±»å‹æ£€æŸ¥**ï¼š

```bash
mypy src/ config/
```

---

## ğŸ§ª æµ‹è¯•

### å•å…ƒæµ‹è¯•ç¤ºä¾‹

**æµ‹è¯• ProposerAgent**ï¼š

```python
# tests/test_agents.py
import pytest
from src.agents import ProposerAgent, MultimodalLLMClient
from config.llm_config import llm_config

def test_proposer_basic():
    client = MultimodalLLMClient(llm_config)
    proposer = ProposerAgent(client)
    
    output = proposer.propose(
        image_paths=["tests/fixtures/test_image.jpg"],
        task_type="å›¾ç‰‡é—®ç­”ç±»",
        difficulty=0.3,
        history_qa_pairs=[]
    )
    
    assert output.question
    assert output.answer
    assert len(output.question) > 10
```

**æµ‹è¯•æ•°æ®æ¨¡å‹**ï¼š

```python
# tests/test_models.py
from src.models import QAPair

def test_qa_pair_validation():
    qa = QAPair(
        question="æµ‹è¯•é—®é¢˜",
        answer="æµ‹è¯•ç­”æ¡ˆ",
        difficulty=0.5,
        iteration=1
    )
    
    assert qa.difficulty == 0.5
    assert 0 <= qa.difficulty <= 1

def test_qa_pair_invalid_difficulty():
    with pytest.raises(ValidationError):
        QAPair(
            question="æµ‹è¯•",
            answer="æµ‹è¯•",
            difficulty=1.5,  # è¶…å‡ºèŒƒå›´
            iteration=1
        )
```

---

## ğŸš€ æ€§èƒ½ä¼˜åŒ–

### 1. å¹¶è¡Œå¤„ç†

**æ‰¹é‡å¤„ç†å¤šä¸ªå›¾ç‰‡**ï¼š

```python
import asyncio
from concurrent.futures import ThreadPoolExecutor

async def process_batch(image_list, task_config):
    with ThreadPoolExecutor(max_workers=5) as executor:
        loop = asyncio.get_event_loop()
        tasks = [
            loop.run_in_executor(
                executor,
                process_single_image,
                image
            )
            for image in image_list
        ]
        results = await asyncio.gather(*tasks)
    return results
```

### 2. ç¼“å­˜æœºåˆ¶

**ç¼“å­˜ LLM å“åº”**ï¼š

```python
from functools import lru_cache

class MultimodalLLMClient:
    @lru_cache(maxsize=128)
    def call_with_images_cached(self, system_prompt, user_prompt, image_hash):
        # ä½¿ç”¨å›¾ç‰‡å“ˆå¸Œä½œä¸ºç¼“å­˜é”®
        return self.call_with_images(...)
```

### 3. å‡å°‘ API è°ƒç”¨

**æ‰¹é‡éªŒè¯**ï¼š

```python
def batch_validate(self, qa_pairs, batch_size=5):
    """æ‰¹é‡éªŒè¯å¤šä¸ªé—®ç­”å¯¹"""
    results = []
    for i in range(0, len(qa_pairs), batch_size):
        batch = qa_pairs[i:i+batch_size]
        # åœ¨ä¸€æ¬¡ API è°ƒç”¨ä¸­éªŒè¯å¤šä¸ª
        batch_result = self._validate_batch(batch)
        results.extend(batch_result)
    return results
```

---

## ğŸ“ å¸¸è§å¼€å‘ä»»åŠ¡

### ä»»åŠ¡ 1ï¼šæ·»åŠ æ–°çš„ä»»åŠ¡ç±»å‹

1. åœ¨ `config/prompts.py` çš„ `task_descriptions` ä¸­æ·»åŠ 
2. æ›´æ–° `src/models.py` çš„ `TaskType` æšä¸¾
3. åœ¨ UI çš„ä¸‹æ‹‰èœå•ä¸­æ·»åŠ é€‰é¡¹

### ä»»åŠ¡ 2ï¼šè‡ªå®šä¹‰éªŒè¯é€»è¾‘

1. ä¿®æ”¹ `src/agents.py` çš„ `ValidatorAgent.validate()`
2. æ·»åŠ è‡ªå®šä¹‰éªŒè¯è§„åˆ™
3. è°ƒæ•´ `VALIDATION_THRESHOLD`

### ä»»åŠ¡ 3ï¼šé›†æˆæ–°çš„ LLM API

1. ä¿®æ”¹ `src/agents.py` çš„ `MultimodalLLMClient`
2. é€‚é…æ–° API çš„è¯·æ±‚æ ¼å¼
3. æ›´æ–°é…ç½®æ–‡ä»¶

---

**å¼€å‘æ„‰å¿«ï¼ğŸ’»**
