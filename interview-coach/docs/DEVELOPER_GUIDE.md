# å¼€å‘æŒ‡å—

é¢å‘å¼€å‘è€…ï¼Œä»‹ç»äºŒæ¬¡å¼€å‘ã€åŠŸèƒ½æ‰©å±•å’Œç³»ç»Ÿå®šåˆ¶ã€‚

## ğŸ“‹ ç›®å½•

- [ç¯å¢ƒæ­å»º](#ç¯å¢ƒæ­å»º)
- [æ¶æ„æ¦‚è§ˆ](#æ¶æ„æ¦‚è§ˆ)
- [æ ¸å¿ƒæ¨¡å—](#æ ¸å¿ƒæ¨¡å—)
- [æ‰©å±•å¼€å‘](#æ‰©å±•å¼€å‘)
- [æµ‹è¯•ä¸è°ƒè¯•](#æµ‹è¯•ä¸è°ƒè¯•)
- [éƒ¨ç½²æŒ‡å—](#éƒ¨ç½²æŒ‡å—)

---

## ç¯å¢ƒæ­å»º

### ç¯å¢ƒè¦æ±‚

- Python 3.9+
- pip 20.0+
- Git

### å¼€å‘é…ç½®

```bash
# 1. å…‹éš†å¹¶è¿›å…¥é¡¹ç›®
git clone <repository-url>
cd interview-coach

# 2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆæ¨èï¼‰
python -m venv venv
source venv/bin/activate  # macOS/Linux
# venv\Scripts\activate   # Windows

# 3. å®‰è£…ä¾èµ–
pip install -r requirements.txt

# 4. å®‰è£…å¼€å‘å·¥å…·ï¼ˆå¯é€‰ï¼‰
pip install pytest black isort mypy flake8

# 5. é…ç½®ç¯å¢ƒ
cp .env.example .env
# ç¼–è¾‘ .envï¼Œå¡«å†™ API å¯†é’¥
```

---

## æ¶æ„æ¦‚è§ˆ

### ç›®å½•ç»“æ„

```
interview-coach/
â”œâ”€â”€ config/              # é…ç½®ç®¡ç†
â”‚   â”œâ”€â”€ llm_config.py   # LLM å®¢æˆ·ç«¯
â”‚   â”œâ”€â”€ prompts.py      # Prompt æ¨¡æ¿
â”‚   â””â”€â”€ settings.py     # Pydantic Settings
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/         # Pydantic æ•°æ®æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ resume.py
â”‚   â”‚   â”œâ”€â”€ evaluation.py
â”‚   â”‚   â””â”€â”€ interview.py
â”‚   â”œâ”€â”€ loaders/        # ç®€å†åŠ è½½å™¨
â”‚   â”œâ”€â”€ evaluator/      # è¯„ä¼°å¼•æ“
â”‚   â”œâ”€â”€ interview/      # é¢è¯•ä»£ç†
â”‚   â”œâ”€â”€ tools/          # å·¥å…·æ¨¡å—
â”‚   â”œâ”€â”€ utils/          # å·¥å…·å‡½æ•°
â”‚   â””â”€â”€ exceptions.py   # å¼‚å¸¸å®šä¹‰
â”‚
â”œâ”€â”€ tests/              # æµ‹è¯•
â”œâ”€â”€ web_ui.py          # Gradio UI
â””â”€â”€ quick_start.py     # CLI ç¤ºä¾‹
```

### æ¶æ„åŸåˆ™

1. **æ¨¡å—åŒ–**: èŒè´£å•ä¸€,ä½è€¦åˆ
2. **ç±»å‹å®‰å…¨**: Pydantic v2 æ•°æ®éªŒè¯
3. **é…ç½®é©±åŠ¨**: é›†ä¸­é…ç½®ç®¡ç†
4. **å¯æ‰©å±•**: é¢„ç•™æ‰©å±•æ¥å£
5. **å¯æµ‹è¯•**: å®Œæ•´æµ‹è¯•è¦†ç›–

---

## æ ¸å¿ƒæ¨¡å—

### 1. æ•°æ®æ¨¡å‹ (src/models/)

ä½¿ç”¨ **Pydantic v2** å®ç°ç±»å‹å®‰å…¨çš„æ•°æ®æ¨¡å‹ã€‚

#### resume.py - ç®€å†æ•°æ®

```python
from pydantic import BaseModel, Field, computed_field

class ResumeMetadata(BaseModel):
    """ç®€å†å…ƒæ•°æ®"""
    filename: str
    file_size: int
    page_count: int = 0
    
    @computed_field
    @property
    def file_size_mb(self) -> float:
        return round(self.file_size / (1024 * 1024), 2)

class ResumeData(BaseModel):
    """ç®€å†å®Œæ•´æ•°æ®"""
    content: str = Field(..., description="ç®€å†æ–‡æœ¬å†…å®¹")
    metadata: ResumeMetadata
    
    @computed_field
    @property
    def word_count(self) -> int:
        return len(self.content)
```

**æ‰©å±•ç¤ºä¾‹**: æ·»åŠ æ–°å­—æ®µ
```python
class ResumeData(BaseModel):
    # æ–°å¢å­—æ®µ
    parsed_sections: dict[str, str] = Field(
        default_factory=dict,
        description="è§£æçš„ç®€å†ç« èŠ‚"
    )
```

#### evaluation.py - è¯„ä¼°ç»“æœ

```python
class ScoreDetails(BaseModel):
    """è¯„åˆ†è¯¦æƒ…"""
    basic_info: int = Field(ge=0, le=10)
    work_experience: int = Field(ge=0, le=10)
    project_quality: int = Field(ge=0, le=10)
    skills_match: int = Field(ge=0, le=10)
    education: int = Field(ge=0, le=10)
    overall_impression: int = Field(ge=0, le=10)
    
    @computed_field
    @property
    def total_score(self) -> float:
        return round(
            (self.basic_info + self.work_experience + 
             self.project_quality + self.skills_match + 
             self.education + self.overall_impression) / 6 * 10,
            1
        )
```

#### interview.py - é¢è¯•ä¼šè¯

```python
from enum import Enum

class MessageRole(str, Enum):
    SYSTEM = "system"
    USER = "user"
    ASSISTANT = "assistant"

class InterviewType(str, Enum):
    TECHNICAL = "technical"
    BEHAVIORAL = "behavioral"
    COMPREHENSIVE = "comprehensive"

class InterviewMessage(BaseModel):
    role: MessageRole
    content: str
    timestamp: datetime = Field(default_factory=datetime.now)

class InterviewSession(BaseModel):
    messages: list[InterviewMessage] = Field(default_factory=list)
    interview_type: InterviewType = InterviewType.COMPREHENSIVE
```

### 2. é…ç½®ç®¡ç† (config/settings.py)

ä½¿ç”¨ **Pydantic Settings** ç®¡ç†é…ç½®ã€‚

```python
from pydantic_settings import BaseSettings, SettingsConfigDict
from pathlib import Path

class SystemConfig(BaseSettings):
    """ç³»ç»Ÿé…ç½® - è‡ªåŠ¨ä»ç¯å¢ƒå˜é‡åŠ è½½"""
    
    # LLM é…ç½®
    llm_api_key: str = Field(..., description="LLM APIå¯†é’¥")
    llm_api_base: str = Field(
        default="https://api.openai.com/v1",
        description="APIç«¯ç‚¹"
    )
    llm_model: str = Field(
        default="gpt-3.5-turbo",
        description="æ¨¡å‹åç§°"
    )
    
    # è·¯å¾„é…ç½®
    base_dir: Path = Field(default_factory=lambda: Path(__file__).parent.parent)
    
    @computed_field
    @property
    def data_dir(self) -> Path:
        return self.base_dir / "data"
    
    model_config = SettingsConfigDict(
        env_file=".env",
        env_file_encoding="utf-8",
        case_sensitive=False
    )

# å•ä¾‹æ¨¡å¼
_config_instance = None

def get_config() -> SystemConfig:
    global _config_instance
    if _config_instance is None:
        _config_instance = SystemConfig()
    return _config_instance
```

### 3. å¼‚å¸¸å¤„ç† (src/exceptions.py)

```python
class InterviewCoachException(Exception):
    """åŸºç¡€å¼‚å¸¸"""
    pass

class ResumeLoadError(InterviewCoachException):
    """ç®€å†åŠ è½½å¤±è´¥"""
    pass

class LLMAPIError(InterviewCoachException):
    """LLM APIè°ƒç”¨å¤±è´¥"""
    pass

class EvaluationError(InterviewCoachException):
    """è¯„ä¼°å¤„ç†å¤±è´¥"""
    pass
```

### 4. ç®€å†åŠ è½½å™¨ (src/loaders/)

```python
import fitz  # PyMuPDF
from src.models.resume import ResumeData, ResumeMetadata
from src.exceptions import ResumeLoadError

class ResumeLoader:
    def load_pdf(self, file_path: str) -> ResumeData:
        """åŠ è½½PDFç®€å†"""
        try:
            doc = fitz.open(file_path)
            content = "\n".join(
                page.get_text() for page in doc
            )
            
            metadata = ResumeMetadata(
                filename=Path(file_path).name,
                file_size=Path(file_path).stat().st_size,
                page_count=doc.page_count
            )
            
            return ResumeData(
                content=content,
                metadata=metadata
            )
        except Exception as e:
            raise ResumeLoadError(f"åŠ è½½å¤±è´¥: {e}")
```

### 5. è¯„ä¼°å¼•æ“ (src/evaluator/)

```python
from openai import OpenAI
from src.models.evaluation import EvaluationResult
from src.exceptions import EvaluationError

class ResumeEvaluator:
    def __init__(self, client: OpenAI, model: str):
        self.client = client
        self.model = model
    
    def evaluate(
        self, 
        resume: ResumeData,
        job_title: str = "",
        job_requirements: str = ""
    ) -> EvaluationResult:
        """è¯„ä¼°ç®€å†"""
        try:
            prompt = self._build_prompt(
                resume, job_title, job_requirements
            )
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                response_format={"type": "json_object"}
            )
            
            # è§£æä¸º Pydantic æ¨¡å‹
            result_dict = json.loads(
                response.choices[0].message.content
            )
            return EvaluationResult(**result_dict)
            
        except Exception as e:
            raise EvaluationError(f"è¯„ä¼°å¤±è´¥: {e}")
```

---

## æ‰©å±•å¼€å‘

### æ·»åŠ æ–°çš„è¯„ä¼°ç»´åº¦

1. **ä¿®æ”¹æ•°æ®æ¨¡å‹** (`src/models/evaluation.py`):
```python
class ScoreDetails(BaseModel):
    # åŸæœ‰å­—æ®µ...
    
    # æ–°å¢å­—æ®µ
    soft_skills: int = Field(
        ge=0, le=10,
        description="è½¯æŠ€èƒ½è¯„åˆ†"
    )
    
    @computed_field
    @property
    def total_score(self) -> float:
        # æ›´æ–°è®¡ç®—é€»è¾‘
        return round(
            (self.basic_info + ... + self.soft_skills) / 7 * 10,
            1
        )
```

2. **æ›´æ–° Prompt** (`config/prompts.py`):
```python
EVALUATION_PROMPT = """
è¯„ä¼°ç»´åº¦ï¼š
...
7. è½¯æŠ€èƒ½ï¼ˆ0-10åˆ†ï¼‰ï¼šæ²Ÿé€šã€é¢†å¯¼åŠ›ç­‰
"""
```

3. **æµ‹è¯•æ–°åŠŸèƒ½**:
```python
def test_new_dimension():
    result = evaluator.evaluate(resume)
    assert hasattr(result.scores, 'soft_skills')
    assert 0 <= result.scores.soft_skills <= 10
```

### æ·»åŠ æ–°çš„é¢è¯•ç±»å‹

1. **æ‰©å±•æšä¸¾** (`src/models/interview.py`):
```python
class InterviewType(str, Enum):
    TECHNICAL = "technical"
    BEHAVIORAL = "behavioral"
    COMPREHENSIVE = "comprehensive"
    CASE_STUDY = "case_study"  # æ–°å¢
```

2. **æ›´æ–° Prompt** (`config/prompts.py`):
```python
INTERVIEW_PROMPTS = {
    InterviewType.CASE_STUDY: """
    ä½ æ˜¯æ¡ˆä¾‹é¢è¯•å®˜ï¼Œä¸“æ³¨äºä¸šåŠ¡åˆ†æèƒ½åŠ›...
    """
}
```

3. **UI é›†æˆ** (`web_ui.py`):
```python
interview_type = gr.Radio(
    choices=[
        "æŠ€æœ¯é¢è¯•",
        "è¡Œä¸ºé¢è¯•", 
        "ç»¼åˆé¢è¯•",
        "æ¡ˆä¾‹åˆ†æ"  # æ–°å¢
    ]
)
```

### æ·»åŠ æ–°çš„æ•°æ®æº

ç¤ºä¾‹ï¼šæ”¯æŒ Word æ–‡æ¡£

```python
# src/loaders/resume_loader.py
from docx import Document

class ResumeLoader:
    def load_docx(self, file_path: str) -> ResumeData:
        """åŠ è½½Wordç®€å†"""
        try:
            doc = Document(file_path)
            content = "\n".join(
                para.text for para in doc.paragraphs
            )
            
            metadata = ResumeMetadata(
                filename=Path(file_path).name,
                file_size=Path(file_path).stat().st_size,
                page_count=len(doc.sections)
            )
            
            return ResumeData(
                content=content,
                metadata=metadata
            )
        except Exception as e:
            raise ResumeLoadError(f"åŠ è½½Wordå¤±è´¥: {e}")
```

---

## æµ‹è¯•ä¸è°ƒè¯•

### è¿è¡Œæµ‹è¯•

```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
pytest

# è¿è¡Œç‰¹å®šæµ‹è¯•æ–‡ä»¶
pytest tests/test_loader.py

# æŸ¥çœ‹è¦†ç›–ç‡
pytest --cov=src tests/

# è¯¦ç»†è¾“å‡º
pytest -v -s
```

### ä»£ç è´¨é‡æ£€æŸ¥

```bash
# æ ¼å¼åŒ–ä»£ç 
black .
isort .

# ç±»å‹æ£€æŸ¥
mypy src/

# ä»£ç é£æ ¼
flake8 src/
```

### è°ƒè¯•æŠ€å·§

**1. æ—¥å¿—è°ƒè¯•**:
```python
from src.utils.logger import setup_logger

logger = setup_logger(__name__)
logger.debug(f"Resume content: {resume.content[:100]}")
```

**2. Pydantic éªŒè¯è°ƒè¯•**:
```python
try:
    resume = ResumeData(**data)
except ValidationError as e:
    print(e.json())  # æŸ¥çœ‹è¯¦ç»†é”™è¯¯
```

**3. LLM å“åº”è°ƒè¯•**:
```python
# æ‰“å°å®Œæ•´å“åº”
response = client.chat.completions.create(...)
print(response.model_dump_json(indent=2))
```

---

## éƒ¨ç½²æŒ‡å—

### æœ¬åœ°éƒ¨ç½²

```bash
# å¯åŠ¨ Web UI
python web_ui.py

# è‡ªå®šä¹‰ç«¯å£
python web_ui.py --server-port 8080
```

### Docker éƒ¨ç½²

```dockerfile
FROM python:3.9-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .
EXPOSE 7861

CMD ["python", "web_ui.py", "--server-name", "0.0.0.0"]
```

```bash
# æ„å»ºé•œåƒ
docker build -t interview-coach .

# è¿è¡Œå®¹å™¨
docker run -p 7861:7861 \
  -e LLM_API_KEY=your_key \
  -e LLM_API_BASE=https://api.openai.com/v1 \
  interview-coach
```

### ç”Ÿäº§ç¯å¢ƒå»ºè®®

1. **å®‰å…¨**:
   - ä½¿ç”¨å¯†é’¥ç®¡ç†æœåŠ¡å­˜å‚¨ API å¯†é’¥
   - å¯ç”¨ HTTPS
   - æ·»åŠ èº«ä»½è®¤è¯

2. **æ€§èƒ½**:
   - é…ç½®åˆé€‚çš„å¹¶å‘æ•°
   - å¯ç”¨å“åº”ç¼“å­˜
   - ä½¿ç”¨è´Ÿè½½å‡è¡¡

3. **ç›‘æ§**:
   - æ¥å…¥æ—¥å¿—æ”¶é›†ç³»ç»Ÿ
   - é…ç½®æ€§èƒ½ç›‘æ§
   - è®¾ç½®å‘Šè­¦è§„åˆ™

---

## å¸¸è§é—®é¢˜

### Q: å¦‚ä½•åˆ‡æ¢ LLM æœåŠ¡å•†?
**A**: ä¿®æ”¹ `.env` æ–‡ä»¶ä¸­çš„ `LLM_API_BASE` å’Œ `LLM_MODEL`ã€‚

### Q: å¦‚ä½•è‡ªå®šä¹‰ Prompt?
**A**: ç¼–è¾‘ `config/prompts.py`,æ‰€æœ‰ Prompt æ¨¡æ¿é›†ä¸­ç®¡ç†ã€‚

### Q: Pydantic éªŒè¯å¤±è´¥æ€ä¹ˆåŠ?
**A**: æ£€æŸ¥è¾“å…¥æ•°æ®æ ¼å¼,æŸ¥çœ‹ `ValidationError` è¯¦ç»†ä¿¡æ¯ã€‚

### Q: å¦‚ä½•æ·»åŠ æ–°çš„é…ç½®é¡¹?
**A**: åœ¨ `config/settings.py` çš„ `SystemConfig` ä¸­æ·»åŠ å­—æ®µ,æ”¯æŒä»ç¯å¢ƒå˜é‡è‡ªåŠ¨åŠ è½½ã€‚

---

## å‚è€ƒèµ„æº

- [Pydantic æ–‡æ¡£](https://docs.pydantic.dev/)
- [OpenAI API æ–‡æ¡£](https://platform.openai.com/docs)
- [Gradio æ–‡æ¡£](https://gradio.app/docs/)
- [PyMuPDF æ–‡æ¡£](https://pymupdf.readthedocs.io/)

---

å¦‚éœ€æ›´å¤šå¸®åŠ©,æ¬¢è¿æäº¤ Issue!
# åœ¨ get_llm_client ä¸­æ·»åŠ 
if api_base.endswith("your-llm-service.com"):
    # æ·»åŠ ç‰¹å®šé…ç½®
    client = OpenAI(
        api_key=api_key,
        base_url=api_base,
        # æ·»åŠ ç‰¹å®šå‚æ•°
    )
```

#### prompts.py - Promptç®¡ç†

**æ ¸å¿ƒåŠŸèƒ½**ï¼š
- ç»Ÿä¸€ç®¡ç†æ‰€æœ‰Promptæ¨¡æ¿
- æä¾›Promptæ„å»ºå·¥å…·ç±»

**ç±»ç»“æ„**ï¼š
```python
class PromptTemplates:
    """Promptæ¨¡æ¿é›†åˆ"""
    RESUME_EVALUATION = """..."""      # ç®€å†è¯„ä¼°
    QUICK_SCORE = """..."""           # å¿«é€Ÿè¯„åˆ†
    IMPROVEMENT_SUGGESTIONS = """...""" # æ”¹è¿›å»ºè®®
    JOB_ANALYSIS = """..."""          # å²—ä½è§£è¯»
    INTERVIEW_TECHNICAL = """..."""    # æŠ€æœ¯é¢è¯•
    INTERVIEW_BEHAVIORAL = """..."""   # è¡Œä¸ºé¢è¯•
    INTERVIEW_COMPREHENSIVE = """...""" # ç»¼åˆé¢è¯•

class PromptManager:
    """Promptç®¡ç†å™¨"""
    @staticmethod
    def get_resume_evaluation_prompt(...) -> str:
        """æ„å»ºç®€å†è¯„ä¼°Prompt"""
```

**æ‰©å±•ç¤ºä¾‹**ï¼šæ·»åŠ æ–°çš„Promptæ¨¡æ¿
```python
# 1. åœ¨ PromptTemplates ä¸­æ·»åŠ æ¨¡æ¿
class PromptTemplates:
    NEW_FEATURE = """ä½ çš„Promptæ¨¡æ¿..."""

# 2. åœ¨ PromptManager ä¸­æ·»åŠ æ„å»ºæ–¹æ³•
class PromptManager:
    @staticmethod
    def get_new_feature_prompt(param1, param2) -> str:
        return PromptTemplates.NEW_FEATURE.format(
            param1=param1,
            param2=param2
        )
```

#### settings.py - ç³»ç»Ÿé…ç½®

**æ ¸å¿ƒåŠŸèƒ½**ï¼š
- ç®¡ç†ç³»ç»Ÿçº§é…ç½®å‚æ•°
- æä¾›é…ç½®ç±»

**é…ç½®ç±»**ï¼š
```python
class SystemConfig:
    # Webæœç´¢é…ç½®
    ENABLE_WEB_SEARCH: bool
    WEB_SEARCH_ENGINE: str
    MAX_SEARCH_RESULTS: int
    
    # é¢è¯•é…ç½®
    MAX_HISTORY_TURNS: int
    
    # æ—¥å¿—é…ç½®
    LOG_LEVEL: str
```

---

### 2. ä¸šåŠ¡é€»è¾‘æ¨¡å— (src/)

#### loaders/resume_loader.py - ç®€å†åŠ è½½å™¨

**æ ¸å¿ƒç±»**ï¼š`ResumeLoader`

**ä¸»è¦æ–¹æ³•**ï¼š
```python
def load_resume(self, file_path: str) -> Dict[str, Any]:
    """
    åŠ è½½å¹¶è§£æPDFç®€å†
    
    Args:
        file_path: ç®€å†æ–‡ä»¶è·¯å¾„
        
    Returns:
        {
            "content": str,      # ç®€å†æ–‡æœ¬å†…å®¹
            "metadata": {        # å…ƒæ•°æ®
                "file_name": str,
                "file_size": int,
                "content_length": int,
                "load_time": float
            }
        }
    """
```

**æ‰©å±•ç¤ºä¾‹**ï¼šæ”¯æŒDOCXæ ¼å¼
```python
import docx

def load_resume(self, file_path: str) -> Dict[str, Any]:
    # æ·»åŠ æ ¼å¼æ£€æµ‹
    if file_path.endswith('.docx'):
        return self._load_docx(file_path)
    elif file_path.endswith('.pdf'):
        return self._load_pdf(file_path)
    
def _load_docx(self, file_path: str) -> Dict[str, Any]:
    doc = docx.Document(file_path)
    text = "\n".join([para.text for para in doc.paragraphs])
    # æ„å»ºè¿”å›ç»“æœ...
```

#### evaluator/resume_evaluator.py - ç®€å†è¯„ä¼°å™¨

**æ ¸å¿ƒç±»**ï¼š`ResumeEvaluator`

**ä¸»è¦æ–¹æ³•**ï¼š
```python
def evaluate(self, resume_content: str, 
             position: Optional[str] = None,
             requirements: Optional[str] = None) -> Dict[str, Any]:
    """å®Œæ•´è¯„ä¼°"""

def quick_score(self, resume_content: str) -> Dict[str, Any]:
    """å¿«é€Ÿè¯„åˆ†"""

def suggest_improvements(self, resume_content: str) -> Dict[str, Any]:
    """æ”¹è¿›å»ºè®®"""
```

**æ‰©å±•ç¤ºä¾‹**ï¼šæ·»åŠ æ–°çš„è¯„ä¼°ç»´åº¦
```python
def evaluate_with_custom_dimensions(
    self, 
    resume_content: str,
    custom_dimensions: List[str]
) -> Dict[str, Any]:
    """ä½¿ç”¨è‡ªå®šä¹‰è¯„ä¼°ç»´åº¦"""
    
    # æ„å»ºè‡ªå®šä¹‰Prompt
    dimensions_text = "\n".join([
        f"- {dim}" for dim in custom_dimensions
    ])
    
    prompt = f"""è¯·ä»ä»¥ä¸‹ç»´åº¦è¯„ä¼°ç®€å†ï¼š
{dimensions_text}

ç®€å†å†…å®¹ï¼š
{resume_content}
"""
    
    # è°ƒç”¨LLM
    response = self.client.chat.completions.create(...)
    return result
```

#### interview/interview_agent.py - é¢è¯•Agent

**æ ¸å¿ƒç±»**ï¼š`InterviewAgent`

**ä¸»è¦æ–¹æ³•**ï¼š
```python
def start_interview(self) -> Dict[str, Any]:
    """å¼€å§‹é¢è¯•ï¼Œç”Ÿæˆå¼€åœºç™½"""

def chat(self, user_message: str, 
         use_web_search: bool = False) -> Dict[str, Any]:
    """å¤„ç†ç”¨æˆ·å›ç­”ï¼Œç”Ÿæˆé¢è¯•å®˜å›å¤"""

def get_interview_summary(self) -> Dict[str, Any]:
    """è·å–é¢è¯•æ€»ç»“"""

def clear_history(self):
    """æ¸…ç©ºå¯¹è¯å†å²"""
```

**å¯¹è¯ç®¡ç†**ï¼š
```python
# å¯¹è¯å†å²ç»“æ„
self.chat_history: List[Dict[str, str]] = [
    {"role": "system", "content": "ç³»ç»Ÿæç¤º"},
    {"role": "assistant", "content": "é¢è¯•å®˜æ¶ˆæ¯"},
    {"role": "user", "content": "ç”¨æˆ·æ¶ˆæ¯"},
    ...
]
```

**æ‰©å±•ç¤ºä¾‹**ï¼šæ·»åŠ é¢è¯•è¯„åˆ†åŠŸèƒ½
```python
def score_answer(self, answer: str, question: str) -> Dict[str, Any]:
    """è¯„ä¼°å›ç­”è´¨é‡"""
    
    prompt = f"""ä½œä¸ºé¢è¯•å®˜ï¼Œè¯·è¯„ä¼°ä»¥ä¸‹å›ç­”ï¼š

é—®é¢˜ï¼š{question}
å›ç­”ï¼š{answer}

è¯·ç»™å‡ºï¼š
1. è¯„åˆ†ï¼ˆ0-10åˆ†ï¼‰
2. è¯„ä»·
3. æ”¹è¿›å»ºè®®
"""
    
    response = self.client.chat.completions.create(...)
    return {
        "score": ...,
        "evaluation": ...,
        "suggestions": ...
    }
```

#### tools/web_search.py - Webæœç´¢å·¥å…·

**æ ¸å¿ƒç±»**ï¼š`WebSearchTool`

**ä¸»è¦æ–¹æ³•**ï¼š
```python
def search(self, query: str) -> List[Dict[str, str]]:
    """
    æ‰§è¡Œæœç´¢
    
    Returns:
        [
            {
                "title": "æ ‡é¢˜",
                "url": "é“¾æ¥",
                "snippet": "æ‘˜è¦"
            },
            ...
        ]
    """
```

**æ‰©å±•ç¤ºä¾‹**ï¼šæ·»åŠ Googleæœç´¢æ”¯æŒ
```python
from googlesearch import search as google_search

class WebSearchTool:
    def _google_search(self, query: str) -> List[Dict[str, str]]:
        """Googleæœç´¢å®ç°"""
        results = []
        for url in google_search(query, num_results=self.max_results):
            # è·å–é¡µé¢å†…å®¹
            results.append({
                "title": ...,
                "url": url,
                "snippet": ...
            })
        return results
```

---

### 3. UIå±‚ (web_ui.py)

**æ ¸å¿ƒç»“æ„**ï¼š
```python
# å…¨å±€å˜é‡
resume_loader: Optional[ResumeLoader] = None
resume_evaluator: Optional[ResumeEvaluator] = None
interview_agent: Optional[InterviewAgent] = None
current_resume_content: Optional[str] = None

# åˆå§‹åŒ–å‡½æ•°
def initialize_components():
    """åˆå§‹åŒ–ç³»ç»Ÿç»„ä»¶"""

# åŠŸèƒ½å‡½æ•°
def upload_resume(file) -> str:
    """ä¸Šä¼ ç®€å†"""

def evaluate_resume(position: str, requirements: str) -> str:
    """è¯„ä¼°ç®€å†"""

def analyze_job_position(job_input: str, question_count: int) -> str:
    """å²—ä½è§£è¯»"""

def start_interview(interview_type: str, enable_web: bool) -> List:
    """å¼€å§‹é¢è¯•"""

def chat_with_interviewer(message: str, history: List, 
                          enable_web: bool) -> Tuple[str, List]:
    """é¢è¯•å¯¹è¯"""

# UIåˆ›å»ºå‡½æ•°
def create_ui():
    """åˆ›å»ºGradio UI"""
```

**æ‰©å±•ç¤ºä¾‹**ï¼šæ·»åŠ æ–°çš„Tabé¡µ
```python
def create_ui():
    with gr.Blocks() as app:
        # ç°æœ‰Tabé¡µ...
        
        # æ–°å¢Tabé¡µ
        with gr.Tab("ğŸ†• æ–°åŠŸèƒ½"):
            gr.Markdown("## æ–°åŠŸèƒ½è¯´æ˜")
            
            with gr.Row():
                input_box = gr.Textbox(label="è¾“å…¥")
                output_box = gr.Markdown(value="è¾“å‡º")
            
            submit_btn = gr.Button("æäº¤")
            
            # ç»‘å®šäº‹ä»¶
            submit_btn.click(
                fn=your_new_function,
                inputs=[input_box],
                outputs=[output_box]
            )
    
    return app
```

---

## æ‰©å±•å¼€å‘

### 1. æ·»åŠ æ–°çš„è¯„ä¼°ç»´åº¦

**æ­¥éª¤**ï¼š

1. **ä¿®æ”¹Promptæ¨¡æ¿** (`config/prompts.py`)
```python
RESUME_EVALUATION = """
...ç°æœ‰ç»´åº¦...

7. **ä½ çš„æ–°ç»´åº¦**ï¼ˆ0-10åˆ†ï¼‰
   è¯„ä¼°æ ‡å‡†...
"""
```

2. **æ— éœ€ä¿®æ”¹ä»£ç **ï¼ŒPromptå˜æ›´ä¼šè‡ªåŠ¨ç”Ÿæ•ˆ

### 2. æ·»åŠ æ–°çš„é¢è¯•ç±»å‹

**æ­¥éª¤**ï¼š

1. **æ·»åŠ Promptæ¨¡æ¿** (`config/prompts.py`)
```python
class PromptTemplates:
    INTERVIEW_NEW_TYPE = """ä½ æ˜¯ä¸€ä½XXé¢è¯•å®˜..."""

class PromptManager:
    @staticmethod
    def get_interview_prompt_new_type(resume_summary: str) -> str:
        return PromptTemplates.INTERVIEW_NEW_TYPE.format(
            resume_summary=resume_summary
        )
```

2. **ä¿®æ”¹é¢è¯•Agent** (`src/interview/interview_agent.py`)
```python
def _build_system_prompt(self) -> str:
    if self.interview_type == "new_type":
        return PromptManager.get_interview_prompt_new_type(
            self._extract_resume_summary()
        )
    # ç°æœ‰ä»£ç ...
```

3. **ä¿®æ”¹UI** (`web_ui.py`)
```python
interview_type = gr.Radio(
    choices=[
        ("æŠ€æœ¯é¢è¯•", "technical"),
        ("è¡Œä¸ºé¢è¯•", "behavioral"),
        ("ç»¼åˆé¢è¯•", "comprehensive"),
        ("æ–°ç±»å‹é¢è¯•", "new_type"),  # æ·»åŠ 
    ]
)
```

### 3. é›†æˆæ–°çš„LLMæœåŠ¡å•†

**æ­¥éª¤**ï¼š

1. **ä¿®æ”¹é…ç½®** (`config/llm_config.py`)
```python
def get_llm_client() -> Tuple[OpenAI, str, float]:
    # è¯»å–é…ç½®
    api_base = os.getenv("LLM_API_BASE")
    
    # æ·»åŠ æ–°æœåŠ¡å•†åˆ¤æ–­
    if "new-llm-service.com" in api_base:
        client = OpenAI(
            api_key=api_key,
            base_url=api_base,
            # æ–°æœåŠ¡å•†ç‰¹å®šé…ç½®
            timeout=60.0,
            max_retries=3,
        )
    
    return client, model, temperature
```

2. **æ›´æ–°ç¯å¢ƒå˜é‡æ¨¡æ¿** (`.env.example`)
```ini
# æ–°LLMæœåŠ¡å•†
LLM_API_KEY=your-api-key
LLM_API_BASE=https://api.new-llm-service.com/v1
LLM_MODEL=new-model-name
```

### 4. æ·»åŠ ç®€å†å¯¼å‡ºåŠŸèƒ½

**å®ç°ç¤ºä¾‹**ï¼š
```python
# åœ¨ web_ui.py ä¸­æ·»åŠ 
def export_evaluation_report(evaluation_result: str) -> str:
    """å¯¼å‡ºè¯„ä¼°æŠ¥å‘Šä¸ºPDF"""
    import markdown
    from weasyprint import HTML
    
    # Markdownè½¬HTML
    html_content = markdown.markdown(evaluation_result)
    
    # HTMLè½¬PDF
    output_path = f"output/evaluation_{int(time.time())}.pdf"
    HTML(string=html_content).write_pdf(output_path)
    
    return output_path

# UIä¸­æ·»åŠ å¯¼å‡ºæŒ‰é’®
export_btn = gr.Button("ğŸ“¥ å¯¼å‡ºPDF")
export_btn.click(
    fn=export_evaluation_report,
    inputs=[evaluation_output],
    outputs=[gr.File()]
)
```

---

## è°ƒè¯•ä¸æµ‹è¯•

### æ—¥å¿—ç³»ç»Ÿ

**é…ç½®æ—¥å¿—çº§åˆ«** (`.env`)
```ini
LOG_LEVEL=DEBUG  # DEBUG, INFO, WARNING, ERROR
```

**æ—¥å¿—ä½ç½®**
- æ—¥å¿—æ–‡ä»¶ï¼š`logs/app_{æ—¥æœŸ}.log`
- æ§åˆ¶å°è¾“å‡ºï¼šå®æ—¶æ˜¾ç¤º

**å…³é”®æ—¥å¿—ç‚¹**ï¼š
```python
from loguru import logger

# åŠŸèƒ½å…¥å£
logger.info("å¼€å§‹XXXåŠŸèƒ½...")

# LLMè°ƒç”¨ï¼ˆå·²å†…ç½®ï¼‰
logger.info(f"[LLM API] XXX - Prompt:\n{prompt}")

# é”™è¯¯å¤„ç†
logger.error(f"XXXå¤±è´¥: {e}")

# è°ƒè¯•ä¿¡æ¯
logger.debug(f"ä¸­é—´ç»“æœ: {data}")
```

### å•å…ƒæµ‹è¯•

**æµ‹è¯•ç»“æ„**ï¼š
```
tests/
â”œâ”€â”€ test_loaders.py
â”œâ”€â”€ test_evaluator.py
â”œâ”€â”€ test_interview.py
â””â”€â”€ test_tools.py
```

**ç¼–å†™æµ‹è¯•**ï¼š
```python
# tests/test_evaluator.py
import pytest
from src.evaluator import ResumeEvaluator

def test_quick_score():
    evaluator = ResumeEvaluator()
    resume = "æµ‹è¯•ç®€å†å†…å®¹..."
    
    result = evaluator.quick_score(resume)
    
    assert "score_text" in result
    assert "metadata" in result
    assert result["metadata"]["elapsed_time"] > 0
```

**è¿è¡Œæµ‹è¯•**ï¼š
```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
pytest

# è¿è¡Œç‰¹å®šæµ‹è¯•
pytest tests/test_evaluator.py

# æ˜¾ç¤ºè¯¦ç»†è¾“å‡º
pytest -v

# ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š
pytest --cov=src tests/
```

### è°ƒè¯•æŠ€å·§

1. **Promptè°ƒè¯•**
   - æ‰€æœ‰LLMè°ƒç”¨éƒ½ä¼šæ‰“å°Promptæ—¥å¿—
   - è®¾ç½® `LOG_LEVEL=INFO` æŸ¥çœ‹å®Œæ•´Prompt
   - å¤åˆ¶Promptåˆ°LLMå¹³å°æµ‹è¯•

2. **æ–­ç‚¹è°ƒè¯•**
   - VS Code: æ·»åŠ æ–­ç‚¹åæŒ‰F5å¯åŠ¨è°ƒè¯•
   - PyCharm: å³é”® -> Debug 'web_ui'

3. **Gradioè°ƒè¯•**
   - åœ¨ `web_ui.py` çš„ `launch()` ä¸­æ·»åŠ  `debug=True`
   - æŸ¥çœ‹æµè§ˆå™¨æ§åˆ¶å°çš„ç½‘ç»œè¯·æ±‚

---

## éƒ¨ç½²æŒ‡å—

### æœ¬åœ°éƒ¨ç½²

å‚è€ƒ[å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)éƒ¨åˆ†ã€‚

### Dockeréƒ¨ç½²

1. **åˆ›å»ºDockerfile**
```dockerfile
FROM python:3.9-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

EXPOSE 7861

CMD ["python", "web_ui.py"]
```

2. **æ„å»ºé•œåƒ**
```bash
docker build -t interview-coach .
```

3. **è¿è¡Œå®¹å™¨**
```bash
docker run -d \
  -p 7861:7861 \
  -v $(pwd)/data:/app/data \
  -v $(pwd)/logs:/app/logs \
  --env-file .env \
  --name interview-coach \
  interview-coach
```

### äº‘æœåŠ¡å™¨éƒ¨ç½²

1. **ä½¿ç”¨systemdæœåŠ¡**

åˆ›å»º `/etc/systemd/system/interview-coach.service`ï¼š
```ini
[Unit]
Description=AI Interview Coach
After=network.target

[Service]
Type=simple
User=your-user
WorkingDirectory=/path/to/interview-coach
Environment="PATH=/path/to/venv/bin"
ExecStart=/path/to/venv/bin/python web_ui.py
Restart=always

[Install]
WantedBy=multi-user.target
```

å¯åŠ¨æœåŠ¡ï¼š
```bash
sudo systemctl enable interview-coach
sudo systemctl start interview-coach
sudo systemctl status interview-coach
```

2. **ä½¿ç”¨Nginxåå‘ä»£ç†**

```nginx
server {
    listen 80;
    server_name your-domain.com;

    location / {
        proxy_pass http://127.0.0.1:7861;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
    }
}
```

### æ€§èƒ½ä¼˜åŒ–

1. **APIè°ƒç”¨ä¼˜åŒ–**
   - ä½¿ç”¨æ›´å¿«çš„æ¨¡å‹ï¼ˆå¦‚GPT-3.5-turboï¼‰
   - å‡å°‘temperatureé™ä½éšæœºæ€§
   - é™åˆ¶max_tokenså‡å°‘å“åº”æ—¶é—´

2. **ç¼“å­˜ä¼˜åŒ–**
   - ç¼“å­˜å¸¸ç”¨çš„è¯„ä¼°ç»“æœ
   - ä½¿ç”¨Redisç¼“å­˜Promptç»“æœ

3. **å¹¶å‘å¤„ç†**
   - Gradioé»˜è®¤æ”¯æŒå¤šç”¨æˆ·å¹¶å‘
   - æ³¨æ„LLM APIçš„å¹¶å‘é™åˆ¶

---

## å¸¸è§é—®é¢˜

### Q1: å¦‚ä½•ä¿®æ”¹UIç«¯å£ï¼Ÿ

**A**: ä¿®æ”¹ `web_ui.py` ä¸­çš„ `launch()` å‚æ•°ï¼š
```python
app.launch(
    server_name="127.0.0.1",
    server_port=7862,  # ä¿®æ”¹ç«¯å£
    share=False,
)
```

### Q2: å¦‚ä½•æ·»åŠ ç”¨æˆ·è®¤è¯ï¼Ÿ

**A**: Gradioæ”¯æŒè®¤è¯ï¼š
```python
app.launch(
    server_name="127.0.0.1",
    server_port=7861,
    auth=("username", "password"),  # æ·»åŠ è®¤è¯
)
```

### Q3: å¦‚ä½•ä¼˜åŒ–LLMå“åº”é€Ÿåº¦ï¼Ÿ

**A**: 
- ä½¿ç”¨æ›´å¿«çš„æ¨¡å‹
- å‡å°‘Prompté•¿åº¦
- ä½¿ç”¨streamingæ¨¡å¼ï¼ˆéœ€ä¿®æ”¹ä»£ç ï¼‰
- å¢åŠ APIå¹¶å‘é™åˆ¶

### Q4: å¦‚ä½•æ”¯æŒå¤šè¯­è¨€ï¼Ÿ

**A**: ä¿®æ”¹Promptæ¨¡æ¿ï¼Œæ·»åŠ è¯­è¨€å‚æ•°ï¼š
```python
def get_resume_evaluation_prompt(resume_content, language="zh"):
    if language == "en":
        prompt = """You are a senior HR..."""
    else:
        prompt = """ä½ æ˜¯ä¸€ä½èµ„æ·±HR..."""
    return prompt
```

### Q5: å¦‚ä½•ç›‘æ§ç³»ç»Ÿè¿è¡ŒçŠ¶æ€ï¼Ÿ

**A**: 
- æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶ï¼š`tail -f logs/app_*.log`
- æ·»åŠ ç›‘æ§æ¥å£ï¼ˆéœ€å¼€å‘ï¼‰
- ä½¿ç”¨ç³»ç»Ÿç›‘æ§å·¥å…·ï¼ˆå¦‚Prometheusï¼‰

---

## ä»£ç è§„èŒƒ

### Pythonä»£ç è§„èŒƒ

éµå¾ª PEP 8 è§„èŒƒï¼š

```python
# å‘½åè§„èŒƒ
class ResumeEvaluator:  # ç±»åï¼šå¤§é©¼å³°
    def evaluate_resume(self):  # å‡½æ•°åï¼šå°å†™+ä¸‹åˆ’çº¿
        max_score = 100  # å˜é‡åï¼šå°å†™+ä¸‹åˆ’çº¿
        API_KEY = "xxx"  # å¸¸é‡ï¼šå¤§å†™+ä¸‹åˆ’çº¿

# æ³¨é‡Šè§„èŒƒ
def process_data(data: List[str]) -> Dict[str, Any]:
    """
    å¤„ç†æ•°æ®çš„ç®€çŸ­æè¿°
    
    Args:
        data: è¾“å…¥æ•°æ®è¯´æ˜
        
    Returns:
        è¿”å›å€¼è¯´æ˜
        
    Raises:
        ValueError: å¼‚å¸¸æƒ…å†µè¯´æ˜
    """
    pass

# ç±»å‹æ³¨è§£
from typing import Optional, List, Dict, Any

def func(param: str) -> Optional[Dict[str, Any]]:
    pass
```

### æ ¼å¼åŒ–å·¥å…·

```bash
# ä½¿ç”¨blackæ ¼å¼åŒ–
black web_ui.py

# ä½¿ç”¨flake8æ£€æŸ¥
flake8 web_ui.py

# ä½¿ç”¨mypyç±»å‹æ£€æŸ¥
mypy web_ui.py
```

---

## è´¡çŒ®æŒ‡å—

1. Forké¡¹ç›®
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. æäº¤Pull Request

---

## æŠ€æœ¯æ”¯æŒ

- ğŸ“§ Email: support@example.com
- ğŸ’¬ Discussion: GitHub Discussions
- ğŸ› Bug Report: GitHub Issues

---

ç¥å¼€å‘é¡ºåˆ©ï¼å¦‚æœ‰é—®é¢˜æ¬¢è¿åé¦ˆã€‚
