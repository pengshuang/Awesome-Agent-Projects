# AI æ¨¡æ‹Ÿé¢è¯•ç³»ç»Ÿ - å¼€å‘æŒ‡å—

æœ¬æŒ‡å—é¢å‘å¼€å‘è€…ï¼Œä»‹ç»å¦‚ä½•è¿›è¡ŒäºŒæ¬¡å¼€å‘ã€åŠŸèƒ½æ‰©å±•å’Œç³»ç»Ÿå®šåˆ¶ã€‚

## ğŸ“‹ ç›®å½•

- [å¼€å‘ç¯å¢ƒæ­å»º](#å¼€å‘ç¯å¢ƒæ­å»º)
- [é¡¹ç›®æ¶æ„](#é¡¹ç›®æ¶æ„)
- [æ ¸å¿ƒæ¨¡å—è¯¦è§£](#æ ¸å¿ƒæ¨¡å—è¯¦è§£)
- [æ‰©å±•å¼€å‘](#æ‰©å±•å¼€å‘)
- [è°ƒè¯•ä¸æµ‹è¯•](#è°ƒè¯•ä¸æµ‹è¯•)
- [éƒ¨ç½²æŒ‡å—](#éƒ¨ç½²æŒ‡å—)
- [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)

---

## å¼€å‘ç¯å¢ƒæ­å»º

### ç¯å¢ƒè¦æ±‚

- Python 3.9+
- pip 20.0+
- Git
- ä»£ç ç¼–è¾‘å™¨ï¼ˆæ¨è VS Codeï¼‰

### å¼€å‘ç¯å¢ƒé…ç½®

1. **å…‹éš†é¡¹ç›®**
```bash
git clone https://github.com/yourusername/interview-coach.git
cd interview-coach
```

2. **åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ**ï¼ˆæ¨èï¼‰
```bash
# ä½¿ç”¨ venv
python -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate  # Windows

# æˆ–ä½¿ç”¨ conda
conda create -n interview-coach python=3.9
conda activate interview-coach
```

3. **å®‰è£…ä¾èµ–**
```bash
# å®‰è£…æ ¸å¿ƒä¾èµ–
pip install -r requirements.txt

# å®‰è£…å¼€å‘ä¾èµ–ï¼ˆå¯é€‰ï¼‰
pip install pytest black flake8 mypy
```

4. **é…ç½®ç¯å¢ƒå˜é‡**
```bash
cp .env.example .env
# ç¼–è¾‘ .env æ–‡ä»¶ï¼Œå¡«å†™å¼€å‘ç”¨çš„APIå¯†é’¥
```

5. **éªŒè¯å®‰è£…**
```bash
python -c "import gradio; import openai; print('Environment OK')"
```

---

## é¡¹ç›®æ¶æ„

### æ•´ä½“æ¶æ„

```
interview-coach/
â”œâ”€â”€ config/                    # é…ç½®å±‚
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ llm_config.py         # LLMå®¢æˆ·ç«¯é…ç½®
â”‚   â”œâ”€â”€ prompts.py            # Promptæ¨¡æ¿ç®¡ç†
â”‚   â””â”€â”€ settings.py           # ç³»ç»Ÿé…ç½®
â”‚
â”œâ”€â”€ src/                       # ä¸šåŠ¡é€»è¾‘å±‚
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ constants.py          # å¸¸é‡å®šä¹‰
â”‚   â”‚
â”‚   â”œâ”€â”€ loaders/              # æ•°æ®åŠ è½½æ¨¡å—
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ resume_loader.py
â”‚   â”‚
â”‚   â”œâ”€â”€ evaluator/            # è¯„ä¼°æ¨¡å—
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ resume_evaluator.py
â”‚   â”‚
â”‚   â”œâ”€â”€ interview/            # é¢è¯•æ¨¡å—
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ interview_agent.py
â”‚   â”‚
â”‚   â”œâ”€â”€ tools/                # å·¥å…·æ¨¡å—
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ web_search.py
â”‚   â”‚
â”‚   â””â”€â”€ utils/                # å·¥å…·å‡½æ•°
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ logger.py
â”‚       â””â”€â”€ helpers.py
â”‚
â”œâ”€â”€ data/                      # æ•°æ®å±‚
â”‚   â”œâ”€â”€ resumes/              # ç®€å†å­˜å‚¨
â”‚   â””â”€â”€ cache/                # ç¼“å­˜æ–‡ä»¶
â”‚
â”œâ”€â”€ logs/                      # æ—¥å¿—æ–‡ä»¶
â”œâ”€â”€ docs/                      # æ–‡æ¡£
â”‚
â”œâ”€â”€ web_ui.py                 # UIå±‚ï¼ˆGradioï¼‰
â”œâ”€â”€ init_system.py            # ç³»ç»Ÿåˆå§‹åŒ–
â””â”€â”€ requirements.txt          # ä¾èµ–ç®¡ç†
```

### æ¶æ„è®¾è®¡åŸåˆ™

1. **æ¨¡å—åŒ–**ï¼šæ¯ä¸ªæ¨¡å—èŒè´£å•ä¸€ï¼Œä½è€¦åˆ
2. **é…ç½®é©±åŠ¨**ï¼šæ ¸å¿ƒé…ç½®é›†ä¸­ç®¡ç†ï¼Œæ˜“äºä¿®æ”¹
3. **å¯æ‰©å±•**ï¼šé¢„ç•™æ‰©å±•æ¥å£ï¼Œæ–¹ä¾¿æ·»åŠ æ–°åŠŸèƒ½
4. **ç®€æ´æ€§**ï¼šç›´æ¥ä½¿ç”¨OpenAI SDKï¼Œä¸å¼•å…¥å¤æ‚æ¡†æ¶
5. **å¯ç»´æŠ¤**ï¼šå®Œå–„çš„æ—¥å¿—å’Œé”™è¯¯å¤„ç†

---

## æ ¸å¿ƒæ¨¡å—è¯¦è§£

### 1. é…ç½®æ¨¡å— (config/)

#### llm_config.py - LLMé…ç½®

**æ ¸å¿ƒåŠŸèƒ½**ï¼š
- ä»ç¯å¢ƒå˜é‡è¯»å–LLMé…ç½®
- åˆ›å»ºOpenAIå®¢æˆ·ç«¯å®ä¾‹
- æ”¯æŒå¤šç§LLMæœåŠ¡å•†

**å…³é”®å‡½æ•°**ï¼š
```python
def get_llm_client() -> Tuple[OpenAI, str, float]:
    """
    è·å–LLMå®¢æˆ·ç«¯å®ä¾‹
    
    Returns:
        (client, model, temperature)
    """
```

**æ‰©å±•ç¤ºä¾‹**ï¼šæ·»åŠ æ–°çš„LLMæœåŠ¡å•†
```python
# åœ¨ get_llm_client ä¸­æ·»åŠ 
if api_base.endswith("your-llm-service.com"):
    # æ·»åŠ ç‰¹å®šé…ç½®
    client = OpenAI(
        api_key=api_key,
        base_url=api_base,
        # æ·»åŠ ç‰¹å®šå‚æ•°
    )
```

#### prompts.py - Promptç®¡ç†

**æ ¸å¿ƒåŠŸèƒ½**ï¼š
- ç»Ÿä¸€ç®¡ç†æ‰€æœ‰Promptæ¨¡æ¿
- æä¾›Promptæ„å»ºå·¥å…·ç±»

**ç±»ç»“æ„**ï¼š
```python
class PromptTemplates:
    """Promptæ¨¡æ¿é›†åˆ"""
    RESUME_EVALUATION = """..."""      # ç®€å†è¯„ä¼°
    QUICK_SCORE = """..."""           # å¿«é€Ÿè¯„åˆ†
    IMPROVEMENT_SUGGESTIONS = """...""" # æ”¹è¿›å»ºè®®
    JOB_ANALYSIS = """..."""          # å²—ä½è§£è¯»
    INTERVIEW_TECHNICAL = """..."""    # æŠ€æœ¯é¢è¯•
    INTERVIEW_BEHAVIORAL = """..."""   # è¡Œä¸ºé¢è¯•
    INTERVIEW_COMPREHENSIVE = """...""" # ç»¼åˆé¢è¯•

class PromptManager:
    """Promptç®¡ç†å™¨"""
    @staticmethod
    def get_resume_evaluation_prompt(...) -> str:
        """æ„å»ºç®€å†è¯„ä¼°Prompt"""
```

**æ‰©å±•ç¤ºä¾‹**ï¼šæ·»åŠ æ–°çš„Promptæ¨¡æ¿
```python
# 1. åœ¨ PromptTemplates ä¸­æ·»åŠ æ¨¡æ¿
class PromptTemplates:
    NEW_FEATURE = """ä½ çš„Promptæ¨¡æ¿..."""

# 2. åœ¨ PromptManager ä¸­æ·»åŠ æ„å»ºæ–¹æ³•
class PromptManager:
    @staticmethod
    def get_new_feature_prompt(param1, param2) -> str:
        return PromptTemplates.NEW_FEATURE.format(
            param1=param1,
            param2=param2
        )
```

#### settings.py - ç³»ç»Ÿé…ç½®

**æ ¸å¿ƒåŠŸèƒ½**ï¼š
- ç®¡ç†ç³»ç»Ÿçº§é…ç½®å‚æ•°
- æä¾›é…ç½®ç±»

**é…ç½®ç±»**ï¼š
```python
class SystemConfig:
    # Webæœç´¢é…ç½®
    ENABLE_WEB_SEARCH: bool
    WEB_SEARCH_ENGINE: str
    MAX_SEARCH_RESULTS: int
    
    # é¢è¯•é…ç½®
    MAX_HISTORY_TURNS: int
    
    # æ—¥å¿—é…ç½®
    LOG_LEVEL: str
```

---

### 2. ä¸šåŠ¡é€»è¾‘æ¨¡å— (src/)

#### loaders/resume_loader.py - ç®€å†åŠ è½½å™¨

**æ ¸å¿ƒç±»**ï¼š`ResumeLoader`

**ä¸»è¦æ–¹æ³•**ï¼š
```python
def load_resume(self, file_path: str) -> Dict[str, Any]:
    """
    åŠ è½½å¹¶è§£æPDFç®€å†
    
    Args:
        file_path: ç®€å†æ–‡ä»¶è·¯å¾„
        
    Returns:
        {
            "content": str,      # ç®€å†æ–‡æœ¬å†…å®¹
            "metadata": {        # å…ƒæ•°æ®
                "file_name": str,
                "file_size": int,
                "content_length": int,
                "load_time": float
            }
        }
    """
```

**æ‰©å±•ç¤ºä¾‹**ï¼šæ”¯æŒDOCXæ ¼å¼
```python
import docx

def load_resume(self, file_path: str) -> Dict[str, Any]:
    # æ·»åŠ æ ¼å¼æ£€æµ‹
    if file_path.endswith('.docx'):
        return self._load_docx(file_path)
    elif file_path.endswith('.pdf'):
        return self._load_pdf(file_path)
    
def _load_docx(self, file_path: str) -> Dict[str, Any]:
    doc = docx.Document(file_path)
    text = "\n".join([para.text for para in doc.paragraphs])
    # æ„å»ºè¿”å›ç»“æœ...
```

#### evaluator/resume_evaluator.py - ç®€å†è¯„ä¼°å™¨

**æ ¸å¿ƒç±»**ï¼š`ResumeEvaluator`

**ä¸»è¦æ–¹æ³•**ï¼š
```python
def evaluate(self, resume_content: str, 
             position: Optional[str] = None,
             requirements: Optional[str] = None) -> Dict[str, Any]:
    """å®Œæ•´è¯„ä¼°"""

def quick_score(self, resume_content: str) -> Dict[str, Any]:
    """å¿«é€Ÿè¯„åˆ†"""

def suggest_improvements(self, resume_content: str) -> Dict[str, Any]:
    """æ”¹è¿›å»ºè®®"""
```

**æ‰©å±•ç¤ºä¾‹**ï¼šæ·»åŠ æ–°çš„è¯„ä¼°ç»´åº¦
```python
def evaluate_with_custom_dimensions(
    self, 
    resume_content: str,
    custom_dimensions: List[str]
) -> Dict[str, Any]:
    """ä½¿ç”¨è‡ªå®šä¹‰è¯„ä¼°ç»´åº¦"""
    
    # æ„å»ºè‡ªå®šä¹‰Prompt
    dimensions_text = "\n".join([
        f"- {dim}" for dim in custom_dimensions
    ])
    
    prompt = f"""è¯·ä»ä»¥ä¸‹ç»´åº¦è¯„ä¼°ç®€å†ï¼š
{dimensions_text}

ç®€å†å†…å®¹ï¼š
{resume_content}
"""
    
    # è°ƒç”¨LLM
    response = self.client.chat.completions.create(...)
    return result
```

#### interview/interview_agent.py - é¢è¯•Agent

**æ ¸å¿ƒç±»**ï¼š`InterviewAgent`

**ä¸»è¦æ–¹æ³•**ï¼š
```python
def start_interview(self) -> Dict[str, Any]:
    """å¼€å§‹é¢è¯•ï¼Œç”Ÿæˆå¼€åœºç™½"""

def chat(self, user_message: str, 
         use_web_search: bool = False) -> Dict[str, Any]:
    """å¤„ç†ç”¨æˆ·å›ç­”ï¼Œç”Ÿæˆé¢è¯•å®˜å›å¤"""

def get_interview_summary(self) -> Dict[str, Any]:
    """è·å–é¢è¯•æ€»ç»“"""

def clear_history(self):
    """æ¸…ç©ºå¯¹è¯å†å²"""
```

**å¯¹è¯ç®¡ç†**ï¼š
```python
# å¯¹è¯å†å²ç»“æ„
self.chat_history: List[Dict[str, str]] = [
    {"role": "system", "content": "ç³»ç»Ÿæç¤º"},
    {"role": "assistant", "content": "é¢è¯•å®˜æ¶ˆæ¯"},
    {"role": "user", "content": "ç”¨æˆ·æ¶ˆæ¯"},
    ...
]
```

**æ‰©å±•ç¤ºä¾‹**ï¼šæ·»åŠ é¢è¯•è¯„åˆ†åŠŸèƒ½
```python
def score_answer(self, answer: str, question: str) -> Dict[str, Any]:
    """è¯„ä¼°å›ç­”è´¨é‡"""
    
    prompt = f"""ä½œä¸ºé¢è¯•å®˜ï¼Œè¯·è¯„ä¼°ä»¥ä¸‹å›ç­”ï¼š

é—®é¢˜ï¼š{question}
å›ç­”ï¼š{answer}

è¯·ç»™å‡ºï¼š
1. è¯„åˆ†ï¼ˆ0-10åˆ†ï¼‰
2. è¯„ä»·
3. æ”¹è¿›å»ºè®®
"""
    
    response = self.client.chat.completions.create(...)
    return {
        "score": ...,
        "evaluation": ...,
        "suggestions": ...
    }
```

#### tools/web_search.py - Webæœç´¢å·¥å…·

**æ ¸å¿ƒç±»**ï¼š`WebSearchTool`

**ä¸»è¦æ–¹æ³•**ï¼š
```python
def search(self, query: str) -> List[Dict[str, str]]:
    """
    æ‰§è¡Œæœç´¢
    
    Returns:
        [
            {
                "title": "æ ‡é¢˜",
                "url": "é“¾æ¥",
                "snippet": "æ‘˜è¦"
            },
            ...
        ]
    """
```

**æ‰©å±•ç¤ºä¾‹**ï¼šæ·»åŠ Googleæœç´¢æ”¯æŒ
```python
from googlesearch import search as google_search

class WebSearchTool:
    def _google_search(self, query: str) -> List[Dict[str, str]]:
        """Googleæœç´¢å®ç°"""
        results = []
        for url in google_search(query, num_results=self.max_results):
            # è·å–é¡µé¢å†…å®¹
            results.append({
                "title": ...,
                "url": url,
                "snippet": ...
            })
        return results
```

---

### 3. UIå±‚ (web_ui.py)

**æ ¸å¿ƒç»“æ„**ï¼š
```python
# å…¨å±€å˜é‡
resume_loader: Optional[ResumeLoader] = None
resume_evaluator: Optional[ResumeEvaluator] = None
interview_agent: Optional[InterviewAgent] = None
current_resume_content: Optional[str] = None

# åˆå§‹åŒ–å‡½æ•°
def initialize_components():
    """åˆå§‹åŒ–ç³»ç»Ÿç»„ä»¶"""

# åŠŸèƒ½å‡½æ•°
def upload_resume(file) -> str:
    """ä¸Šä¼ ç®€å†"""

def evaluate_resume(position: str, requirements: str) -> str:
    """è¯„ä¼°ç®€å†"""

def analyze_job_position(job_input: str, question_count: int) -> str:
    """å²—ä½è§£è¯»"""

def start_interview(interview_type: str, enable_web: bool) -> List:
    """å¼€å§‹é¢è¯•"""

def chat_with_interviewer(message: str, history: List, 
                          enable_web: bool) -> Tuple[str, List]:
    """é¢è¯•å¯¹è¯"""

# UIåˆ›å»ºå‡½æ•°
def create_ui():
    """åˆ›å»ºGradio UI"""
```

**æ‰©å±•ç¤ºä¾‹**ï¼šæ·»åŠ æ–°çš„Tabé¡µ
```python
def create_ui():
    with gr.Blocks() as app:
        # ç°æœ‰Tabé¡µ...
        
        # æ–°å¢Tabé¡µ
        with gr.Tab("ğŸ†• æ–°åŠŸèƒ½"):
            gr.Markdown("## æ–°åŠŸèƒ½è¯´æ˜")
            
            with gr.Row():
                input_box = gr.Textbox(label="è¾“å…¥")
                output_box = gr.Markdown(value="è¾“å‡º")
            
            submit_btn = gr.Button("æäº¤")
            
            # ç»‘å®šäº‹ä»¶
            submit_btn.click(
                fn=your_new_function,
                inputs=[input_box],
                outputs=[output_box]
            )
    
    return app
```

---

## æ‰©å±•å¼€å‘

### 1. æ·»åŠ æ–°çš„è¯„ä¼°ç»´åº¦

**æ­¥éª¤**ï¼š

1. **ä¿®æ”¹Promptæ¨¡æ¿** (`config/prompts.py`)
```python
RESUME_EVALUATION = """
...ç°æœ‰ç»´åº¦...

7. **ä½ çš„æ–°ç»´åº¦**ï¼ˆ0-10åˆ†ï¼‰
   è¯„ä¼°æ ‡å‡†...
"""
```

2. **æ— éœ€ä¿®æ”¹ä»£ç **ï¼ŒPromptå˜æ›´ä¼šè‡ªåŠ¨ç”Ÿæ•ˆ

### 2. æ·»åŠ æ–°çš„é¢è¯•ç±»å‹

**æ­¥éª¤**ï¼š

1. **æ·»åŠ Promptæ¨¡æ¿** (`config/prompts.py`)
```python
class PromptTemplates:
    INTERVIEW_NEW_TYPE = """ä½ æ˜¯ä¸€ä½XXé¢è¯•å®˜..."""

class PromptManager:
    @staticmethod
    def get_interview_prompt_new_type(resume_summary: str) -> str:
        return PromptTemplates.INTERVIEW_NEW_TYPE.format(
            resume_summary=resume_summary
        )
```

2. **ä¿®æ”¹é¢è¯•Agent** (`src/interview/interview_agent.py`)
```python
def _build_system_prompt(self) -> str:
    if self.interview_type == "new_type":
        return PromptManager.get_interview_prompt_new_type(
            self._extract_resume_summary()
        )
    # ç°æœ‰ä»£ç ...
```

3. **ä¿®æ”¹UI** (`web_ui.py`)
```python
interview_type = gr.Radio(
    choices=[
        ("æŠ€æœ¯é¢è¯•", "technical"),
        ("è¡Œä¸ºé¢è¯•", "behavioral"),
        ("ç»¼åˆé¢è¯•", "comprehensive"),
        ("æ–°ç±»å‹é¢è¯•", "new_type"),  # æ·»åŠ 
    ]
)
```

### 3. é›†æˆæ–°çš„LLMæœåŠ¡å•†

**æ­¥éª¤**ï¼š

1. **ä¿®æ”¹é…ç½®** (`config/llm_config.py`)
```python
def get_llm_client() -> Tuple[OpenAI, str, float]:
    # è¯»å–é…ç½®
    api_base = os.getenv("LLM_API_BASE")
    
    # æ·»åŠ æ–°æœåŠ¡å•†åˆ¤æ–­
    if "new-llm-service.com" in api_base:
        client = OpenAI(
            api_key=api_key,
            base_url=api_base,
            # æ–°æœåŠ¡å•†ç‰¹å®šé…ç½®
            timeout=60.0,
            max_retries=3,
        )
    
    return client, model, temperature
```

2. **æ›´æ–°ç¯å¢ƒå˜é‡æ¨¡æ¿** (`.env.example`)
```ini
# æ–°LLMæœåŠ¡å•†
LLM_API_KEY=your-api-key
LLM_API_BASE=https://api.new-llm-service.com/v1
LLM_MODEL=new-model-name
```

### 4. æ·»åŠ ç®€å†å¯¼å‡ºåŠŸèƒ½

**å®ç°ç¤ºä¾‹**ï¼š
```python
# åœ¨ web_ui.py ä¸­æ·»åŠ 
def export_evaluation_report(evaluation_result: str) -> str:
    """å¯¼å‡ºè¯„ä¼°æŠ¥å‘Šä¸ºPDF"""
    import markdown
    from weasyprint import HTML
    
    # Markdownè½¬HTML
    html_content = markdown.markdown(evaluation_result)
    
    # HTMLè½¬PDF
    output_path = f"output/evaluation_{int(time.time())}.pdf"
    HTML(string=html_content).write_pdf(output_path)
    
    return output_path

# UIä¸­æ·»åŠ å¯¼å‡ºæŒ‰é’®
export_btn = gr.Button("ğŸ“¥ å¯¼å‡ºPDF")
export_btn.click(
    fn=export_evaluation_report,
    inputs=[evaluation_output],
    outputs=[gr.File()]
)
```

---

## è°ƒè¯•ä¸æµ‹è¯•

### æ—¥å¿—ç³»ç»Ÿ

**é…ç½®æ—¥å¿—çº§åˆ«** (`.env`)
```ini
LOG_LEVEL=DEBUG  # DEBUG, INFO, WARNING, ERROR
```

**æ—¥å¿—ä½ç½®**
- æ—¥å¿—æ–‡ä»¶ï¼š`logs/app_{æ—¥æœŸ}.log`
- æ§åˆ¶å°è¾“å‡ºï¼šå®æ—¶æ˜¾ç¤º

**å…³é”®æ—¥å¿—ç‚¹**ï¼š
```python
from loguru import logger

# åŠŸèƒ½å…¥å£
logger.info("å¼€å§‹XXXåŠŸèƒ½...")

# LLMè°ƒç”¨ï¼ˆå·²å†…ç½®ï¼‰
logger.info(f"[LLM API] XXX - Prompt:\n{prompt}")

# é”™è¯¯å¤„ç†
logger.error(f"XXXå¤±è´¥: {e}")

# è°ƒè¯•ä¿¡æ¯
logger.debug(f"ä¸­é—´ç»“æœ: {data}")
```

### å•å…ƒæµ‹è¯•

**æµ‹è¯•ç»“æ„**ï¼š
```
tests/
â”œâ”€â”€ test_loaders.py
â”œâ”€â”€ test_evaluator.py
â”œâ”€â”€ test_interview.py
â””â”€â”€ test_tools.py
```

**ç¼–å†™æµ‹è¯•**ï¼š
```python
# tests/test_evaluator.py
import pytest
from src.evaluator import ResumeEvaluator

def test_quick_score():
    evaluator = ResumeEvaluator()
    resume = "æµ‹è¯•ç®€å†å†…å®¹..."
    
    result = evaluator.quick_score(resume)
    
    assert "score_text" in result
    assert "metadata" in result
    assert result["metadata"]["elapsed_time"] > 0
```

**è¿è¡Œæµ‹è¯•**ï¼š
```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
pytest

# è¿è¡Œç‰¹å®šæµ‹è¯•
pytest tests/test_evaluator.py

# æ˜¾ç¤ºè¯¦ç»†è¾“å‡º
pytest -v

# ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š
pytest --cov=src tests/
```

### è°ƒè¯•æŠ€å·§

1. **Promptè°ƒè¯•**
   - æ‰€æœ‰LLMè°ƒç”¨éƒ½ä¼šæ‰“å°Promptæ—¥å¿—
   - è®¾ç½® `LOG_LEVEL=INFO` æŸ¥çœ‹å®Œæ•´Prompt
   - å¤åˆ¶Promptåˆ°LLMå¹³å°æµ‹è¯•

2. **æ–­ç‚¹è°ƒè¯•**
   - VS Code: æ·»åŠ æ–­ç‚¹åæŒ‰F5å¯åŠ¨è°ƒè¯•
   - PyCharm: å³é”® -> Debug 'web_ui'

3. **Gradioè°ƒè¯•**
   - åœ¨ `web_ui.py` çš„ `launch()` ä¸­æ·»åŠ  `debug=True`
   - æŸ¥çœ‹æµè§ˆå™¨æ§åˆ¶å°çš„ç½‘ç»œè¯·æ±‚

---

## éƒ¨ç½²æŒ‡å—

### æœ¬åœ°éƒ¨ç½²

å‚è€ƒ[å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)éƒ¨åˆ†ã€‚

### Dockeréƒ¨ç½²

1. **åˆ›å»ºDockerfile**
```dockerfile
FROM python:3.9-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

EXPOSE 7861

CMD ["python", "web_ui.py"]
```

2. **æ„å»ºé•œåƒ**
```bash
docker build -t interview-coach .
```

3. **è¿è¡Œå®¹å™¨**
```bash
docker run -d \
  -p 7861:7861 \
  -v $(pwd)/data:/app/data \
  -v $(pwd)/logs:/app/logs \
  --env-file .env \
  --name interview-coach \
  interview-coach
```

### äº‘æœåŠ¡å™¨éƒ¨ç½²

1. **ä½¿ç”¨systemdæœåŠ¡**

åˆ›å»º `/etc/systemd/system/interview-coach.service`ï¼š
```ini
[Unit]
Description=AI Interview Coach
After=network.target

[Service]
Type=simple
User=your-user
WorkingDirectory=/path/to/interview-coach
Environment="PATH=/path/to/venv/bin"
ExecStart=/path/to/venv/bin/python web_ui.py
Restart=always

[Install]
WantedBy=multi-user.target
```

å¯åŠ¨æœåŠ¡ï¼š
```bash
sudo systemctl enable interview-coach
sudo systemctl start interview-coach
sudo systemctl status interview-coach
```

2. **ä½¿ç”¨Nginxåå‘ä»£ç†**

```nginx
server {
    listen 80;
    server_name your-domain.com;

    location / {
        proxy_pass http://127.0.0.1:7861;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
    }
}
```

### æ€§èƒ½ä¼˜åŒ–

1. **APIè°ƒç”¨ä¼˜åŒ–**
   - ä½¿ç”¨æ›´å¿«çš„æ¨¡å‹ï¼ˆå¦‚GPT-3.5-turboï¼‰
   - å‡å°‘temperatureé™ä½éšæœºæ€§
   - é™åˆ¶max_tokenså‡å°‘å“åº”æ—¶é—´

2. **ç¼“å­˜ä¼˜åŒ–**
   - ç¼“å­˜å¸¸ç”¨çš„è¯„ä¼°ç»“æœ
   - ä½¿ç”¨Redisç¼“å­˜Promptç»“æœ

3. **å¹¶å‘å¤„ç†**
   - Gradioé»˜è®¤æ”¯æŒå¤šç”¨æˆ·å¹¶å‘
   - æ³¨æ„LLM APIçš„å¹¶å‘é™åˆ¶

---

## å¸¸è§é—®é¢˜

### Q1: å¦‚ä½•ä¿®æ”¹UIç«¯å£ï¼Ÿ

**A**: ä¿®æ”¹ `web_ui.py` ä¸­çš„ `launch()` å‚æ•°ï¼š
```python
app.launch(
    server_name="127.0.0.1",
    server_port=7862,  # ä¿®æ”¹ç«¯å£
    share=False,
)
```

### Q2: å¦‚ä½•æ·»åŠ ç”¨æˆ·è®¤è¯ï¼Ÿ

**A**: Gradioæ”¯æŒè®¤è¯ï¼š
```python
app.launch(
    server_name="127.0.0.1",
    server_port=7861,
    auth=("username", "password"),  # æ·»åŠ è®¤è¯
)
```

### Q3: å¦‚ä½•ä¼˜åŒ–LLMå“åº”é€Ÿåº¦ï¼Ÿ

**A**: 
- ä½¿ç”¨æ›´å¿«çš„æ¨¡å‹
- å‡å°‘Prompté•¿åº¦
- ä½¿ç”¨streamingæ¨¡å¼ï¼ˆéœ€ä¿®æ”¹ä»£ç ï¼‰
- å¢åŠ APIå¹¶å‘é™åˆ¶

### Q4: å¦‚ä½•æ”¯æŒå¤šè¯­è¨€ï¼Ÿ

**A**: ä¿®æ”¹Promptæ¨¡æ¿ï¼Œæ·»åŠ è¯­è¨€å‚æ•°ï¼š
```python
def get_resume_evaluation_prompt(resume_content, language="zh"):
    if language == "en":
        prompt = """You are a senior HR..."""
    else:
        prompt = """ä½ æ˜¯ä¸€ä½èµ„æ·±HR..."""
    return prompt
```

### Q5: å¦‚ä½•ç›‘æ§ç³»ç»Ÿè¿è¡ŒçŠ¶æ€ï¼Ÿ

**A**: 
- æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶ï¼š`tail -f logs/app_*.log`
- æ·»åŠ ç›‘æ§æ¥å£ï¼ˆéœ€å¼€å‘ï¼‰
- ä½¿ç”¨ç³»ç»Ÿç›‘æ§å·¥å…·ï¼ˆå¦‚Prometheusï¼‰

---

## ä»£ç è§„èŒƒ

### Pythonä»£ç è§„èŒƒ

éµå¾ª PEP 8 è§„èŒƒï¼š

```python
# å‘½åè§„èŒƒ
class ResumeEvaluator:  # ç±»åï¼šå¤§é©¼å³°
    def evaluate_resume(self):  # å‡½æ•°åï¼šå°å†™+ä¸‹åˆ’çº¿
        max_score = 100  # å˜é‡åï¼šå°å†™+ä¸‹åˆ’çº¿
        API_KEY = "xxx"  # å¸¸é‡ï¼šå¤§å†™+ä¸‹åˆ’çº¿

# æ³¨é‡Šè§„èŒƒ
def process_data(data: List[str]) -> Dict[str, Any]:
    """
    å¤„ç†æ•°æ®çš„ç®€çŸ­æè¿°
    
    Args:
        data: è¾“å…¥æ•°æ®è¯´æ˜
        
    Returns:
        è¿”å›å€¼è¯´æ˜
        
    Raises:
        ValueError: å¼‚å¸¸æƒ…å†µè¯´æ˜
    """
    pass

# ç±»å‹æ³¨è§£
from typing import Optional, List, Dict, Any

def func(param: str) -> Optional[Dict[str, Any]]:
    pass
```

### æ ¼å¼åŒ–å·¥å…·

```bash
# ä½¿ç”¨blackæ ¼å¼åŒ–
black web_ui.py

# ä½¿ç”¨flake8æ£€æŸ¥
flake8 web_ui.py

# ä½¿ç”¨mypyç±»å‹æ£€æŸ¥
mypy web_ui.py
```

---

## è´¡çŒ®æŒ‡å—

1. Forké¡¹ç›®
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. æäº¤Pull Request

---

## æŠ€æœ¯æ”¯æŒ

- ğŸ“§ Email: support@example.com
- ğŸ’¬ Discussion: GitHub Discussions
- ğŸ› Bug Report: GitHub Issues

---

ç¥å¼€å‘é¡ºåˆ©ï¼å¦‚æœ‰é—®é¢˜æ¬¢è¿åé¦ˆã€‚
