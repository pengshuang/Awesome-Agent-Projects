"""
Pydantic æ•°æ®æ¨¡å‹ä½¿ç”¨ç¤ºä¾‹
å±•ç¤ºå¦‚ä½•ä½¿ç”¨æ–°çš„æ•°æ®æ¨¡å‹
"""

import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from pydantic import ValidationError
from src.models.resume import ResumeData, ResumeMetadata
from src.models.evaluation import EvaluationResult, ScoreDetails
from src.models.interview import (
    InterviewSession,
    InterviewMessage,
    MessageRole,
    InterviewType,
)
from config.settings import get_config


def example_resume_models():
    """ç¤ºä¾‹ 1: ç®€å†æ•°æ®æ¨¡å‹"""
    print("\n" + "=" * 70)
    print("ç¤ºä¾‹ 1: ç®€å†æ•°æ®æ¨¡å‹ï¼ˆPydanticï¼‰")
    print("=" * 70)
    
    # åˆ›å»ºç®€å†å…ƒæ•°æ®
    metadata = ResumeMetadata(
        file_name="resume.pdf",
        file_path="/data/resumes/resume.pdf",
        file_size=1048576,  # 1MB
        content_length=5000,
        load_time=1.23,
    )
    
    # è®¿é—®è®¡ç®—å±æ€§
    print(f"\næ–‡ä»¶å¤§å°: {metadata.file_size_mb} MB")
    
    # åˆ›å»ºç®€å†æ•°æ®
    resume = ResumeData(
        content="è¿™æ˜¯ä¸€ä»½ç®€å†å†…å®¹ï¼ŒåŒ…å«ä¸ªäººä¿¡æ¯ã€å·¥ä½œç»å†ã€é¡¹ç›®ç»éªŒç­‰...",
        metadata=metadata,
    )
    
    # è®¿é—®è®¡ç®—å±æ€§
    print(f"å­—æ•°ç»Ÿè®¡: {resume.word_count}")
    print(f"å†…å®¹é¢„è§ˆ: {resume.preview}")
    
    # å¯¼å‡ºä¸ºå­—å…¸
    print("\nå¯¼å‡ºä¸ºå­—å…¸:")
    print(resume.model_dump())
    
    # å¯¼å‡ºä¸º JSON
    print("\nå¯¼å‡ºä¸º JSON:")
    print(resume.model_dump_json(indent=2))
    
    # æ•°æ®éªŒè¯ç¤ºä¾‹
    print("\næ•°æ®éªŒè¯ç¤ºä¾‹:")
    try:
        bad_resume = ResumeData(
            content="",  # ç©ºå†…å®¹ä¼šè§¦å‘éªŒè¯é”™è¯¯
            metadata=metadata,
        )
    except ValidationError as e:
        print("éªŒè¯å¤±è´¥ï¼ˆé¢„æœŸè¡Œä¸ºï¼‰:")
        for error in e.errors():
            print(f"  - {error['loc']}: {error['msg']}")


def example_evaluation_models():
    """ç¤ºä¾‹ 2: è¯„ä¼°ç»“æœæ¨¡å‹"""
    print("\n" + "=" * 70)
    print("ç¤ºä¾‹ 2: è¯„ä¼°ç»“æœæ¨¡å‹ï¼ˆPydanticï¼‰")
    print("=" * 70)
    
    # åˆ›å»ºè¯„åˆ†è¯¦æƒ…
    scores = ScoreDetails(
        basic_info=8.5,
        work_experience=7.0,
        project_quality=8.0,
        skill_match=7.5,
        education=9.0,
        overall_impression=8.0,
    )
    
    # è‡ªåŠ¨è®¡ç®—çš„å±æ€§
    print(f"\næ€»åˆ†: {scores.total_score}/100")
    print(f"è¯„çº§: {scores.grade}")
    
    # åˆ›å»ºè¯„ä¼°ç»“æœ
    evaluation = EvaluationResult(
        evaluation_text="## è¯„ä¼°ç»“æœ\n\nè¿™æ˜¯ä¸€ä»½ä¼˜ç§€çš„ç®€å†...",
        position="Python åç«¯å·¥ç¨‹å¸ˆ",
        requirements="3å¹´ä»¥ä¸ŠPythonå¼€å‘ç»éªŒ",
        strengths=["æŠ€æœ¯æ ˆåŒ¹é…", "é¡¹ç›®ç»éªŒä¸°å¯Œ", "æ•™è‚²èƒŒæ™¯ä¼˜ç§€"],
        weaknesses=["ç¼ºå°‘é‡åŒ–æŒ‡æ ‡"],
        suggestions=["æ·»åŠ å…·ä½“çš„é¡¹ç›®æ•°æ®å’Œæˆæœ"],
        score_details=scores,
        model="gpt-3.5-turbo",
        elapsed_time=5.23,
    )
    
    # è®¿é—®æ‘˜è¦
    print(f"\nè¯„ä¼°æ‘˜è¦: {evaluation.summary}")
    
    # å¯¼å‡ºéƒ¨åˆ†æ•°æ®
    print("\nå¯¼å‡ºéƒ¨åˆ†æ•°æ®ï¼ˆæ’é™¤å®Œæ•´æ–‡æœ¬ï¼‰:")
    partial_data = evaluation.model_dump(
        exclude={"evaluation_text"}, include={"position", "summary", "score_details"}
    )
    print(partial_data)
    
    # æ•°æ®éªŒè¯ç¤ºä¾‹
    print("\næ•°æ®éªŒè¯ç¤ºä¾‹:")
    try:
        bad_scores = ScoreDetails(
            basic_info=11.0,  # è¶…å‡ºèŒƒå›´ (0-10)
            work_experience=7.0,
            project_quality=8.0,
            skill_match=7.5,
            education=9.0,
            overall_impression=8.0,
        )
    except ValidationError as e:
        print("éªŒè¯å¤±è´¥ï¼ˆé¢„æœŸè¡Œä¸ºï¼‰:")
        for error in e.errors():
            print(f"  - {error['loc']}: {error['msg']}")


def example_interview_models():
    """ç¤ºä¾‹ 3: é¢è¯•ä¼šè¯æ¨¡å‹"""
    print("\n" + "=" * 70)
    print("ç¤ºä¾‹ 3: é¢è¯•ä¼šè¯æ¨¡å‹ï¼ˆPydanticï¼‰")
    print("=" * 70)
    
    # åˆ›å»ºé¢è¯•ä¼šè¯
    session = InterviewSession(
        interview_type=InterviewType.TECHNICAL,
        resume_content="å€™é€‰äººç®€å†å†…å®¹...",
        enable_web_search=True,
        max_history_turns=20,
    )
    
    # æ·»åŠ æ¶ˆæ¯
    session.add_message(
        role=MessageRole.ASSISTANT,
        content="æ‚¨å¥½ï¼æ¬¢è¿å‚åŠ ä»Šå¤©çš„æŠ€æœ¯é¢è¯•ã€‚è¯·å…ˆåšä¸ªè‡ªæˆ‘ä»‹ç»ã€‚",
        tokens=50,
    )
    
    session.add_message(
        role=MessageRole.USER,
        content="æ‚¨å¥½ï¼æˆ‘æ˜¯å¼ ä¸‰ï¼Œæœ‰3å¹´çš„Pythonå¼€å‘ç»éªŒ...",
        tokens=30,
    )
    
    session.add_message(
        role=MessageRole.ASSISTANT,
        content="å¾ˆå¥½ï¼è¯·è¯¦ç»†ä»‹ç»ä¸€ä¸‹æ‚¨æœ€è¿‘çš„é¡¹ç›®ç»éªŒã€‚",
        tokens=25,
    )
    
    # è®¿é—®ä¼šè¯ç»Ÿè®¡
    print(f"\nä¼šè¯æ‘˜è¦: {session.summary}")
    print(f"æ€»è½®æ•°: {session.total_turns}")
    print(f"æ—¶é•¿: {session.duration_minutes} åˆ†é’Ÿ")
    print(f"æ€»Token: {session.total_tokens}")
    print(f"æ˜¯å¦è¿›è¡Œä¸­: {session.is_active}")
    
    # è·å–å¯¹è¯å†å²ï¼ˆç”¨äº LLM APIï¼‰
    history = session.get_history(max_turns=2)
    print(f"\næœ€è¿‘2è½®å¯¹è¯:")
    for msg in history:
        print(f"  {msg['role']}: {msg['content'][:50]}...")
    
    # ç»“æŸä¼šè¯
    session.end_session()
    print(f"\nä¼šè¯å·²ç»“æŸ")
    print(f"æœ€ç»ˆæ—¶é•¿: {session.duration_minutes} åˆ†é’Ÿ")
    
    # å¯¼å‡ºä¸º JSON
    print("\nå¯¼å‡ºä¸º JSONï¼ˆéƒ¨åˆ†ï¼‰:")
    session_data = session.model_dump(
        exclude={"resume_content", "messages"},
        include={"interview_type", "summary", "total_turns", "duration_minutes"},
    )
    print(session_data)


def example_config_settings():
    """ç¤ºä¾‹ 4: é…ç½®ç®¡ç†ï¼ˆPydantic Settingsï¼‰"""
    print("\n" + "=" * 70)
    print("ç¤ºä¾‹ 4: é…ç½®ç®¡ç†ï¼ˆPydantic Settingsï¼‰")
    print("=" * 70)
    
    # è·å–é…ç½®å®ä¾‹ï¼ˆå•ä¾‹ï¼‰
    config = get_config()
    
    # è®¿é—®é…ç½®
    print(f"\nLLM æ¨¡å‹: {config.llm_model}")
    print(f"LLM Base: {config.llm_api_base}")
    print(f"æ¸©åº¦: {config.temperature}")
    print(f"è”ç½‘æœç´¢: {'å¯ç”¨' if config.enable_web_search else 'ç¦ç”¨'}")
    print(f"æœç´¢å¼•æ“: {config.web_search_engine}")
    
    # è®¿é—®è®¡ç®—å±æ€§ï¼ˆè·¯å¾„ï¼‰
    print(f"\né¡¹ç›®æ ¹ç›®å½•: {config.base_dir}")
    print(f"ç®€å†ç›®å½•: {config.resumes_dir}")
    print(f"æ—¥å¿—ç›®å½•: {config.logs_dir}")
    
    # è·å–é…ç½®æ‘˜è¦
    print(f"\n{config.get_summary()}")
    
    # å¯¼å‡ºé…ç½®ï¼ˆæ’é™¤æ•æ„Ÿä¿¡æ¯ï¼‰
    config_data = config.model_dump(exclude={"llm_api_key"})
    print(f"\né…ç½®æ•°æ®ï¼ˆæ’é™¤API Keyï¼‰:")
    print(config_data)


def example_json_serialization():
    """ç¤ºä¾‹ 5: JSON åºåˆ—åŒ–å’Œååºåˆ—åŒ–"""
    print("\n" + "=" * 70)
    print("ç¤ºä¾‹ 5: JSON åºåˆ—åŒ–å’Œååºåˆ—åŒ–")
    print("=" * 70)
    
    # åˆ›å»ºæ•°æ®
    metadata = ResumeMetadata(
        file_name="resume.pdf",
        file_path="/data/resumes/resume.pdf",
        file_size=1048576,
        content_length=5000,
        load_time=1.23,
    )
    
    resume = ResumeData(content="ç®€å†å†…å®¹...", metadata=metadata)
    
    # å¯¼å‡ºä¸º JSON å­—ç¬¦ä¸²
    json_str = resume.model_dump_json(indent=2)
    print(f"\nå¯¼å‡ºä¸º JSON:")
    print(json_str)
    
    # ä» JSON å­—ç¬¦ä¸²åŠ è½½
    loaded_resume = ResumeData.model_validate_json(json_str)
    print(f"\nä» JSON åŠ è½½æˆåŠŸ:")
    print(f"æ–‡ä»¶å: {loaded_resume.metadata.file_name}")
    print(f"å†…å®¹é•¿åº¦: {loaded_resume.metadata.content_length}")
    
    # ä»å­—å…¸åŠ è½½
    data_dict = resume.model_dump()
    loaded_from_dict = ResumeData.model_validate(data_dict)
    print(f"\nä»å­—å…¸åŠ è½½æˆåŠŸ:")
    print(f"é¢„è§ˆ: {loaded_from_dict.preview}")


def example_schema_generation():
    """ç¤ºä¾‹ 6: JSON Schema ç”Ÿæˆ"""
    print("\n" + "=" * 70)
    print("ç¤ºä¾‹ 6: JSON Schema ç”Ÿæˆï¼ˆç”¨äº API æ–‡æ¡£ï¼‰")
    print("=" * 70)
    
    # ç”Ÿæˆ JSON Schema
    import json
    
    schema = InterviewSession.model_json_schema()
    print(f"\nInterviewSession JSON Schema:")
    print(json.dumps(schema, indent=2, ensure_ascii=False))


def main():
    """è¿è¡Œæ‰€æœ‰ç¤ºä¾‹"""
    print("\n" + "=" * 70)
    print("Pydantic æ•°æ®æ¨¡å‹ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 70)
    
    example_resume_models()
    example_evaluation_models()
    example_interview_models()
    
    try:
        example_config_settings()
    except Exception as e:
        print(f"\nâš ï¸ é…ç½®ç¤ºä¾‹è·³è¿‡ï¼ˆéœ€è¦é…ç½® .env æ–‡ä»¶ï¼‰: {e}")
    
    example_json_serialization()
    example_schema_generation()
    
    print("\n" + "=" * 70)
    print("æ‰€æœ‰ç¤ºä¾‹è¿è¡Œå®Œæˆï¼")
    print("=" * 70)
    print("\nğŸ’¡ æç¤º:")
    print("  - æŸ¥çœ‹ docs/PYDANTIC_GUIDE.md äº†è§£æ›´å¤šç”¨æ³•")
    print("  - æ‰€æœ‰æ•°æ®æ¨¡å‹éƒ½æ”¯æŒè‡ªåŠ¨éªŒè¯å’Œåºåˆ—åŒ–")
    print("  - ä½¿ç”¨ model_dump() å’Œ model_dump_json() å¯¼å‡ºæ•°æ®")
    print("  - ä½¿ç”¨ model_validate() å’Œ model_validate_json() åŠ è½½æ•°æ®")


if __name__ == "__main__":
    main()
