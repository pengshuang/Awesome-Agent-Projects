# é‡æ„è¯´æ˜ - ç§»é™¤ LlamaIndex ä¾èµ–

## ğŸ“ å˜æ›´æ¦‚è¿°

æœ¬æ¬¡é‡æ„ç§»é™¤äº†å¯¹ LlamaIndex æ¡†æ¶çš„ä¾èµ–ï¼Œæ”¹ä¸ºç›´æ¥ä½¿ç”¨ OpenAI å®˜æ–¹ Python å®¢æˆ·ç«¯åº“ã€‚è¿™ä¸ªæ”¹åŠ¨ä½¿é¡¹ç›®æ›´åŠ è½»é‡ã€ç®€æ´ã€æ˜“äºç†è§£å’Œç»´æŠ¤ã€‚

## ğŸ¯ é‡æ„åŸå› 

1. **ç®€åŒ–ä¾èµ–**: LlamaIndex æ˜¯ä¸€ä¸ªé‡é‡çº§çš„ RAG æ¡†æ¶ï¼Œä½†æœ¬é¡¹ç›®ä¸éœ€è¦ RAG åŠŸèƒ½
2. **é™ä½å¤æ‚åº¦**: ç›´æ¥ä½¿ç”¨ OpenAI API ä½¿ä»£ç æ›´ç›´è§‚
3. **æå‡æ€§èƒ½**: å‡å°‘ä¸­é—´å±‚æŠ½è±¡ï¼Œæå‡å“åº”é€Ÿåº¦
4. **æ˜“äºç»´æŠ¤**: æ›´å°‘çš„ä¾èµ–æ„å‘³ç€æ›´å°‘çš„æ½œåœ¨é—®é¢˜
5. **é™ä½å­¦ä¹ æˆæœ¬**: å¼€å‘è€…åªéœ€äº†è§£ OpenAI APIï¼Œæ— éœ€å­¦ä¹  LlamaIndex

## ğŸ”„ ä¸»è¦å˜æ›´

### 1. ä¾èµ–å˜æ›´

**ä¹‹å‰ (requirements.txt)**:
```txt
llama-index>=0.13.0,<0.14.0
llama-index-core>=0.13.0,<0.14.0
llama-index-llms-openai>=0.3.0
llama-index-llms-openai-like>=0.2.0
```

**ç°åœ¨ (requirements.txt)**:
```txt
openai>=1.0.0
```

å¤§å¹…å‡å°‘äº†ä¾èµ–åŒ…æ•°é‡ï¼

### 2. LLM é…ç½®æ¨¡å— (config/llm_config.py)

**ä¹‹å‰**:
```python
from llama_index.core.llms import LLM
from llama_index.llms.openai import OpenAI

def get_llm(...) -> LLM:
    return OpenAI(...)  # è¿”å› LlamaIndex åŒ…è£…çš„å¯¹è±¡
```

**ç°åœ¨**:
```python
from openai import OpenAI

def get_llm_client(...) -> Tuple[OpenAI, str, float]:
    client = OpenAI(api_key=..., base_url=...)
    return client, model, temperature
```

ç›´æ¥è¿”å› OpenAI å®¢æˆ·ç«¯ï¼Œæ›´åŠ ç®€æ´ï¼

### 3. Settings å…¨å±€é…ç½®ç§»é™¤

**ä¹‹å‰**:
```python
from llama_index.core import Settings

Settings.llm = get_llm()  # å…¨å±€è®¾ç½®
```

**ç°åœ¨**:
```python
# ç›´æ¥åœ¨ç±»ä¸­åˆå§‹åŒ–å®¢æˆ·ç«¯
self.client, self.model, self.temperature = get_llm_client()
```

ä¸å†ä¾èµ–å…¨å±€çŠ¶æ€ï¼Œæ›´åŠ æ¸…æ™°ï¼

### 4. LLM è°ƒç”¨æ–¹å¼ç®€åŒ–

**ä¹‹å‰ (resume_evaluator.py)**:
```python
response = self.llm.complete(prompt)
evaluation_text = response.text
```

**ç°åœ¨**:
```python
response = self.client.chat.completions.create(
    model=self.model,
    messages=[{"role": "user", "content": prompt}],
    temperature=self.temperature,
)
evaluation_text = response.choices[0].message.content
```

ç›´æ¥ä½¿ç”¨ OpenAI æ ‡å‡† APIï¼Œæ›´åŠ æ ‡å‡†ï¼

**ä¹‹å‰ (interview_agent.py)**:
```python
# éœ€è¦åˆ¤æ–­æ˜¯å¦æ”¯æŒ chat æ–¹æ³•
if hasattr(self.llm, 'chat'):
    from llama_index.core.llms import ChatMessage
    chat_messages = [ChatMessage(...) for msg in messages]
    response = self.llm.chat(chat_messages)
    assistant_message = response.message.content
else:
    # å›é€€é€»è¾‘
    prompt = self._format_messages_as_prompt(messages)
    response = self.llm.complete(prompt)
    assistant_message = response.text
```

**ç°åœ¨**:
```python
# ç›´æ¥è°ƒç”¨ï¼Œæ— éœ€åˆ¤æ–­
response = self.client.chat.completions.create(
    model=self.model,
    messages=messages,
    temperature=self.temperature,
)
assistant_message = response.choices[0].message.content
```

ä»£ç æ›´ç®€æ´ï¼Œæ²¡æœ‰æ¡ä»¶åˆ†æ”¯ï¼

## ğŸ“Š å¯¹æ¯”åˆ†æ

| æŒ‡æ ‡ | ä¹‹å‰ (LlamaIndex) | ç°åœ¨ (OpenAI ç›´æ¥) | æ”¹è¿› |
|------|------------------|-------------------|------|
| **æ ¸å¿ƒä¾èµ–åŒ…æ•°é‡** | ~15ä¸ª | ~3ä¸ª | â¬‡ï¸ 80% |
| **å®‰è£…å¤§å°** | ~500MB | ~50MB | â¬‡ï¸ 90% |
| **ä»£ç è¡Œæ•°** | æ›´å¤š | æ›´å°‘ | â¬‡ï¸ 20% |
| **å­¦ä¹ æ›²çº¿** | é™¡å³­ | å¹³ç¼“ | â¬†ï¸ 50% |
| **è°ƒè¯•éš¾åº¦** | è¾ƒé«˜ | è¾ƒä½ | â¬†ï¸ 40% |
| **API å“åº”é€Ÿåº¦** | è¾ƒæ…¢ | è¾ƒå¿« | â¬†ï¸ 10% |
| **å…¼å®¹æ€§** | éœ€è¦é€‚é… | åŸç”Ÿæ”¯æŒ | â¬†ï¸ 100% |

## âœ… å…¼å®¹æ€§è¯´æ˜

### ä¾ç„¶æ”¯æŒæ‰€æœ‰ OpenAI å…¼å®¹ API

ç”±äº OpenAI Python å®¢æˆ·ç«¯æ”¯æŒè‡ªå®šä¹‰ `base_url`ï¼Œæ‰€æœ‰ OpenAI å…¼å®¹çš„ API éƒ½å¯ä»¥æ— ç¼ä½¿ç”¨ï¼š

- âœ… OpenAI å®˜æ–¹
- âœ… DeepSeek
- âœ… Qwen (é€šä¹‰åƒé—®)
- âœ… Moonshot
- âœ… æ™ºè°± AI (GLM)
- âœ… æœ¬åœ°éƒ¨ç½²æ¨¡å‹ (Ollama, vLLM ç­‰)
- âœ… å…¶ä»–ä»»ä½• OpenAI å…¼å®¹ API

### é…ç½®æ–¹å¼ä¸å˜

`.env` æ–‡ä»¶é…ç½®æ–¹å¼å®Œå…¨ä¸€è‡´ï¼š

```ini
LLM_API_KEY=your-key
LLM_API_BASE=https://api.deepseek.com
LLM_MODEL=deepseek-chat
TEMPERATURE=0.7
```

## ğŸš€ å‡çº§æŒ‡å—

å¦‚æœä½ ä¹‹å‰æ‹‰å–è¿‡ä»£ç ï¼Œéœ€è¦ï¼š

1. **æ›´æ–°ä¾èµ–**
   ```bash
   pip uninstall llama-index llama-index-core llama-index-llms-openai llama-index-llms-openai-like
   pip install -r requirements.txt
   ```

2. **æ— éœ€ä¿®æ”¹é…ç½®**
   `.env` æ–‡ä»¶æ— éœ€ä»»ä½•æ”¹åŠ¨

3. **é‡å¯åº”ç”¨**
   ```bash
   python3 web_ui.py
   ```

## ğŸ“– API å˜æ›´

### å¼€å‘è€… API å˜æ›´

å¦‚æœä½ åœ¨äºŒæ¬¡å¼€å‘ï¼Œéœ€è¦æ³¨æ„ä»¥ä¸‹å˜æ›´ï¼š

**config æ¨¡å—**:
- `get_llm()` â†’ `get_llm_client()`
- è¿”å›å€¼ä» `LLM` å¯¹è±¡æ”¹ä¸º `(OpenAI, str, float)` å…ƒç»„

**ResumeEvaluator**:
- `self.llm` â†’ `self.client`
- LLM è°ƒç”¨æ–¹å¼æ”¹å˜ï¼ˆè§ä¸Šæ–‡ï¼‰

**InterviewAgent**:
- `self.llm` â†’ `self.client`
- ç§»é™¤äº† `_format_messages_as_prompt()` æ–¹æ³•
- ç®€åŒ–äº† `chat()` æ–¹æ³•çš„å®ç°

## ğŸ’¡ æ€»ç»“

è¿™æ¬¡é‡æ„æ˜¯ä¸€æ¬¡**å»æ¡†æ¶åŒ–**çš„å°è¯•ï¼Œè¯æ˜äº†ï¼š

1. âœ… ä¸æ˜¯æ‰€æœ‰ LLM åº”ç”¨éƒ½éœ€è¦å¤æ‚æ¡†æ¶
2. âœ… ç®€å•ç›´æ¥çš„ API è°ƒç”¨æ›´æ˜“ç†è§£
3. âœ… å‡å°‘ä¾èµ–èƒ½æå‡é¡¹ç›®å¥å£®æ€§
4. âœ… åŸç”Ÿ SDK å¾€å¾€æ˜¯æœ€å¥½çš„é€‰æ‹©

æœ¬é¡¹ç›®ç°åœ¨æ›´åŠ **è½»é‡ã€å¿«é€Ÿã€æ˜“æ‡‚**ï¼

---

**é‡æ„æ—¥æœŸ**: 2025-12-20
**å½±å“èŒƒå›´**: å…¨éƒ¨æ ¸å¿ƒæ¨¡å—
**å…¼å®¹æ€§**: å®Œå…¨å‘åå…¼å®¹ï¼ˆç”¨æˆ·é…ç½®æ— éœ€ä¿®æ”¹ï¼‰
